{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58dffa5e",
   "metadata": {},
   "source": [
    "#### Convert the original dataset files (extension .dat) to CSV format.\n",
    " - The dataset comprises 20 DAT files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd8d21d",
   "metadata": {},
   "source": [
    "#### Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a0dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import wfdb\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec94588a",
   "metadata": {},
   "source": [
    "#### Functions for converting the list of DAT files to CSV format.\n",
    "- The result is grouped into a single CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd82e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants for task names.\n",
    "FIRST_RELAX_TASK = \"first_relax_task\"\n",
    "PHYS_STRESS_TASK = \"physical_stress_task\"\n",
    "SECOND_RELAX_TASK = \"second_relax_task\"\n",
    "COGN_STRESS_TASK = \"cognitive_stress_task\"\n",
    "THIRD_RELAX_TASK = \"third_relax_task\"\n",
    "EMOT_STRESS_TASK = \"emotional_stress_task\"\n",
    "FOURTH_RELAX_TASK = \"fourth_relax_task\"\n",
    "\n",
    "# Constants for timestamp range limits.\n",
    "I_RANGE_VALUE = \"initial_range_value\"\n",
    "F_RANGE_VALUE = \"final_range_value\"\n",
    "\n",
    "# Constants for tasks sequence in annotation locations in samples relative to the beginning of the record.\n",
    "FIRST_RELAX_TASK_IDX = 0\n",
    "PHYS_STRESS_TASK_IDX = 1\n",
    "SECOND_RELAX_TASK_IDX = 2\n",
    "MINI_EMOT_STRESS_TASK_IDX = 3\n",
    "COGN_STRESS_TASK_IDX = 4\n",
    "THIRD_RELAX_TASK_IDX = 5\n",
    "EMOT_STRESS_TASK_IDX = 6\n",
    "FOURTH_RELAX_TASK_IDX = 7\n",
    "\n",
    "def get_range_indexes(annotation_sample, task_seq):\n",
    "    # Returns initial and final indexes of the annotations for each task.\n",
    "    # Parameters:\n",
    "    #    annotation_sample (list): list containing the initial indexes of the annotation locations for each task.\n",
    "    #    task_seq (int): task sequence\n",
    "    # Return:\n",
    "    #    Dictionary with keys \"initial_range_value\" and \"final_range_value\".\n",
    "    if annotation_sample is None or len(annotation_sample) == 0:\n",
    "        return None\n",
    "    result_dict = {}\n",
    "    try:\n",
    "        i_idx = annotation_sample[task_seq] // 8\n",
    "        f_idx = (annotation_sample[task_seq] + 2400) // 8\n",
    "        result_dict[I_RANGE_VALUE] = i_idx\n",
    "        result_dict[F_RANGE_VALUE] = f_idx\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    return result_dict\n",
    "\n",
    "def extract_timestamps_ranges(annotation_sample):\n",
    "    # Returns initial and final indexes of the annotations for all tasks.\n",
    "    # These indices represent the start and end timestamps of each task.\n",
    "    # Parameters:\n",
    "    #    annotation_sample (list): list containing the initial indexes of the annotation locations for each task.\n",
    "    # Return:\n",
    "    #    Dictionary with keys for each task.\n",
    "    print(\"\\nInit extract_timestamps_ranges function...\")\n",
    "    if annotation_sample is None or len(annotation_sample) == 0:\n",
    "        return None\n",
    "    result = {}\n",
    "    try:\n",
    "        result[FIRST_RELAX_TASK] = get_range_indexes(annotation_sample, FIRST_RELAX_TASK_IDX)\n",
    "        result[PHYS_STRESS_TASK] = get_range_indexes(annotation_sample, PHYS_STRESS_TASK_IDX)\n",
    "        result[SECOND_RELAX_TASK] = get_range_indexes(annotation_sample, SECOND_RELAX_TASK_IDX)\n",
    "        result[COGN_STRESS_TASK] = get_range_indexes(annotation_sample, COGN_STRESS_TASK_IDX)\n",
    "        result[THIRD_RELAX_TASK] = get_range_indexes(annotation_sample, THIRD_RELAX_TASK_IDX)\n",
    "        result[EMOT_STRESS_TASK] = get_range_indexes(annotation_sample, EMOT_STRESS_TASK_IDX)\n",
    "        result[FOURTH_RELAX_TASK] = get_range_indexes(annotation_sample, FOURTH_RELAX_TASK_IDX)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    print(\"Finish extract_timestamps_ranges function...\")\n",
    "    return result;\n",
    "\n",
    "def is_valid_timestamps_ranges_list(tasks_timestamps_range_dict):\n",
    "    # Checks whether the timestamp range settings for each task were successfully loaded.\n",
    "    # Parameters:\n",
    "    #    tasks_timestamps_range_dict (dict): initial and final value settings of timestamps for each task.\n",
    "    # Return:\n",
    "    #    True or False\n",
    "    if (len(tasks_timestamps_range_dict.keys()) != 7):\n",
    "        return False\n",
    "    for key_names in tasks_timestamps_range_dict.keys():\n",
    "        if tasks_timestamps_range_dict[key_names] is None:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def join_files(files_list):\n",
    "    # Generate a CSV file (dataset) that groups the contents of the DAT files.\n",
    "    # Parameters:\n",
    "    #    files_list (list): list of files to be processed.\n",
    "    print(\"\\nInit join_files function...\")\n",
    "    try:\n",
    "        # Check the structure of DAT files. The structure can be verified in the MIT Header file (.hea)\n",
    "        record = wfdb.rdrecord(\"../dataset/datafiles/\" + files_list[0]) \n",
    "        print(\"\\nDAT files structure:\")\n",
    "        print(record.__dict__)\n",
    "        # Result Dataframe\n",
    "        df_final = pd.DataFrame(columns = [\"hr\", \"label\"])\n",
    "        # Process files list.\n",
    "        for file_name in files_list:\n",
    "            # Load the DAT file.\n",
    "            print(\"\\nInit loading {} file...\".format(file_name))\n",
    "            record = wfdb.rdrecord(\"../dataset/datafiles/\" + file_name) \n",
    "            df = record.to_dataframe()\n",
    "            # Get timestamps ranges for each task and load its annotations.\n",
    "            annotation = wfdb.rdann(\"../dataset/datafiles/\" + file_name, \"atr\")\n",
    "            range_dict = extract_timestamps_ranges(annotation.sample)\n",
    "            if range_dict is None or not is_valid_timestamps_ranges_list(range_dict):\n",
    "                print(\"\\nFail to load {} file annotations.\".format(file_name))\n",
    "                continue\n",
    "            # Add a target to the dataframe with a fake class.\n",
    "            df[\"label\"] = 5\n",
    "            # Set correct annotations to the target.\n",
    "            # Task first relaxation - class 0 - 5 minutes / 300 seconds.\n",
    "            # Task physical stress - class 1 - 5 minutes / 300 seconds.\n",
    "            # Task second relaxation - class 0 - 5 minutes / 300 seconds.\n",
    "            # Task cognitive stress - class 2 - 5 minutures / 300 seconds.\n",
    "            # Task third relaxation - class 0 - 5 minutues / 300 seconds.\n",
    "            # Task emotional stress - class 3 - 5 minutes / 300 seconds.\n",
    "            frt = range_dict[FIRST_RELAX_TASK]\n",
    "            df.iloc[frt[I_RANGE_VALUE]:frt[I_RANGE_VALUE] + 300, 2] = 0\n",
    "            pst = range_dict[PHYS_STRESS_TASK]\n",
    "            df.iloc[pst[I_RANGE_VALUE]:pst[I_RANGE_VALUE] + 300, 2] = 1\n",
    "            srt = range_dict[SECOND_RELAX_TASK]\n",
    "            df.iloc[srt[I_RANGE_VALUE]:srt[I_RANGE_VALUE] + 300, 2] = 0\n",
    "            cst = range_dict[COGN_STRESS_TASK]\n",
    "            df.iloc[cst[I_RANGE_VALUE]:cst[I_RANGE_VALUE] + 300, 2] = 2\n",
    "            trt = range_dict[THIRD_RELAX_TASK]\n",
    "            df.iloc[trt[I_RANGE_VALUE]:trt[I_RANGE_VALUE] + 300, 2] = 0\n",
    "            est = range_dict[EMOT_STRESS_TASK]\n",
    "            df.iloc[est[I_RANGE_VALUE]:est[I_RANGE_VALUE] + 300, 2] = 3\n",
    "            fhrt = range_dict[FOURTH_RELAX_TASK]\n",
    "            df.iloc[fhrt[I_RANGE_VALUE]:fhrt[I_RANGE_VALUE] + 300, 2] = 0\n",
    "            # Keep only the HR feature in the dataset. The SpO2 feature will not be used for this study.\n",
    "            df.drop([\"SpO2\"], axis = \"columns\", inplace = True)\n",
    "            # Records from the \"mini emotional stress\" task and surplus records will be removed from the dataset.\n",
    "            df_aux = df[df[\"label\"] != 5]\n",
    "            df_final = pd.concat([df_final, df_aux])\n",
    "            print(\"\\nFinish loading {} file...\".format(file_name))\n",
    "    except Exception as e:\n",
    "        print(\"\\nFail to load DAT files.\")\n",
    "        print(\"Error: {}\".format(e))\n",
    "        return None\n",
    "    print(\"\\n\")\n",
    "    print(df_final.describe)\n",
    "    print(\"\\nStart writing original-noneeg-dataset.csv file...\")\n",
    "    df_final.to_csv('../dataset/original-noneeg-dataset.csv', index = False,  sep='|')\n",
    "    print(\"Finish writing CSV file...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f72c00",
   "metadata": {},
   "source": [
    "#### Generate the list with the names of the DAT files to be converted to CSV and call the conversion function.\n",
    "- A file named original-noneeg-dataset.csv will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1d9bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Init join_files function...\n",
      "\n",
      "DAT files structure:\n",
      "{'record_name': 'Subject1_SpO2HR', 'n_sig': 2, 'fs': 1, 'counter_freq': None, 'base_counter': None, 'sig_len': 2299, 'base_time': None, 'base_date': None, 'comments': ['age: 30', 'gender: M', 'height/cm: 177', 'weight/kg: 94'], 'sig_name': ['SpO2', 'hr'], 'p_signal': array([[96.99996948, 89.00076296],\n",
      "       [96.99996948, 88.00013733],\n",
      "       [96.99996948, 87.00044252],\n",
      "       ...,\n",
      "       [94.00006104, 76.0000763 ],\n",
      "       [95.00003052, 75.00038148],\n",
      "       [95.00003052, 74.00068667]]), 'd_signal': None, 'e_p_signal': None, 'e_d_signal': None, 'file_name': ['Subject1_SpO2HR.dat', 'Subject1_SpO2HR.dat'], 'fmt': ['16', '16'], 'samps_per_frame': [1, 1], 'skew': [None, None], 'byte_offset': [None, None], 'adc_gain': [10922.3333333, 1074.32786885], 'baseline': [-1048544, -103672], 'units': ['%', 'bpm'], 'adc_res': [16, 16], 'adc_zero': [0, 0], 'init_value': [10922, -8056], 'checksum': [54860, 19971], 'block_size': [0, 0]}\n",
      "\n",
      "Init loading Subject1_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject1_SpO2HR file...\n",
      "\n",
      "Init loading Subject2_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject2_SpO2HR file...\n",
      "\n",
      "Init loading Subject3_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject3_SpO2HR file...\n",
      "\n",
      "Init loading Subject4_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject4_SpO2HR file...\n",
      "\n",
      "Init loading Subject5_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject5_SpO2HR file...\n",
      "\n",
      "Init loading Subject6_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject6_SpO2HR file...\n",
      "\n",
      "Init loading Subject7_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject7_SpO2HR file...\n",
      "\n",
      "Init loading Subject8_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject8_SpO2HR file...\n",
      "\n",
      "Init loading Subject9_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject9_SpO2HR file...\n",
      "\n",
      "Init loading Subject10_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject10_SpO2HR file...\n",
      "\n",
      "Init loading Subject11_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject11_SpO2HR file...\n",
      "\n",
      "Init loading Subject12_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject12_SpO2HR file...\n",
      "\n",
      "Init loading Subject13_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject13_SpO2HR file...\n",
      "\n",
      "Init loading Subject14_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject14_SpO2HR file...\n",
      "\n",
      "Init loading Subject15_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject15_SpO2HR file...\n",
      "\n",
      "Init loading Subject16_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject16_SpO2HR file...\n",
      "\n",
      "Init loading Subject17_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject17_SpO2HR file...\n",
      "\n",
      "Init loading Subject18_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject18_SpO2HR file...\n",
      "\n",
      "Init loading Subject19_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject19_SpO2HR file...\n",
      "\n",
      "Init loading Subject20_SpO2HR file...\n",
      "\n",
      "Init extract_timestamps_ranges function...\n",
      "Finish extract_timestamps_ranges function...\n",
      "\n",
      "Finish loading Subject20_SpO2HR file...\n",
      "\n",
      "\n",
      "<bound method NDFrame.describe of                         hr label\n",
      "0 days 00:00:00  89.000763     0\n",
      "0 days 00:00:01  88.000137     0\n",
      "0 days 00:00:02  87.000443     0\n",
      "0 days 00:00:03  87.000443     0\n",
      "0 days 00:00:04  87.000443     0\n",
      "...                    ...   ...\n",
      "0 days 00:41:55  63.000885     0\n",
      "0 days 00:41:56  65.000214     0\n",
      "0 days 00:41:57  67.000702     0\n",
      "0 days 00:41:58  68.000366     0\n",
      "0 days 00:41:59  71.000519     0\n",
      "\n",
      "[41992 rows x 2 columns]>\n",
      "\n",
      "Start writing original-noneeg-dataset.csv file...\n",
      "Finish writing CSV file...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files_list = []\n",
    "\n",
    "# File name pattern: Subject[X]_SpO2HR\n",
    "for i in range(1, 21):\n",
    "    files_list.append(\"Subject\" + str(i) + \"_SpO2HR\")\n",
    "\n",
    "join_files(files_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90637585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
