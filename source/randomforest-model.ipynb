{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83bc191a",
   "metadata": {},
   "source": [
    "#### Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca5e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df = pd.read_csv(\"../dataset/original-noneeg-dataset.csv\", sep=\"|\", dtype = {\"hr\": \"float64\", \"label\": \"int8\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd331b19",
   "metadata": {},
   "source": [
    "#### Display the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af6a65fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41992, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87415071",
   "metadata": {},
   "source": [
    "#### Build a helper function to convert the set data to the required format to perform the undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cbc1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_steps = 30\n",
    "\n",
    "def build_time_window_structure(df):\n",
    "    # Splits the dataset into \"time windows\" to be used as a time series list.\n",
    "    # The function groups each 30 dataset records (CSV lines) into one record.\n",
    "    # Each record contains 30 steps and each step contains 1 feature value.\n",
    "    # Parameters:\n",
    "    #    df: Dataframe to be splitted.\n",
    "    # Return:\n",
    "    #    First list contains all time windows.\n",
    "    #    Second list contains all target values.\n",
    "    print(\"\\nStarting build_time_window_structure function.\")\n",
    "    initial_line_number = 0\n",
    "    first_feat_index = 0\n",
    "    last_feat_index = 1\n",
    "    X_array = []\n",
    "    y_array = []\n",
    "    while initial_line_number < len(df[\"label\"]):\n",
    "        target_value = df[\"label\"][initial_line_number]\n",
    "        sub_matrix = df.iloc[initial_line_number : (initial_line_number + number_of_steps), first_feat_index : last_feat_index]\n",
    "        sub_matrix_values = sub_matrix.values\n",
    "        new_line = sub_matrix_values.flatten()\n",
    "        size_diff = number_of_steps - len(new_line)\n",
    "        if size_diff > 0:\n",
    "            last_value = new_line[len(new_line) - 1]\n",
    "            new_line = np.append(new_line, [last_value] * size_diff)\n",
    "        X_array.append(new_line)\n",
    "        y_array.append(target_value)\n",
    "        initial_line_number += number_of_steps\n",
    "    print(\"Quantity of samples (features) => \", len(X_array))\n",
    "    print(\"Quantity os samples (labels) => \", len(y_array))\n",
    "    print(\"Finishing build_time_window_structure function.\")\n",
    "    return X_array, y_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a84877",
   "metadata": {},
   "source": [
    "#### Perform undersampling for balancing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba63a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting undersampling process.\n",
      "\n",
      "Starting build_time_window_structure function.\n",
      "Quantity of samples (features) =>  1400\n",
      "Quantity os samples (labels) =>  1400\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Quantity of resampled samples =>  800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Correct dataset imbalance through undersampling.\n",
    "print(\"\\nStarting undersampling process.\")\n",
    "X_list, y_list = build_time_window_structure(df)\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "X_arr = np.array(X_list)\n",
    "y_arr = np.array(y_list)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_arr, y_arr)\n",
    "print(\"\\nQuantity of resampled samples => \", len(y_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73177084",
   "metadata": {},
   "source": [
    "#### GridSearch to evaluate Random Forest hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b96d0bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training at:  23:20:42\n",
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "\n",
      "Time taken for training:  00:02:15\n",
      "\n",
      "Best values:\n",
      "{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pt = PowerTransformer()\n",
    "pt.fit(X_resampled)\n",
    "X = pt.transform(X_resampled)\n",
    "y = y_resampled\n",
    "\n",
    "model = RandomForestClassifier(random_state = 42, n_jobs = 4)\n",
    "params = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 10, 15, 21],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "strat_k_fold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "grid_search_cv = GridSearchCV(model, cv = strat_k_fold, param_grid = params, n_jobs = 4, verbose = 5)\n",
    "\n",
    "# Train the Random Forest model and show the best hyperparameter values.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training at: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "grid_search_cv.fit(X, y)\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\nBest values:\")\n",
    "print(grid_search_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cbec0a",
   "metadata": {},
   "source": [
    "#### Train the model using cross validation (10 fold) and display metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53e67a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training at:  23:24:00\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Training fold 6\n",
      "Training fold 7\n",
      "Training fold 8\n",
      "Training fold 9\n",
      "Training fold 10\n",
      "\n",
      "Time taken for training:  00:00:05\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.6486 - Test Accuracy 0.4625\n",
      "Fold 2 - Train Accuracy 0.6306 - Test Accuracy 0.4625\n",
      "Fold 3 - Train Accuracy 0.6264 - Test Accuracy 0.4750\n",
      "Fold 4 - Train Accuracy 0.6292 - Test Accuracy 0.4875\n",
      "Fold 5 - Train Accuracy 0.6472 - Test Accuracy 0.4375\n",
      "Fold 6 - Train Accuracy 0.6389 - Test Accuracy 0.4500\n",
      "Fold 7 - Train Accuracy 0.6319 - Test Accuracy 0.5125\n",
      "Fold 8 - Train Accuracy 0.6375 - Test Accuracy 0.4875\n",
      "Fold 9 - Train Accuracy 0.6306 - Test Accuracy 0.3750\n",
      "Fold 10 - Train Accuracy 0.6347 - Test Accuracy 0.4125\n",
      "\n",
      "Mean Train Accuracy: 0.6356 - Std: 0.0071 \n",
      "Mean Test Accuracy: 0.4562 - Std: 0.0380 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.27      0.33       200\n",
      "           1       0.60      0.69      0.65       200\n",
      "           2       0.39      0.41      0.40       200\n",
      "           3       0.38      0.45      0.41       200\n",
      "\n",
      "    accuracy                           0.46       800\n",
      "   macro avg       0.45      0.46      0.45       800\n",
      "weighted avg       0.45      0.46      0.45       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Normalize data using box-cox method.\n",
    "pt = PowerTransformer()\n",
    "pt.fit(X_resampled)\n",
    "X = pt.transform(X_resampled)\n",
    "y = y_resampled\n",
    "\n",
    "strat_k_fold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Train the Random Forest model and show the best hyperparameter values.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training at: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "\n",
    "train_accuracy_by_fold = []\n",
    "test_accuracy_by_fold = []\n",
    "y_predclass_for_report = []\n",
    "y_testclass_for_report = []\n",
    "fold_number = 1\n",
    "for train_index, test_index in strat_k_fold.split(X, y):\n",
    "    print(\"Training fold {}\".format(fold_number))\n",
    "    model = RandomForestClassifier(random_state = 42, n_jobs = 4, n_estimators = 300, max_depth = 5, criterion = \"gini\")\n",
    "    model.fit(X[train_index], y[train_index])\n",
    "    train_pred_classes = model.predict(X[train_index])\n",
    "    test_pred_classes = model.predict(X[test_index])\n",
    "    train_accuracy = accuracy_score(y[train_index] , train_pred_classes)\n",
    "    test_accuracy = accuracy_score(y[test_index] , test_pred_classes)\n",
    "    train_accuracy_by_fold.append(train_accuracy)\n",
    "    test_accuracy_by_fold.append(test_accuracy)\n",
    "    y_predclass_for_report.extend(test_pred_classes)\n",
    "    y_testclass_for_report.extend(y[test_index])\n",
    "    fold_number += 1\n",
    "\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show metrics.\n",
    "for i in range(len(train_accuracy_by_fold)):\n",
    "    print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "                            train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "print(\"\\nMean Train Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(train_accuracy_by_fold), np.std(train_accuracy_by_fold)))\n",
    "print(\"Mean Test Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(test_accuracy_by_fold), np.std(test_accuracy_by_fold)))\n",
    "\n",
    "print(\"\\nEvaluate other metrics:\")\n",
    "print(classification_report(y_testclass_for_report, y_predclass_for_report))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b40bbb4",
   "metadata": {},
   "source": [
    "#### Train the model using cross validation (10 fold) and display metrics.\n",
    "- Data augmentation (5x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a7f1417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data augmentation.\n",
      "\n",
      "Quantity of samples generated by oversampling =>  4000\n",
      "\n",
      "Starting training at:  23:24:53\n",
      "Training fold 1\n",
      "Training fold 2\n",
      "Training fold 3\n",
      "Training fold 4\n",
      "Training fold 5\n",
      "Training fold 6\n",
      "Training fold 7\n",
      "Training fold 8\n",
      "Training fold 9\n",
      "Training fold 10\n",
      "\n",
      "Time taken for training:  00:00:07\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.6467 - Test Accuracy 0.5975\n",
      "Fold 2 - Train Accuracy 0.6569 - Test Accuracy 0.6625\n",
      "Fold 3 - Train Accuracy 0.6497 - Test Accuracy 0.5825\n",
      "Fold 4 - Train Accuracy 0.6489 - Test Accuracy 0.6525\n",
      "Fold 5 - Train Accuracy 0.6344 - Test Accuracy 0.6325\n",
      "Fold 6 - Train Accuracy 0.6525 - Test Accuracy 0.6575\n",
      "Fold 7 - Train Accuracy 0.6586 - Test Accuracy 0.6125\n",
      "Fold 8 - Train Accuracy 0.6631 - Test Accuracy 0.6525\n",
      "Fold 9 - Train Accuracy 0.6522 - Test Accuracy 0.5925\n",
      "Fold 10 - Train Accuracy 0.6508 - Test Accuracy 0.5725\n",
      "\n",
      "Mean Train Accuracy: 0.6514 - Std: 0.0073 \n",
      "Mean Test Accuracy: 0.6215 - Std: 0.0323 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.45      0.55      1000\n",
      "           1       0.72      0.77      0.74      1000\n",
      "           2       0.56      0.61      0.59      1000\n",
      "           3       0.55      0.65      0.60      1000\n",
      "\n",
      "    accuracy                           0.62      4000\n",
      "   macro avg       0.63      0.62      0.62      4000\n",
      "weighted avg       0.63      0.62      0.62      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data augmentation (5x).\n",
    "print(\"\\nStarting data augmentation.\")\n",
    "X_all_oversampled = []\n",
    "y_all_oversampled = []\n",
    "X_resampled_values = X_resampled\n",
    "for count in range(0, 4):\n",
    "    X_oversampled, y_oversampled = resample(X_resampled_values[y_resampled == count],\n",
    "                                            y_resampled[y_resampled == count],\n",
    "                                            replace = True,\n",
    "                                            n_samples = 1000,\n",
    "                                            random_state = 42)\n",
    "    X_all_oversampled.extend(X_oversampled)\n",
    "    y_all_oversampled.extend(y_oversampled)\n",
    "X_resampled_arr = np.array(X_all_oversampled)\n",
    "y_resampled_arr = np.array(y_all_oversampled)\n",
    "print(\"\\nQuantity of samples generated by oversampling => \", len(y_resampled_arr))\n",
    "\n",
    "# Normalize data using box-cox method.\n",
    "pt = PowerTransformer()\n",
    "pt.fit(X_resampled_arr)\n",
    "X = pt.transform(X_resampled_arr)\n",
    "y = y_resampled_arr\n",
    "\n",
    "strat_k_fold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Train the Random Forest model and show the best hyperparameter values.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training at: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "\n",
    "train_accuracy_by_fold = []\n",
    "test_accuracy_by_fold = []\n",
    "y_predclass_for_report = []\n",
    "y_testclass_for_report = []\n",
    "fold_number = 1\n",
    "for train_index, test_index in strat_k_fold.split(X, y):\n",
    "    print(\"Training fold {}\".format(fold_number))\n",
    "    model = RandomForestClassifier(random_state = 42, n_jobs = 4, n_estimators = 300, max_depth = 5, criterion = \"gini\") \n",
    "    model.fit(X[train_index], y[train_index])\n",
    "    train_pred_classes = model.predict(X[train_index])\n",
    "    test_pred_classes = model.predict(X[test_index])\n",
    "    train_accuracy = accuracy_score(y[train_index] , train_pred_classes)\n",
    "    test_accuracy = accuracy_score(y[test_index] , test_pred_classes)\n",
    "    train_accuracy_by_fold.append(train_accuracy)\n",
    "    test_accuracy_by_fold.append(test_accuracy)\n",
    "    y_predclass_for_report.extend(test_pred_classes)\n",
    "    y_testclass_for_report.extend(y[test_index])\n",
    "    fold_number += 1\n",
    "\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show metrics.\n",
    "for i in range(len(train_accuracy_by_fold)):\n",
    "    print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "                            train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "print(\"\\nMean Train Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(train_accuracy_by_fold), np.std(train_accuracy_by_fold)))\n",
    "print(\"Mean Test Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(test_accuracy_by_fold), np.std(test_accuracy_by_fold)))\n",
    "\n",
    "print(\"\\nEvaluate other metrics:\")\n",
    "print(classification_report(y_testclass_for_report, y_predclass_for_report))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18bb57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
