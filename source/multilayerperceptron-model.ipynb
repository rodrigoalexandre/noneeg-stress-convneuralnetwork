{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbe460f",
   "metadata": {},
   "source": [
    "#### Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077b6c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.utils import resample\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42175028",
   "metadata": {},
   "source": [
    "#### Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43ccbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"../dataset/original-noneeg-dataset.csv\", sep=\"|\", dtype = {\"hr\": \"float64\", \"label\": \"int8\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d03541",
   "metadata": {},
   "source": [
    "#### Display the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d243cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41992, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c50592",
   "metadata": {},
   "source": [
    "#### Define a helper function to convert the set data to the required format to perform the undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3f5af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_steps = 30\n",
    "\n",
    "def build_time_window_structure(df):\n",
    "    # Splits the dataset into \"time windows\" to be used as a time series list.\n",
    "    # The function groups each 30 dataset records (CSV lines) into one record.\n",
    "    # Each record contains 30 steps and each step contains 1 feature value.\n",
    "    # Parameters:\n",
    "    #    df: Dataframe to be splitted.\n",
    "    # Return:\n",
    "    #    First list contains all time windows.\n",
    "    #    Second list contains all target values.\n",
    "    print(\"\\nStarting build_time_window_structure function.\")\n",
    "    initial_line_number = 0\n",
    "    first_feat_index = 0\n",
    "    last_feat_index = 1\n",
    "    X_array = []\n",
    "    y_array = []\n",
    "    while initial_line_number < len(df[\"label\"]):\n",
    "        target_value = df[\"label\"][initial_line_number]\n",
    "        sub_matrix = df.iloc[initial_line_number : (initial_line_number + number_of_steps), first_feat_index : last_feat_index]\n",
    "        sub_matrix_values = sub_matrix.values\n",
    "        new_line = sub_matrix_values.flatten()\n",
    "        size_diff = number_of_steps - len(new_line)\n",
    "        if size_diff > 0:\n",
    "            last_value = new_line[len(new_line) - 1]\n",
    "            new_line = np.append(new_line, [last_value] * size_diff)\n",
    "        X_array.append(new_line)\n",
    "        y_array.append(target_value)\n",
    "        initial_line_number += number_of_steps\n",
    "    print(\"Quantity of samples (features) => \", len(X_array))\n",
    "    print(\"Quantity os samples (labels) => \", len(y_array))\n",
    "    print(\"Finishing build_time_window_structure function.\")\n",
    "    return X_array, y_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a01eb",
   "metadata": {},
   "source": [
    "#### Perform undersampling to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2e2c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting undersampling process...\n",
      "\n",
      "Starting build_time_window_structure function.\n",
      "Quantity of samples (features) =>  1400\n",
      "Quantity os samples (labels) =>  1400\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Quantity of resampled samples =>  800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Correct dataset imbalance through undersampling.\n",
    "print(\"\\nStarting undersampling process...\")\n",
    "X_list, y_list = build_time_window_structure(df)\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "X_arr = np.array(X_list)\n",
    "y_arr = np.array(y_list)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_arr, y_arr)\n",
    "print(\"\\nQuantity of resampled samples => \", len(y_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab59b5",
   "metadata": {},
   "source": [
    "#### Train a Multilayer Perceptron model and evaluate the metrics.\n",
    "- Layer architecture => Dense (100) + Dense (200) + Dense (300) + Dense (200) + Dense (100) + Dense (4)\n",
    "- No data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7548bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "WARNING:tensorflow:From c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/300\n",
      "WARNING:tensorflow:From c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\DeveloperTools\\python\\3.11.0\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "11/11 [==============================] - 1s 18ms/step - loss: 1.4976 - accuracy: 0.3781 - val_loss: 2.5098 - val_accuracy: 0.0139\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2355 - accuracy: 0.4074 - val_loss: 1.5635 - val_accuracy: 0.0139\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1695 - accuracy: 0.4830 - val_loss: 1.5105 - val_accuracy: 0.0556\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1277 - accuracy: 0.4985 - val_loss: 1.7817 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0956 - accuracy: 0.5108 - val_loss: 2.0172 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0998 - accuracy: 0.5324 - val_loss: 1.5421 - val_accuracy: 0.0556\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0758 - accuracy: 0.5293 - val_loss: 1.5761 - val_accuracy: 0.1111\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0376 - accuracy: 0.5540 - val_loss: 2.3000 - val_accuracy: 0.0139\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0307 - accuracy: 0.5633 - val_loss: 1.6005 - val_accuracy: 0.0694\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9899 - accuracy: 0.5694 - val_loss: 2.3451 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0142 - accuracy: 0.5463 - val_loss: 2.0167 - val_accuracy: 0.0139\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0160 - accuracy: 0.5787 - val_loss: 1.6801 - val_accuracy: 0.0278\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.9921 - accuracy: 0.5617 - val_loss: 1.7796 - val_accuracy: 0.0278\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9421 - accuracy: 0.5772 - val_loss: 1.9350 - val_accuracy: 0.0139\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9173 - accuracy: 0.6157 - val_loss: 1.4781 - val_accuracy: 0.3889\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8863 - accuracy: 0.6204 - val_loss: 1.9150 - val_accuracy: 0.0417\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8809 - accuracy: 0.6173 - val_loss: 1.8409 - val_accuracy: 0.0417\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8572 - accuracy: 0.6373 - val_loss: 2.0670 - val_accuracy: 0.0278\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8570 - accuracy: 0.6451 - val_loss: 1.8590 - val_accuracy: 0.0694\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8082 - accuracy: 0.6790 - val_loss: 2.1410 - val_accuracy: 0.0417\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7839 - accuracy: 0.6898 - val_loss: 1.9249 - val_accuracy: 0.1806\n",
      "Epoch 22/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7537 - accuracy: 0.6944 - val_loss: 1.9859 - val_accuracy: 0.0556\n",
      "Epoch 23/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7725 - accuracy: 0.6636 - val_loss: 2.1638 - val_accuracy: 0.0417\n",
      "Epoch 24/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7412 - accuracy: 0.6991 - val_loss: 1.7872 - val_accuracy: 0.1944\n",
      "Epoch 25/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6949 - accuracy: 0.7130 - val_loss: 2.1702 - val_accuracy: 0.0556\n",
      "Epoch 26/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.7207 - val_loss: 1.8228 - val_accuracy: 0.1389\n",
      "Epoch 27/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.7562 - val_loss: 2.3453 - val_accuracy: 0.0972\n",
      "Epoch 28/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.7485 - val_loss: 2.3271 - val_accuracy: 0.0694\n",
      "Epoch 29/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7350 - accuracy: 0.6821 - val_loss: 1.9856 - val_accuracy: 0.0833\n",
      "Epoch 30/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7472 - accuracy: 0.7052 - val_loss: 2.3585 - val_accuracy: 0.0833\n",
      "Epoch 31/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6700 - accuracy: 0.7083 - val_loss: 1.9037 - val_accuracy: 0.1389\n",
      "Epoch 32/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6312 - accuracy: 0.7469 - val_loss: 2.5514 - val_accuracy: 0.0417\n",
      "Epoch 33/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.7515 - val_loss: 1.9790 - val_accuracy: 0.1944\n",
      "Epoch 34/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.7222 - val_loss: 2.6605 - val_accuracy: 0.1389\n",
      "Epoch 35/300\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.6132 - accuracy: 0.7500Restoring model weights from the end of the best epoch: 15.\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5999 - accuracy: 0.7469 - val_loss: 2.2307 - val_accuracy: 0.1250\n",
      "Epoch 35: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 2\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "11/11 [==============================] - 1s 16ms/step - loss: 1.3351 - accuracy: 0.3611 - val_loss: 1.5611 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.2048 - accuracy: 0.4059 - val_loss: 2.0758 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1741 - accuracy: 0.4738 - val_loss: 1.4804 - val_accuracy: 0.0139\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1375 - accuracy: 0.4985 - val_loss: 1.5297 - val_accuracy: 0.0417\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1341 - accuracy: 0.4954 - val_loss: 1.9674 - val_accuracy: 0.0139\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.1168 - accuracy: 0.5216 - val_loss: 1.5213 - val_accuracy: 0.0556\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0883 - accuracy: 0.5262 - val_loss: 1.8098 - val_accuracy: 0.0139\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0805 - accuracy: 0.5448 - val_loss: 1.6853 - val_accuracy: 0.0833\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0801 - accuracy: 0.5262 - val_loss: 2.1776 - val_accuracy: 0.0139\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0770 - accuracy: 0.5401 - val_loss: 1.7930 - val_accuracy: 0.0278\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0430 - accuracy: 0.5401 - val_loss: 1.8122 - val_accuracy: 0.0139\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0045 - accuracy: 0.5602 - val_loss: 1.9392 - val_accuracy: 0.0139\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9996 - accuracy: 0.5648 - val_loss: 1.8562 - val_accuracy: 0.0278\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9677 - accuracy: 0.5880 - val_loss: 1.9892 - val_accuracy: 0.2083\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9701 - accuracy: 0.5818 - val_loss: 2.1497 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9385 - accuracy: 0.5957 - val_loss: 1.6087 - val_accuracy: 0.0694\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.9324 - accuracy: 0.6111 - val_loss: 2.3920 - val_accuracy: 0.0139\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9166 - accuracy: 0.5957 - val_loss: 2.0045 - val_accuracy: 0.0417\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9052 - accuracy: 0.6157 - val_loss: 2.2097 - val_accuracy: 0.0139\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8938 - accuracy: 0.6049 - val_loss: 1.9071 - val_accuracy: 0.0972\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.6235 - val_loss: 2.1864 - val_accuracy: 0.0278\n",
      "Epoch 22/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8440 - accuracy: 0.6343 - val_loss: 1.9139 - val_accuracy: 0.2778\n",
      "Epoch 23/300\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.9464 - accuracy: 0.6406Restoring model weights from the end of the best epoch: 3.\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8352 - accuracy: 0.6466 - val_loss: 2.0680 - val_accuracy: 0.0278\n",
      "Epoch 23: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 3\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 1.3907 - accuracy: 0.3735 - val_loss: 1.6709 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2195 - accuracy: 0.4552 - val_loss: 2.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.2084 - accuracy: 0.4614 - val_loss: 1.8644 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1624 - accuracy: 0.5370 - val_loss: 1.3120 - val_accuracy: 0.4444\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1153 - accuracy: 0.5000 - val_loss: 1.9149 - val_accuracy: 0.0139\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0797 - accuracy: 0.5231 - val_loss: 1.8607 - val_accuracy: 0.0139\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0809 - accuracy: 0.5093 - val_loss: 1.6245 - val_accuracy: 0.1944\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0320 - accuracy: 0.5478 - val_loss: 1.9046 - val_accuracy: 0.0556\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0401 - accuracy: 0.5772 - val_loss: 1.8660 - val_accuracy: 0.0972\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0445 - accuracy: 0.5463 - val_loss: 1.9038 - val_accuracy: 0.0278\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9931 - accuracy: 0.5772 - val_loss: 2.0431 - val_accuracy: 0.0417\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9570 - accuracy: 0.5772 - val_loss: 2.0880 - val_accuracy: 0.0278\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9858 - accuracy: 0.5972 - val_loss: 1.5834 - val_accuracy: 0.4722\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9373 - accuracy: 0.5787 - val_loss: 1.8583 - val_accuracy: 0.0556\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8975 - accuracy: 0.6127 - val_loss: 2.3158 - val_accuracy: 0.0278\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9127 - accuracy: 0.5957 - val_loss: 1.8498 - val_accuracy: 0.2222\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8601 - accuracy: 0.6389 - val_loss: 1.9858 - val_accuracy: 0.0833\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8166 - accuracy: 0.6667 - val_loss: 2.0556 - val_accuracy: 0.0694\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8117 - accuracy: 0.6559 - val_loss: 2.0918 - val_accuracy: 0.0972\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7883 - accuracy: 0.6698 - val_loss: 2.3945 - val_accuracy: 0.0694\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7576 - accuracy: 0.7037 - val_loss: 1.8087 - val_accuracy: 0.1528\n",
      "Epoch 22/300\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7449 - accuracy: 0.6929 - val_loss: 2.1699 - val_accuracy: 0.0972\n",
      "Epoch 23/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7339 - accuracy: 0.7130 - val_loss: 1.7483 - val_accuracy: 0.1944\n",
      "Epoch 24/300\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.6148 - accuracy: 0.7188Restoring model weights from the end of the best epoch: 4.\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7177 - accuracy: 0.7114 - val_loss: 2.2384 - val_accuracy: 0.0833\n",
      "Epoch 24: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 4\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 1.4200 - accuracy: 0.3611 - val_loss: 1.6747 - val_accuracy: 0.0278\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1901 - accuracy: 0.4228 - val_loss: 2.0776 - val_accuracy: 0.0139\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1685 - accuracy: 0.4861 - val_loss: 1.5960 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1323 - accuracy: 0.5093 - val_loss: 1.5648 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1366 - accuracy: 0.4892 - val_loss: 1.7996 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1039 - accuracy: 0.5185 - val_loss: 1.4815 - val_accuracy: 0.2222\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0606 - accuracy: 0.5463 - val_loss: 1.7452 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0571 - accuracy: 0.5448 - val_loss: 1.5081 - val_accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0553 - accuracy: 0.5386 - val_loss: 1.7599 - val_accuracy: 0.0278\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.0446 - accuracy: 0.5540 - val_loss: 2.0507 - val_accuracy: 0.0278\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.0154 - accuracy: 0.5787 - val_loss: 1.6928 - val_accuracy: 0.0278\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9865 - accuracy: 0.5710 - val_loss: 1.7024 - val_accuracy: 0.0417\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0023 - accuracy: 0.5633 - val_loss: 1.8408 - val_accuracy: 0.0556\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9422 - accuracy: 0.6034 - val_loss: 1.8339 - val_accuracy: 0.0417\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9284 - accuracy: 0.6096 - val_loss: 2.0012 - val_accuracy: 0.0139\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9011 - accuracy: 0.6142 - val_loss: 1.6840 - val_accuracy: 0.1806\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8761 - accuracy: 0.6481 - val_loss: 1.9203 - val_accuracy: 0.2500\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8735 - accuracy: 0.6142 - val_loss: 2.5889 - val_accuracy: 0.0139\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8765 - accuracy: 0.6466 - val_loss: 2.1154 - val_accuracy: 0.0139\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8419 - accuracy: 0.6481 - val_loss: 1.9518 - val_accuracy: 0.0694\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8501 - accuracy: 0.6420 - val_loss: 2.5391 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.8093 - accuracy: 0.6698 - val_loss: 2.1870 - val_accuracy: 0.0833\n",
      "Epoch 23/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7752 - accuracy: 0.6759 - val_loss: 2.1515 - val_accuracy: 0.0417\n",
      "Epoch 24/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7451 - accuracy: 0.6960 - val_loss: 3.2087 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7664 - accuracy: 0.6667 - val_loss: 1.6724 - val_accuracy: 0.0833\n",
      "Epoch 26/300\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.7381 - accuracy: 0.7031Restoring model weights from the end of the best epoch: 6.\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7419 - accuracy: 0.7052 - val_loss: 2.2485 - val_accuracy: 0.0278\n",
      "Epoch 26: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "\n",
      "Training fold 5\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 1.3332 - accuracy: 0.3873 - val_loss: 1.5993 - val_accuracy: 0.0139\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2103 - accuracy: 0.4259 - val_loss: 1.5894 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1663 - accuracy: 0.4537 - val_loss: 1.6781 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1570 - accuracy: 0.4630 - val_loss: 1.7337 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.1140 - accuracy: 0.5231 - val_loss: 1.5938 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.1107 - accuracy: 0.5123 - val_loss: 1.8739 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0771 - accuracy: 0.5139 - val_loss: 1.7066 - val_accuracy: 0.0278\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0814 - accuracy: 0.5386 - val_loss: 1.5551 - val_accuracy: 0.0139\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0380 - accuracy: 0.5772 - val_loss: 1.8203 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0187 - accuracy: 0.5664 - val_loss: 1.9681 - val_accuracy: 0.0139\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9899 - accuracy: 0.5710 - val_loss: 1.5811 - val_accuracy: 0.0556\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9595 - accuracy: 0.5802 - val_loss: 2.2559 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9394 - accuracy: 0.6157 - val_loss: 1.6884 - val_accuracy: 0.0694\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9301 - accuracy: 0.5957 - val_loss: 2.0713 - val_accuracy: 0.0139\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9321 - accuracy: 0.6049 - val_loss: 1.6689 - val_accuracy: 0.0278\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8859 - accuracy: 0.6265 - val_loss: 2.0683 - val_accuracy: 0.0139\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8767 - accuracy: 0.6343 - val_loss: 1.8246 - val_accuracy: 0.0417\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8336 - accuracy: 0.6590 - val_loss: 2.1121 - val_accuracy: 0.0417\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8410 - accuracy: 0.6358 - val_loss: 1.7910 - val_accuracy: 0.0417\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8882 - accuracy: 0.6265 - val_loss: 1.8523 - val_accuracy: 0.0972\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8133 - accuracy: 0.6590 - val_loss: 1.7665 - val_accuracy: 0.0833\n",
      "Epoch 22/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8002 - accuracy: 0.6667 - val_loss: 2.3371 - val_accuracy: 0.0139\n",
      "Epoch 23/300\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7407 - accuracy: 0.7145 - val_loss: 1.8070 - val_accuracy: 0.1389\n",
      "Epoch 24/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7420 - accuracy: 0.7068 - val_loss: 1.8544 - val_accuracy: 0.1250\n",
      "Epoch 25/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7604 - accuracy: 0.6806 - val_loss: 2.6472 - val_accuracy: 0.0139\n",
      "Epoch 26/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.7430 - accuracy: 0.6898 - val_loss: 2.0085 - val_accuracy: 0.1806\n",
      "Epoch 27/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6912 - accuracy: 0.7037 - val_loss: 2.8551 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.6508 - accuracy: 0.7344Restoring model weights from the end of the best epoch: 8.\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7053 - accuracy: 0.7083 - val_loss: 2.2063 - val_accuracy: 0.0833\n",
      "Epoch 28: early stopping\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021483E32020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 6\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 1.3226 - accuracy: 0.3997 - val_loss: 2.3953 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2067 - accuracy: 0.4352 - val_loss: 2.0313 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1563 - accuracy: 0.4969 - val_loss: 1.2398 - val_accuracy: 0.5139\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1340 - accuracy: 0.4923 - val_loss: 1.9260 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1002 - accuracy: 0.5015 - val_loss: 1.8911 - val_accuracy: 0.0139\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0921 - accuracy: 0.5139 - val_loss: 1.5878 - val_accuracy: 0.0417\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.1060 - accuracy: 0.5448 - val_loss: 1.5332 - val_accuracy: 0.1806\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0760 - accuracy: 0.4938 - val_loss: 1.7273 - val_accuracy: 0.0139\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0276 - accuracy: 0.5509 - val_loss: 1.7535 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9943 - accuracy: 0.5725 - val_loss: 1.8311 - val_accuracy: 0.0278\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9890 - accuracy: 0.5802 - val_loss: 1.7292 - val_accuracy: 0.1667\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9547 - accuracy: 0.5833 - val_loss: 1.8850 - val_accuracy: 0.0278\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9632 - accuracy: 0.5664 - val_loss: 2.1297 - val_accuracy: 0.0278\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9583 - accuracy: 0.5895 - val_loss: 1.3849 - val_accuracy: 0.4722\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9549 - accuracy: 0.5910 - val_loss: 2.2288 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9198 - accuracy: 0.5926 - val_loss: 1.7769 - val_accuracy: 0.0972\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8777 - accuracy: 0.6265 - val_loss: 1.7628 - val_accuracy: 0.0694\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8559 - accuracy: 0.6358 - val_loss: 2.3828 - val_accuracy: 0.0417\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8297 - accuracy: 0.6667 - val_loss: 1.8004 - val_accuracy: 0.1111\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8395 - accuracy: 0.6466 - val_loss: 1.8257 - val_accuracy: 0.2500\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8144 - accuracy: 0.6420 - val_loss: 1.8772 - val_accuracy: 0.0694\n",
      "Epoch 22/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8202 - accuracy: 0.6466 - val_loss: 2.3210 - val_accuracy: 0.0556\n",
      "Epoch 23/300\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.7569 - accuracy: 0.7031Restoring model weights from the end of the best epoch: 3.\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7602 - accuracy: 0.6790 - val_loss: 1.8147 - val_accuracy: 0.2083\n",
      "Epoch 23: early stopping\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021485014180> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 7\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "11/11 [==============================] - 1s 31ms/step - loss: 1.3033 - accuracy: 0.3735 - val_loss: 1.6925 - val_accuracy: 0.0278\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2093 - accuracy: 0.4198 - val_loss: 2.4723 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.2047 - accuracy: 0.4352 - val_loss: 1.6758 - val_accuracy: 0.0139\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1371 - accuracy: 0.4985 - val_loss: 1.4742 - val_accuracy: 0.0972\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1314 - accuracy: 0.5000 - val_loss: 1.9034 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1201 - accuracy: 0.5015 - val_loss: 1.7675 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0898 - accuracy: 0.5401 - val_loss: 1.8965 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0579 - accuracy: 0.5309 - val_loss: 1.5285 - val_accuracy: 0.0972\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0702 - accuracy: 0.5231 - val_loss: 2.2617 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0117 - accuracy: 0.5694 - val_loss: 1.5399 - val_accuracy: 0.2639\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0151 - accuracy: 0.5756 - val_loss: 2.0706 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0118 - accuracy: 0.5525 - val_loss: 1.7275 - val_accuracy: 0.0556\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9598 - accuracy: 0.5926 - val_loss: 2.7011 - val_accuracy: 0.0139\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9895 - accuracy: 0.5694 - val_loss: 1.5250 - val_accuracy: 0.2778\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9334 - accuracy: 0.5864 - val_loss: 2.2396 - val_accuracy: 0.0139\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8834 - accuracy: 0.6296 - val_loss: 1.7956 - val_accuracy: 0.1389\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8726 - accuracy: 0.6281 - val_loss: 2.1618 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8430 - accuracy: 0.6497 - val_loss: 2.0734 - val_accuracy: 0.0139\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8058 - accuracy: 0.6605 - val_loss: 1.9730 - val_accuracy: 0.0417\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7909 - accuracy: 0.6636 - val_loss: 2.3482 - val_accuracy: 0.0139\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8274 - accuracy: 0.6528 - val_loss: 1.8987 - val_accuracy: 0.0417\n",
      "Epoch 22/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7774 - accuracy: 0.6821 - val_loss: 2.5225 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7657 - accuracy: 0.6944 - val_loss: 2.2742 - val_accuracy: 0.0556\n",
      "Epoch 24/300\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.5940 - accuracy: 0.7969Restoring model weights from the end of the best epoch: 4.\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.7237 - accuracy: 0.6929 - val_loss: 2.7880 - val_accuracy: 0.0000e+00\n",
      "Epoch 24: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 8\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "11/11 [==============================] - 1s 19ms/step - loss: 1.3643 - accuracy: 0.3858 - val_loss: 1.7422 - val_accuracy: 0.0139\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2157 - accuracy: 0.4213 - val_loss: 1.7856 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1752 - accuracy: 0.4660 - val_loss: 1.9685 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1684 - accuracy: 0.4938 - val_loss: 1.3756 - val_accuracy: 0.4861\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1338 - accuracy: 0.4846 - val_loss: 2.0367 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.1136 - accuracy: 0.4985 - val_loss: 1.6503 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0969 - accuracy: 0.5201 - val_loss: 1.5844 - val_accuracy: 0.1111\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0921 - accuracy: 0.4861 - val_loss: 1.9455 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0568 - accuracy: 0.5556 - val_loss: 1.8557 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0308 - accuracy: 0.5463 - val_loss: 1.6515 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0159 - accuracy: 0.5679 - val_loss: 2.3467 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0237 - accuracy: 0.5602 - val_loss: 1.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9923 - accuracy: 0.5694 - val_loss: 1.8552 - val_accuracy: 0.1111\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0154 - accuracy: 0.5633 - val_loss: 1.9020 - val_accuracy: 0.0139\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9721 - accuracy: 0.6080 - val_loss: 1.6095 - val_accuracy: 0.1528\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9272 - accuracy: 0.6142 - val_loss: 2.0524 - val_accuracy: 0.0417\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.9254 - accuracy: 0.6080 - val_loss: 1.8973 - val_accuracy: 0.0278\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9044 - accuracy: 0.6188 - val_loss: 2.1317 - val_accuracy: 0.0694\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8786 - accuracy: 0.6296 - val_loss: 2.1789 - val_accuracy: 0.0417\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9320 - accuracy: 0.6389 - val_loss: 2.0970 - val_accuracy: 0.0694\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8906 - accuracy: 0.6204 - val_loss: 2.2384 - val_accuracy: 0.0278\n",
      "Epoch 22/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8650 - accuracy: 0.6235 - val_loss: 2.3565 - val_accuracy: 0.0139\n",
      "Epoch 23/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8293 - accuracy: 0.6512 - val_loss: 2.3250 - val_accuracy: 0.0694\n",
      "Epoch 24/300\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.8020 - accuracy: 0.6719Restoring model weights from the end of the best epoch: 4.\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8040 - accuracy: 0.6713 - val_loss: 2.5746 - val_accuracy: 0.0694\n",
      "Epoch 24: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "\n",
      "Training fold 9\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 1.2842 - accuracy: 0.4012 - val_loss: 1.4712 - val_accuracy: 0.2361\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1741 - accuracy: 0.4491 - val_loss: 1.9084 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1289 - accuracy: 0.4830 - val_loss: 1.9838 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.1371 - accuracy: 0.4645 - val_loss: 1.9907 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.1514 - accuracy: 0.5046 - val_loss: 1.5833 - val_accuracy: 0.3194\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0749 - accuracy: 0.5247 - val_loss: 1.8618 - val_accuracy: 0.0278\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0658 - accuracy: 0.5170 - val_loss: 1.9081 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0707 - accuracy: 0.5108 - val_loss: 2.0622 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0191 - accuracy: 0.5540 - val_loss: 1.5628 - val_accuracy: 0.5000\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0034 - accuracy: 0.5556 - val_loss: 2.2647 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9855 - accuracy: 0.5602 - val_loss: 1.8817 - val_accuracy: 0.0278\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9674 - accuracy: 0.5926 - val_loss: 1.8163 - val_accuracy: 0.1111\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9439 - accuracy: 0.6003 - val_loss: 1.6209 - val_accuracy: 0.3611\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9266 - accuracy: 0.5849 - val_loss: 2.0479 - val_accuracy: 0.0278\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9221 - accuracy: 0.6049 - val_loss: 2.0528 - val_accuracy: 0.0139\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8793 - accuracy: 0.6204 - val_loss: 1.8489 - val_accuracy: 0.0556\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8375 - accuracy: 0.6466 - val_loss: 1.9184 - val_accuracy: 0.0417\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8347 - accuracy: 0.6420 - val_loss: 2.3316 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7928 - accuracy: 0.6775 - val_loss: 2.0513 - val_accuracy: 0.1389\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.7838 - accuracy: 0.6466 - val_loss: 1.9324 - val_accuracy: 0.0417\n",
      "Epoch 21/300\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.7859 - accuracy: 0.6719Restoring model weights from the end of the best epoch: 1.\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7519 - accuracy: 0.6867 - val_loss: 2.0764 - val_accuracy: 0.1667\n",
      "Epoch 21: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 10\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 1.3334 - accuracy: 0.3951 - val_loss: 1.7653 - val_accuracy: 0.0278\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1726 - accuracy: 0.4537 - val_loss: 1.3834 - val_accuracy: 0.4028\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1546 - accuracy: 0.4614 - val_loss: 2.0611 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.1199 - accuracy: 0.5031 - val_loss: 1.6920 - val_accuracy: 0.0972\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1112 - accuracy: 0.4877 - val_loss: 1.8463 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0820 - accuracy: 0.5154 - val_loss: 2.0971 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1015 - accuracy: 0.5170 - val_loss: 1.7708 - val_accuracy: 0.0139\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0587 - accuracy: 0.5448 - val_loss: 2.0531 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0374 - accuracy: 0.5494 - val_loss: 1.8308 - val_accuracy: 0.0139\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0166 - accuracy: 0.5664 - val_loss: 1.5557 - val_accuracy: 0.3056\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0004 - accuracy: 0.5633 - val_loss: 1.6957 - val_accuracy: 0.0972\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.0079 - accuracy: 0.5694 - val_loss: 2.2432 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9925 - accuracy: 0.5648 - val_loss: 1.5815 - val_accuracy: 0.1528\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9866 - accuracy: 0.5756 - val_loss: 1.5970 - val_accuracy: 0.0833\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9524 - accuracy: 0.5772 - val_loss: 2.3065 - val_accuracy: 0.0278\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9130 - accuracy: 0.6173 - val_loss: 1.9313 - val_accuracy: 0.0833\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8777 - accuracy: 0.6420 - val_loss: 1.8113 - val_accuracy: 0.1389\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8769 - accuracy: 0.6111 - val_loss: 2.5702 - val_accuracy: 0.0139\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8495 - accuracy: 0.6327 - val_loss: 1.6725 - val_accuracy: 0.0972\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8064 - accuracy: 0.6605 - val_loss: 2.2931 - val_accuracy: 0.0694\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7798 - accuracy: 0.6806 - val_loss: 2.1399 - val_accuracy: 0.1389\n",
      "Epoch 22/300\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.7167 - accuracy: 0.7188Restoring model weights from the end of the best epoch: 2.\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.7933 - accuracy: 0.6605 - val_loss: 1.7129 - val_accuracy: 0.1528\n",
      "Epoch 22: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Time taken for training:  00:00:29\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.5861 - Test Accuracy 0.3875\n",
      "Fold 2 - Train Accuracy 0.4583 - Test Accuracy 0.4250\n",
      "Fold 3 - Train Accuracy 0.4597 - Test Accuracy 0.4375\n",
      "Fold 4 - Train Accuracy 0.5181 - Test Accuracy 0.4625\n",
      "Fold 5 - Train Accuracy 0.5181 - Test Accuracy 0.3375\n",
      "Fold 6 - Train Accuracy 0.4792 - Test Accuracy 0.4250\n",
      "Fold 7 - Train Accuracy 0.4750 - Test Accuracy 0.3750\n",
      "Fold 8 - Train Accuracy 0.4722 - Test Accuracy 0.4250\n",
      "Fold 9 - Train Accuracy 0.4444 - Test Accuracy 0.3375\n",
      "Fold 10 - Train Accuracy 0.4417 - Test Accuracy 0.3750\n",
      "\n",
      "Mean Train Accuracy: 0.4853 \n",
      "Mean Test Accuracy: 0.3988 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       200\n",
      "           1       0.25      0.99      0.40       200\n",
      "           2       0.25      0.01      0.01       200\n",
      "           3       0.00      0.00      0.00       200\n",
      "\n",
      "    accuracy                           0.25       800\n",
      "   macro avg       0.12      0.25      0.10       800\n",
      "weighted avg       0.12      0.25      0.10       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_baseline() :\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape = (30,), activation = 'relu', kernel_initializer = \"he_uniform\"))\n",
    "    model.add(Dense(200, activation = 'relu', kernel_initializer = \"he_uniform\"))\n",
    "    model.add(Dense(300, activation = 'relu', kernel_initializer = \"he_uniform\"))\n",
    "    model.add(Dense(200, activation = 'relu', kernel_initializer = \"he_uniform\"))\n",
    "    model.add(Dense(100, activation = 'relu', kernel_initializer = \"he_uniform\"))\n",
    "    model.add(Dense(4, activation = 'softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Defining the number of folds (10 k-Fold).\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "# Train the MLP model and evaluate it.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training...\\n\")\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 20, restore_best_weights = True)\n",
    "\n",
    "train_accuracy_by_fold = []\n",
    "test_accuracy_by_fold = []\n",
    "y_predclass_for_report = []\n",
    "y_testclass_for_report = []\n",
    "history_by_fold = []\n",
    "fold_number = 1\n",
    "for train_index, test_index in skf.split(X_resampled, y_resampled):\n",
    "    print(\"\\nTraining fold {}\".format(fold_number))\n",
    "    X_train_scaled = pt.fit_transform(X_resampled[train_index])\n",
    "    X_test_scaled = pt.transform(X_resampled[test_index])\n",
    "    model = create_baseline()\n",
    "    history = model.fit(X_train_scaled, y_resampled[train_index], validation_split = 0.1,\n",
    "                            epochs = 300, batch_size = 64, verbose = 1, callbacks = [es])\n",
    "    _, train_accuracy = model.evaluate(X_train_scaled, y_resampled[train_index], verbose = 0)\n",
    "    _, test_accuracy = model.evaluate(X_test_scaled, y_resampled[test_index], verbose = 0)\n",
    "    train_accuracy_by_fold.append(train_accuracy)\n",
    "    test_accuracy_by_fold.append(test_accuracy)\n",
    "    y_predclass_for_report.extend(np.argmax(model.predict(X_resampled[test_index]), axis = 1))\n",
    "    y_testclass_for_report.extend(y_resampled[test_index])\n",
    "    history_by_fold.append(history)\n",
    "    fold_number += 1\n",
    "\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show metrics.\n",
    "for i in range(len(train_accuracy_by_fold)):\n",
    "    print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "                            train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "print(\"\\nMean Train Accuracy: {:.4f} \".format(np.mean(train_accuracy_by_fold)))\n",
    "print(\"Mean Test Accuracy: {:.4f} \".format(np.mean(test_accuracy_by_fold)))\n",
    "\n",
    "print(\"\\nEvaluate other metrics:\")\n",
    "print(classification_report(y_testclass_for_report, y_predclass_for_report, zero_division = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19955e88",
   "metadata": {},
   "source": [
    "#### Train a Multilayer Perceptron model and evaluate the metrics.\n",
    "- Layer architecture => Dense (100) + Dense (200) + Dense (300) + Dense (200) + Dense (100) + Dense (4)\n",
    "- Data augmentation (5x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5651b5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "\n",
      "Training fold 1\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 4ms/step - loss: 1.1999 - accuracy: 0.4555 - val_loss: 1.1450 - val_accuracy: 0.4150\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0895 - accuracy: 0.5213 - val_loss: 1.1105 - val_accuracy: 0.4550\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.9912 - accuracy: 0.5689 - val_loss: 1.0318 - val_accuracy: 0.5450\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.8976 - accuracy: 0.6224 - val_loss: 0.9562 - val_accuracy: 0.5650\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.8212 - accuracy: 0.6421 - val_loss: 0.7700 - val_accuracy: 0.7300\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7079 - accuracy: 0.7153 - val_loss: 0.7213 - val_accuracy: 0.6650\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.7229 - val_loss: 0.6500 - val_accuracy: 0.7100\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7724 - val_loss: 0.5350 - val_accuracy: 0.7700\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7905 - val_loss: 0.5050 - val_accuracy: 0.7700\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8029 - val_loss: 0.4442 - val_accuracy: 0.8350\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8226 - val_loss: 0.3947 - val_accuracy: 0.8550\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8468 - val_loss: 0.4071 - val_accuracy: 0.8650\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8574 - val_loss: 0.3461 - val_accuracy: 0.8700\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8521 - val_loss: 0.3838 - val_accuracy: 0.8400\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8521 - val_loss: 0.3376 - val_accuracy: 0.9000\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.8779 - val_loss: 0.3390 - val_accuracy: 0.8750\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8842 - val_loss: 0.3397 - val_accuracy: 0.8800\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.9089 - val_loss: 0.2733 - val_accuracy: 0.8950\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9103 - val_loss: 0.2523 - val_accuracy: 0.9150\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2022 - accuracy: 0.9174 - val_loss: 0.2798 - val_accuracy: 0.8950\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9208 - val_loss: 0.3731 - val_accuracy: 0.9100\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1844 - accuracy: 0.9329 - val_loss: 0.2163 - val_accuracy: 0.9050\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9416 - val_loss: 0.2225 - val_accuracy: 0.9300\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9221 - val_loss: 0.4563 - val_accuracy: 0.8500\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.2331 - accuracy: 0.9105 - val_loss: 0.2478 - val_accuracy: 0.9400\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9318 - val_loss: 0.2622 - val_accuracy: 0.9200\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9392 - val_loss: 0.1918 - val_accuracy: 0.9500\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9526 - val_loss: 0.1968 - val_accuracy: 0.9300\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9442 - val_loss: 0.2108 - val_accuracy: 0.9450\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9576 - val_loss: 0.1943 - val_accuracy: 0.9450\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9634 - val_loss: 0.1800 - val_accuracy: 0.9500\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9595 - val_loss: 0.2100 - val_accuracy: 0.9400\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9621 - val_loss: 0.1871 - val_accuracy: 0.9550\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9566 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.9658 - val_loss: 0.1796 - val_accuracy: 0.9500\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9576 - val_loss: 0.1696 - val_accuracy: 0.9600\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9476 - val_loss: 0.2830 - val_accuracy: 0.9050\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9292 - val_loss: 0.3511 - val_accuracy: 0.8800\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.9429 - val_loss: 0.1785 - val_accuracy: 0.9600\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9611 - val_loss: 0.1452 - val_accuracy: 0.9700\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9724 - val_loss: 0.1715 - val_accuracy: 0.9650\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9747 - val_loss: 0.1402 - val_accuracy: 0.9750\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9753 - val_loss: 0.1556 - val_accuracy: 0.9650\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9684 - val_loss: 0.1551 - val_accuracy: 0.9650\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9634 - val_loss: 0.1276 - val_accuracy: 0.9800\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9826 - val_loss: 0.1159 - val_accuracy: 0.9800\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9753 - val_loss: 0.1191 - val_accuracy: 0.9750\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9639 - val_loss: 0.2394 - val_accuracy: 0.9550\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9447 - val_loss: 0.2614 - val_accuracy: 0.9100\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9495 - val_loss: 0.1477 - val_accuracy: 0.9700\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9826 - val_loss: 0.1165 - val_accuracy: 0.9850\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9616 - val_loss: 0.1681 - val_accuracy: 0.9450\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9726 - val_loss: 0.1289 - val_accuracy: 0.9850\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9761 - val_loss: 0.1377 - val_accuracy: 0.9750\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9829 - val_loss: 0.1307 - val_accuracy: 0.9750\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9829 - val_loss: 0.1678 - val_accuracy: 0.9500\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9845 - val_loss: 0.1228 - val_accuracy: 0.9800\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9745 - val_loss: 0.2272 - val_accuracy: 0.9600\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9753 - val_loss: 0.1225 - val_accuracy: 0.9750\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9868 - val_loss: 0.1276 - val_accuracy: 0.9700\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9705 - val_loss: 0.4118 - val_accuracy: 0.8950\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9424 - val_loss: 0.2632 - val_accuracy: 0.9750\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9689 - val_loss: 0.2163 - val_accuracy: 0.9600\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9779 - val_loss: 0.3720 - val_accuracy: 0.9450\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9837 - val_loss: 0.1723 - val_accuracy: 0.9850\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9845 - val_loss: 0.2001 - val_accuracy: 0.9600\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9861 - val_loss: 0.1664 - val_accuracy: 0.9800\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.1560 - val_accuracy: 0.9800\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9853 - val_loss: 0.2047 - val_accuracy: 0.9750\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9805 - val_loss: 0.1570 - val_accuracy: 0.9950\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9818 - val_loss: 0.1506 - val_accuracy: 0.9800\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9763 - val_loss: 0.2850 - val_accuracy: 0.9300\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9689 - val_loss: 0.2248 - val_accuracy: 0.9500\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 0.2037 - val_accuracy: 0.9550\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9868 - val_loss: 0.1539 - val_accuracy: 0.9850\n",
      "Epoch 76/300\n",
      "49/60 [=======================>......] - ETA: 0s - loss: 0.0239 - accuracy: 0.9917Restoring model weights from the end of the best epoch: 46.\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.1399 - val_accuracy: 0.9850\n",
      "Epoch 76: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "\n",
      "Training fold 2\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_66 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 5ms/step - loss: 1.2061 - accuracy: 0.4534 - val_loss: 1.1976 - val_accuracy: 0.5100\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1.0701 - accuracy: 0.5345 - val_loss: 0.9830 - val_accuracy: 0.5950\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.9718 - accuracy: 0.5932 - val_loss: 0.8956 - val_accuracy: 0.5950\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.8542 - accuracy: 0.6455 - val_loss: 0.7523 - val_accuracy: 0.6600\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.6942 - val_loss: 0.7024 - val_accuracy: 0.6900\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.7182 - val_loss: 0.6668 - val_accuracy: 0.7150\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.7592 - val_loss: 0.5699 - val_accuracy: 0.7450\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7611 - val_loss: 0.5306 - val_accuracy: 0.7600\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8039 - val_loss: 0.4844 - val_accuracy: 0.7500\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8047 - val_loss: 0.4641 - val_accuracy: 0.8100\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8226 - val_loss: 0.4309 - val_accuracy: 0.7600\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8116 - val_loss: 0.4133 - val_accuracy: 0.7850\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8503 - val_loss: 0.4163 - val_accuracy: 0.8100\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8679 - val_loss: 0.3326 - val_accuracy: 0.8600\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8695 - val_loss: 0.3598 - val_accuracy: 0.8600\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8853 - val_loss: 0.3024 - val_accuracy: 0.8600\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8684 - val_loss: 0.3404 - val_accuracy: 0.8550\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9000 - val_loss: 0.4059 - val_accuracy: 0.8400\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.8953 - val_loss: 0.3679 - val_accuracy: 0.8750\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2542 - accuracy: 0.8984 - val_loss: 0.3374 - val_accuracy: 0.8900\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9205 - val_loss: 0.2605 - val_accuracy: 0.9000\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.8958 - val_loss: 0.3155 - val_accuracy: 0.8900\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8734 - val_loss: 0.3462 - val_accuracy: 0.8550\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.9150 - val_loss: 0.2688 - val_accuracy: 0.9200\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9442 - val_loss: 0.2438 - val_accuracy: 0.9000\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9484 - val_loss: 0.1721 - val_accuracy: 0.9400\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9418 - val_loss: 0.2116 - val_accuracy: 0.9150\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1627 - accuracy: 0.9358 - val_loss: 0.1909 - val_accuracy: 0.9400\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.9479 - val_loss: 0.2273 - val_accuracy: 0.9200\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9495 - val_loss: 0.1938 - val_accuracy: 0.9300\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9508 - val_loss: 0.2143 - val_accuracy: 0.9400\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9455 - val_loss: 0.1828 - val_accuracy: 0.9450\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9650 - val_loss: 0.1926 - val_accuracy: 0.9450\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9676 - val_loss: 0.1494 - val_accuracy: 0.9550\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9529 - val_loss: 0.2186 - val_accuracy: 0.9100\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9621 - val_loss: 0.2015 - val_accuracy: 0.9350\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9645 - val_loss: 0.1747 - val_accuracy: 0.9650\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9624 - val_loss: 0.1547 - val_accuracy: 0.9650\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9695 - val_loss: 0.1574 - val_accuracy: 0.9600\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9708 - val_loss: 0.1346 - val_accuracy: 0.9550\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9687 - val_loss: 0.2014 - val_accuracy: 0.9450\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9700 - val_loss: 0.2234 - val_accuracy: 0.9100\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9668 - val_loss: 0.1332 - val_accuracy: 0.9650\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9700 - val_loss: 0.1688 - val_accuracy: 0.9500\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9595 - val_loss: 0.2396 - val_accuracy: 0.9250\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9553 - val_loss: 0.1863 - val_accuracy: 0.9400\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9568 - val_loss: 0.2312 - val_accuracy: 0.9750\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9616 - val_loss: 0.1491 - val_accuracy: 0.9750\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.9466 - val_loss: 0.2649 - val_accuracy: 0.8800\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9482 - val_loss: 0.1237 - val_accuracy: 0.9600\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9758 - val_loss: 0.1414 - val_accuracy: 0.9550\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9855 - val_loss: 0.1251 - val_accuracy: 0.9650\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9842 - val_loss: 0.1162 - val_accuracy: 0.9850\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9792 - val_loss: 0.1186 - val_accuracy: 0.9600\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9816 - val_loss: 0.1421 - val_accuracy: 0.9700\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9776 - val_loss: 0.1289 - val_accuracy: 0.9550\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9729 - val_loss: 0.1559 - val_accuracy: 0.9550\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9803 - val_loss: 0.1131 - val_accuracy: 0.9700\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9868 - val_loss: 0.1181 - val_accuracy: 0.9850\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9726 - val_loss: 0.1550 - val_accuracy: 0.9750\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9650 - val_loss: 0.1482 - val_accuracy: 0.9650\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9563 - val_loss: 0.3136 - val_accuracy: 0.8800\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9684 - val_loss: 0.0922 - val_accuracy: 0.9850\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9889 - val_loss: 0.1037 - val_accuracy: 0.9850\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.0946 - val_accuracy: 0.9900\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9834 - val_loss: 0.1429 - val_accuracy: 0.9650\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9808 - val_loss: 0.0966 - val_accuracy: 0.9850\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9853 - val_loss: 0.1494 - val_accuracy: 0.9600\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.1251 - val_accuracy: 0.9550\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9868 - val_loss: 0.0777 - val_accuracy: 0.9900\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9861 - val_loss: 0.1087 - val_accuracy: 0.9850\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9889 - val_loss: 0.1727 - val_accuracy: 0.9500\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9629 - val_loss: 0.1567 - val_accuracy: 0.9800\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0827 - accuracy: 0.9713 - val_loss: 0.1421 - val_accuracy: 0.9700\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9603 - val_loss: 0.1599 - val_accuracy: 0.9500\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9716 - val_loss: 0.1215 - val_accuracy: 0.9650\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9879 - val_loss: 0.1291 - val_accuracy: 0.9750\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9821 - val_loss: 0.1289 - val_accuracy: 0.9750\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9771 - val_loss: 0.2285 - val_accuracy: 0.9700\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9824 - val_loss: 0.0811 - val_accuracy: 0.9800\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9850 - val_loss: 0.1144 - val_accuracy: 0.9750\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9855 - val_loss: 0.1620 - val_accuracy: 0.9750\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.1242 - val_accuracy: 0.9750\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.1166 - val_accuracy: 0.9800\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9876 - val_loss: 0.1659 - val_accuracy: 0.9800\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 0.1901 - val_accuracy: 0.9600\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.9647 - val_loss: 0.1539 - val_accuracy: 0.9550\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.9689 - val_loss: 0.0826 - val_accuracy: 0.9750\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9847 - val_loss: 0.0931 - val_accuracy: 0.9800\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9818 - val_loss: 0.1297 - val_accuracy: 0.9750\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9787 - val_loss: 0.1104 - val_accuracy: 0.9800\n",
      "Epoch 92/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9861 - val_loss: 0.0925 - val_accuracy: 0.9800\n",
      "Epoch 93/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.1023 - val_accuracy: 0.9900\n",
      "Epoch 94/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9934 - val_loss: 0.1093 - val_accuracy: 0.9850\n",
      "Epoch 95/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0986 - val_accuracy: 0.9850\n",
      "Epoch 96/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9845 - val_loss: 0.0958 - val_accuracy: 0.9850\n",
      "Epoch 97/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9871 - val_loss: 0.0879 - val_accuracy: 0.9950\n",
      "Epoch 98/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.0949 - val_accuracy: 0.9850\n",
      "Epoch 99/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9700 - val_loss: 0.1446 - val_accuracy: 0.9700\n",
      "Epoch 100/300\n",
      "47/60 [======================>.......] - ETA: 0s - loss: 0.0923 - accuracy: 0.9691Restoring model weights from the end of the best epoch: 70.\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9708 - val_loss: 0.1230 - val_accuracy: 0.9650\n",
      "Epoch 100: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "\n",
      "Training fold 3\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 4ms/step - loss: 1.2169 - accuracy: 0.4334 - val_loss: 1.1201 - val_accuracy: 0.4850\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1.1041 - accuracy: 0.5192 - val_loss: 1.0379 - val_accuracy: 0.5250\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0014 - accuracy: 0.5637 - val_loss: 0.9659 - val_accuracy: 0.6000\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.9051 - accuracy: 0.6074 - val_loss: 0.8605 - val_accuracy: 0.5900\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7887 - accuracy: 0.6632 - val_loss: 0.7660 - val_accuracy: 0.6650\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.7092 - val_loss: 0.6870 - val_accuracy: 0.7200\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.7371 - val_loss: 0.6189 - val_accuracy: 0.7550\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7668 - val_loss: 0.5432 - val_accuracy: 0.7650\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7953 - val_loss: 0.4718 - val_accuracy: 0.8150\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8250 - val_loss: 0.4510 - val_accuracy: 0.8150\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8405 - val_loss: 0.3724 - val_accuracy: 0.8500\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8382 - val_loss: 0.4827 - val_accuracy: 0.8550\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8405 - val_loss: 0.4305 - val_accuracy: 0.8450\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8684 - val_loss: 0.3079 - val_accuracy: 0.9150\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8887 - val_loss: 0.2858 - val_accuracy: 0.9050\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8868 - val_loss: 0.2685 - val_accuracy: 0.9200\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9016 - val_loss: 0.3052 - val_accuracy: 0.8900\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.8921 - val_loss: 0.2367 - val_accuracy: 0.9250\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9211 - val_loss: 0.2632 - val_accuracy: 0.9250\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2606 - accuracy: 0.8934 - val_loss: 0.3555 - val_accuracy: 0.8700\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9118 - val_loss: 0.2230 - val_accuracy: 0.9300\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9195 - val_loss: 0.2675 - val_accuracy: 0.9250\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9203 - val_loss: 0.2438 - val_accuracy: 0.9350\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.9326 - val_loss: 0.2626 - val_accuracy: 0.8900\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9345 - val_loss: 0.1764 - val_accuracy: 0.9550\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9339 - val_loss: 0.2021 - val_accuracy: 0.9200\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9408 - val_loss: 0.1827 - val_accuracy: 0.9450\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9453 - val_loss: 0.1494 - val_accuracy: 0.9700\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1277 - accuracy: 0.9476 - val_loss: 0.1775 - val_accuracy: 0.9600\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9482 - val_loss: 0.1474 - val_accuracy: 0.9500\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9561 - val_loss: 0.1744 - val_accuracy: 0.9600\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9545 - val_loss: 0.1937 - val_accuracy: 0.9550\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9555 - val_loss: 0.1603 - val_accuracy: 0.9700\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9595 - val_loss: 0.1461 - val_accuracy: 0.9750\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0954 - accuracy: 0.9626 - val_loss: 0.1332 - val_accuracy: 0.9650\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9697 - val_loss: 0.1549 - val_accuracy: 0.9650\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9800 - val_loss: 0.1602 - val_accuracy: 0.9650\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9787 - val_loss: 0.1353 - val_accuracy: 0.9800\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9811 - val_loss: 0.1239 - val_accuracy: 0.9800\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9774 - val_loss: 0.1145 - val_accuracy: 0.9950\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8776 - val_loss: 0.4762 - val_accuracy: 0.8300\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9179 - val_loss: 0.1441 - val_accuracy: 0.9800\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.9705 - val_loss: 0.1128 - val_accuracy: 0.9800\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 0.9763 - val_loss: 0.1225 - val_accuracy: 0.9750\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.9700 - val_loss: 0.1349 - val_accuracy: 0.9600\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0857 - val_accuracy: 0.9850\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9845 - val_loss: 0.0949 - val_accuracy: 0.9800\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9837 - val_loss: 0.1734 - val_accuracy: 0.9700\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9676 - val_loss: 0.1547 - val_accuracy: 0.9700\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9666 - val_loss: 0.1389 - val_accuracy: 0.9750\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9692 - val_loss: 0.2696 - val_accuracy: 0.9400\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9553 - val_loss: 0.1504 - val_accuracy: 0.9650\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9863 - val_loss: 0.0865 - val_accuracy: 0.9900\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.0812 - val_accuracy: 0.9900\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.0767 - val_accuracy: 0.9950\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9818 - val_loss: 0.0877 - val_accuracy: 0.9850\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9766 - val_loss: 0.1595 - val_accuracy: 0.9550\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9313 - val_loss: 0.1059 - val_accuracy: 0.9700\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9879 - val_loss: 0.0770 - val_accuracy: 0.9900\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9950 - val_loss: 0.0797 - val_accuracy: 0.9900\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9876 - val_loss: 0.0943 - val_accuracy: 0.9950\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9732 - val_loss: 0.0640 - val_accuracy: 0.9900\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 0.0728 - val_accuracy: 0.9900\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.0696 - val_accuracy: 0.9950\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.1051 - val_accuracy: 0.9850\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9624 - val_loss: 0.2471 - val_accuracy: 0.9200\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9521 - val_loss: 0.1597 - val_accuracy: 0.9600\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9724 - val_loss: 0.0960 - val_accuracy: 0.9950\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9868 - val_loss: 0.0987 - val_accuracy: 0.9850\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9839 - val_loss: 0.1063 - val_accuracy: 0.9750\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9826 - val_loss: 0.1767 - val_accuracy: 0.9650\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9853 - val_loss: 0.0724 - val_accuracy: 0.9950\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0649 - val_accuracy: 0.9950\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.0738 - val_accuracy: 0.9950\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.0872 - val_accuracy: 0.9900\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9861 - val_loss: 0.0677 - val_accuracy: 0.9950\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9829 - val_loss: 0.0826 - val_accuracy: 0.9800\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0713 - val_accuracy: 0.9900\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9597 - val_loss: 0.1094 - val_accuracy: 0.9800\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9829 - val_loss: 0.0751 - val_accuracy: 0.9950\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9892 - val_loss: 0.0802 - val_accuracy: 0.9850\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.0710 - val_accuracy: 0.9950\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9853 - val_loss: 0.0955 - val_accuracy: 0.9950\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9845 - val_loss: 0.1500 - val_accuracy: 0.9650\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.0854 - val_accuracy: 0.9850\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.0756 - val_accuracy: 0.9950\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9845 - val_loss: 0.1564 - val_accuracy: 0.9650\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9782 - val_loss: 0.0904 - val_accuracy: 0.9950\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.0876 - val_accuracy: 0.9950\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.0998 - val_accuracy: 0.9900\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0901 - val_accuracy: 0.9950\n",
      "Epoch 92/300\n",
      "47/60 [======================>.......] - ETA: 0s - loss: 0.0092 - accuracy: 0.9967  Restoring model weights from the end of the best epoch: 62.\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.0966 - val_accuracy: 0.9950\n",
      "Epoch 92: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "\n",
      "Training fold 4\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_78 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 5ms/step - loss: 1.2190 - accuracy: 0.4379 - val_loss: 1.1037 - val_accuracy: 0.5100\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1.0783 - accuracy: 0.5147 - val_loss: 1.0148 - val_accuracy: 0.5550\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.9768 - accuracy: 0.5795 - val_loss: 0.8982 - val_accuracy: 0.6200\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.8432 - accuracy: 0.6413 - val_loss: 0.7863 - val_accuracy: 0.6800\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7482 - accuracy: 0.6905 - val_loss: 0.6583 - val_accuracy: 0.7400\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.7118 - val_loss: 0.6493 - val_accuracy: 0.6850\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7371 - val_loss: 0.5942 - val_accuracy: 0.7850\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7792 - val_loss: 0.4590 - val_accuracy: 0.8150\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.8082 - val_loss: 0.4161 - val_accuracy: 0.8350\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8226 - val_loss: 0.4433 - val_accuracy: 0.8250\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8282 - val_loss: 0.4302 - val_accuracy: 0.7950\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8337 - val_loss: 0.3900 - val_accuracy: 0.8400\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8600 - val_loss: 0.3556 - val_accuracy: 0.8500\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8674 - val_loss: 0.3460 - val_accuracy: 0.8750\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.8850 - val_loss: 0.3077 - val_accuracy: 0.8750\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.8934 - val_loss: 0.2283 - val_accuracy: 0.9200\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.8992 - val_loss: 0.2492 - val_accuracy: 0.9200\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9129 - val_loss: 0.1972 - val_accuracy: 0.9450\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9234 - val_loss: 0.1834 - val_accuracy: 0.9400\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1878 - accuracy: 0.9271 - val_loss: 0.1973 - val_accuracy: 0.9350\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9292 - val_loss: 0.1856 - val_accuracy: 0.9400\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9292 - val_loss: 0.2278 - val_accuracy: 0.9300\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.9300 - val_loss: 0.1838 - val_accuracy: 0.9400\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9418 - val_loss: 0.1626 - val_accuracy: 0.9550\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9389 - val_loss: 0.2363 - val_accuracy: 0.9300\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2281 - accuracy: 0.9216 - val_loss: 0.2034 - val_accuracy: 0.9200\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1562 - accuracy: 0.9432 - val_loss: 0.1986 - val_accuracy: 0.9300\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1605 - accuracy: 0.9400 - val_loss: 0.2240 - val_accuracy: 0.9150\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9597 - val_loss: 0.1417 - val_accuracy: 0.9700\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9595 - val_loss: 0.1303 - val_accuracy: 0.9700\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9629 - val_loss: 0.1222 - val_accuracy: 0.9700\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.9679 - val_loss: 0.1030 - val_accuracy: 0.9750\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9711 - val_loss: 0.1397 - val_accuracy: 0.9450\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9324 - val_loss: 0.2202 - val_accuracy: 0.9050\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9516 - val_loss: 0.1017 - val_accuracy: 0.9700\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9555 - val_loss: 0.1825 - val_accuracy: 0.9350\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9737 - val_loss: 0.0782 - val_accuracy: 0.9900\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9676 - val_loss: 0.1951 - val_accuracy: 0.9300\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9661 - val_loss: 0.1274 - val_accuracy: 0.9700\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9795 - val_loss: 0.0974 - val_accuracy: 0.9750\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9795 - val_loss: 0.1252 - val_accuracy: 0.9750\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9661 - val_loss: 0.1743 - val_accuracy: 0.9450\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9555 - val_loss: 0.4700 - val_accuracy: 0.8800\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9550 - val_loss: 0.1441 - val_accuracy: 0.9700\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9853 - val_loss: 0.0825 - val_accuracy: 0.9800\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9784 - val_loss: 0.1923 - val_accuracy: 0.9400\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9871 - val_loss: 0.1252 - val_accuracy: 0.9700\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9779 - val_loss: 0.0957 - val_accuracy: 0.9900\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9858 - val_loss: 0.0772 - val_accuracy: 0.9850\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.0837 - val_accuracy: 0.9900\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9879 - val_loss: 0.1080 - val_accuracy: 0.9800\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9821 - val_loss: 0.0978 - val_accuracy: 0.9850\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9774 - val_loss: 0.0906 - val_accuracy: 0.9850\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9763 - val_loss: 0.0933 - val_accuracy: 0.9800\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9811 - val_loss: 0.1411 - val_accuracy: 0.9700\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.9403 - val_loss: 0.2314 - val_accuracy: 0.9400\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9587 - val_loss: 0.0812 - val_accuracy: 0.9750\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9900 - val_loss: 0.0891 - val_accuracy: 0.9900\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9839 - val_loss: 0.1476 - val_accuracy: 0.9700\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9842 - val_loss: 0.1131 - val_accuracy: 0.9800\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.0720 - val_accuracy: 0.9900\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9897 - val_loss: 0.0849 - val_accuracy: 0.9850\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9813 - val_loss: 0.0958 - val_accuracy: 0.9850\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9853 - val_loss: 0.1122 - val_accuracy: 0.9950\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9882 - val_loss: 0.1161 - val_accuracy: 0.9750\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9526 - val_loss: 0.1383 - val_accuracy: 0.9700\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0930 - accuracy: 0.9711 - val_loss: 0.1313 - val_accuracy: 0.9700\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9861 - val_loss: 0.1357 - val_accuracy: 0.9550\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9782 - val_loss: 0.0907 - val_accuracy: 0.9900\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.1082 - val_accuracy: 0.9850\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 0.0968 - val_accuracy: 0.9950\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9808 - val_loss: 0.1699 - val_accuracy: 0.9500\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9737 - val_loss: 0.0737 - val_accuracy: 0.9900\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9829 - val_loss: 0.1084 - val_accuracy: 0.9750\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 0.0811 - val_accuracy: 0.9950\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9832 - val_loss: 0.0598 - val_accuracy: 0.9950\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0768 - accuracy: 0.9739 - val_loss: 0.0830 - val_accuracy: 0.9850\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.0677 - val_accuracy: 0.9950\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9918 - val_loss: 0.0781 - val_accuracy: 0.9900\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9918 - val_loss: 0.0725 - val_accuracy: 0.9950\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9858 - val_loss: 0.1084 - val_accuracy: 0.9900\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9818 - val_loss: 0.1980 - val_accuracy: 0.9400\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9650 - val_loss: 0.0848 - val_accuracy: 0.9800\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0651 - val_accuracy: 0.9850\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9747 - val_loss: 0.1477 - val_accuracy: 0.9450\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9650 - val_loss: 0.0698 - val_accuracy: 0.9900\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9826 - val_loss: 0.1171 - val_accuracy: 0.9850\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 0.0489 - val_accuracy: 0.9950\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9924 - val_loss: 0.0570 - val_accuracy: 0.9950\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0604 - val_accuracy: 0.9850\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0671 - val_accuracy: 0.9950\n",
      "Epoch 92/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9861 - val_loss: 0.0646 - val_accuracy: 0.9950\n",
      "Epoch 93/300\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0736 - accuracy: 0.9750 - val_loss: 0.1483 - val_accuracy: 0.9500\n",
      "Epoch 94/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9782 - val_loss: 0.0826 - val_accuracy: 0.9950\n",
      "Epoch 95/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.0745 - val_accuracy: 0.9950\n",
      "Epoch 96/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9892 - val_loss: 0.1425 - val_accuracy: 0.9700\n",
      "Epoch 97/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9842 - val_loss: 0.0949 - val_accuracy: 0.9800\n",
      "Epoch 98/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9800 - val_loss: 0.1094 - val_accuracy: 0.9750\n",
      "Epoch 99/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 0.0629 - val_accuracy: 0.9900\n",
      "Epoch 100/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.0695 - val_accuracy: 0.9900\n",
      "Epoch 101/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.0735 - val_accuracy: 0.9950\n",
      "Epoch 102/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9918 - val_loss: 0.0972 - val_accuracy: 0.9900\n",
      "Epoch 103/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9837 - val_loss: 0.0890 - val_accuracy: 0.9850\n",
      "Epoch 104/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 0.1263 - val_accuracy: 0.9900\n",
      "Epoch 105/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9932 - val_loss: 0.0686 - val_accuracy: 0.9950\n",
      "Epoch 106/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9816 - val_loss: 0.0995 - val_accuracy: 0.9750\n",
      "Epoch 107/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9721 - val_loss: 0.1421 - val_accuracy: 0.9600\n",
      "Epoch 108/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9803 - val_loss: 0.1190 - val_accuracy: 0.9900\n",
      "Epoch 109/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.0935 - val_accuracy: 0.9950\n",
      "Epoch 110/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.1081 - val_accuracy: 0.9850\n",
      "Epoch 111/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.0880 - val_accuracy: 0.9950\n",
      "Epoch 112/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0946 - val_accuracy: 0.9950\n",
      "Epoch 113/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.0940 - val_accuracy: 0.9950\n",
      "Epoch 114/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1294 - accuracy: 0.9592 - val_loss: 0.1638 - val_accuracy: 0.9700\n",
      "Epoch 115/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9774 - val_loss: 0.1494 - val_accuracy: 0.9800\n",
      "Epoch 116/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9897 - val_loss: 0.1041 - val_accuracy: 0.9750\n",
      "Epoch 117/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9926 - val_loss: 0.0610 - val_accuracy: 0.9950\n",
      "Epoch 118/300\n",
      "49/60 [=======================>......] - ETA: 0s - loss: 0.0183 - accuracy: 0.9933Restoring model weights from the end of the best epoch: 88.\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.0661 - val_accuracy: 0.9950\n",
      "Epoch 118: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 5\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 5ms/step - loss: 1.1710 - accuracy: 0.4416 - val_loss: 1.0943 - val_accuracy: 0.5650\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1.0381 - accuracy: 0.5529 - val_loss: 1.0082 - val_accuracy: 0.5650\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.9171 - accuracy: 0.6055 - val_loss: 0.8925 - val_accuracy: 0.6000\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7879 - accuracy: 0.6658 - val_loss: 0.7821 - val_accuracy: 0.6400\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7015 - accuracy: 0.7021 - val_loss: 0.6918 - val_accuracy: 0.6900\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.7371 - val_loss: 0.5870 - val_accuracy: 0.7400\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7703 - val_loss: 0.5930 - val_accuracy: 0.7500\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7913 - val_loss: 0.5266 - val_accuracy: 0.7600\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.8039 - val_loss: 0.4336 - val_accuracy: 0.8400\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8403 - val_loss: 0.3995 - val_accuracy: 0.8250\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8287 - val_loss: 0.4315 - val_accuracy: 0.8400\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8566 - val_loss: 0.3619 - val_accuracy: 0.8600\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8729 - val_loss: 0.3184 - val_accuracy: 0.8550\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8658 - val_loss: 0.3449 - val_accuracy: 0.8600\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8792 - val_loss: 0.2950 - val_accuracy: 0.9100\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.8984 - val_loss: 0.2523 - val_accuracy: 0.9100\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2386 - accuracy: 0.9013 - val_loss: 0.2426 - val_accuracy: 0.9300\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9089 - val_loss: 0.2599 - val_accuracy: 0.8950\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1959 - accuracy: 0.9187 - val_loss: 0.2260 - val_accuracy: 0.9150\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1768 - accuracy: 0.9239 - val_loss: 0.2487 - val_accuracy: 0.8950\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9308 - val_loss: 0.2236 - val_accuracy: 0.9300\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1728 - accuracy: 0.9245 - val_loss: 0.3034 - val_accuracy: 0.9100\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9095 - val_loss: 0.2084 - val_accuracy: 0.9200\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1973 - accuracy: 0.9239 - val_loss: 0.3038 - val_accuracy: 0.8900\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1868 - accuracy: 0.9158 - val_loss: 0.2132 - val_accuracy: 0.9400\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9439 - val_loss: 0.1823 - val_accuracy: 0.9350\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1278 - accuracy: 0.9426 - val_loss: 0.1741 - val_accuracy: 0.9250\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9484 - val_loss: 0.1720 - val_accuracy: 0.9400\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9489 - val_loss: 0.2457 - val_accuracy: 0.8900\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9521 - val_loss: 0.2069 - val_accuracy: 0.9350\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9371 - val_loss: 0.2441 - val_accuracy: 0.9300\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9342 - val_loss: 0.2035 - val_accuracy: 0.9550\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9676 - val_loss: 0.1420 - val_accuracy: 0.9700\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9689 - val_loss: 0.1675 - val_accuracy: 0.9500\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9700 - val_loss: 0.1421 - val_accuracy: 0.9600\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9674 - val_loss: 0.1713 - val_accuracy: 0.9600\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9705 - val_loss: 0.1869 - val_accuracy: 0.9500\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9576 - val_loss: 0.1806 - val_accuracy: 0.9550\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9608 - val_loss: 0.1419 - val_accuracy: 0.9650\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9753 - val_loss: 0.1392 - val_accuracy: 0.9700\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9705 - val_loss: 0.1583 - val_accuracy: 0.9350\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9705 - val_loss: 0.1386 - val_accuracy: 0.9750\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9705 - val_loss: 0.1689 - val_accuracy: 0.9700\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9689 - val_loss: 0.1509 - val_accuracy: 0.9600\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9655 - val_loss: 0.2184 - val_accuracy: 0.9400\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9611 - val_loss: 0.1218 - val_accuracy: 0.9650\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9753 - val_loss: 0.1409 - val_accuracy: 0.9600\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9789 - val_loss: 0.1196 - val_accuracy: 0.9850\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9824 - val_loss: 0.1362 - val_accuracy: 0.9800\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9734 - val_loss: 0.1118 - val_accuracy: 0.9850\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9834 - val_loss: 0.1102 - val_accuracy: 0.9950\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9792 - val_loss: 0.1188 - val_accuracy: 0.9850\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9797 - val_loss: 0.1076 - val_accuracy: 0.9900\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9684 - val_loss: 0.1593 - val_accuracy: 0.9650\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1104 - accuracy: 0.9676 - val_loss: 0.1789 - val_accuracy: 0.9550\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.9655 - val_loss: 0.0815 - val_accuracy: 0.9950\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9863 - val_loss: 0.0884 - val_accuracy: 0.9950\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9766 - val_loss: 0.1186 - val_accuracy: 0.9900\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9895 - val_loss: 0.0987 - val_accuracy: 0.9900\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9871 - val_loss: 0.1406 - val_accuracy: 0.9700\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9821 - val_loss: 0.1526 - val_accuracy: 0.9600\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9768 - val_loss: 0.1141 - val_accuracy: 0.9900\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9821 - val_loss: 0.1973 - val_accuracy: 0.9500\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.9584 - val_loss: 0.2177 - val_accuracy: 0.9350\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9808 - val_loss: 0.1201 - val_accuracy: 0.9800\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9745 - val_loss: 0.1107 - val_accuracy: 0.9800\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9863 - val_loss: 0.1302 - val_accuracy: 0.9700\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.1081 - val_accuracy: 0.9850\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 0.1586 - val_accuracy: 0.9700\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9734 - val_loss: 0.1262 - val_accuracy: 0.9750\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9818 - val_loss: 0.0959 - val_accuracy: 0.9800\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9579 - val_loss: 0.1320 - val_accuracy: 0.9500\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9782 - val_loss: 0.1265 - val_accuracy: 0.9850\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9918 - val_loss: 0.1087 - val_accuracy: 0.9900\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9845 - val_loss: 0.1171 - val_accuracy: 0.9850\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.1154 - val_accuracy: 0.9850\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.9834 - val_loss: 0.1456 - val_accuracy: 0.9650\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9842 - val_loss: 0.1226 - val_accuracy: 0.9700\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9882 - val_loss: 0.1359 - val_accuracy: 0.9800\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9866 - val_loss: 0.1304 - val_accuracy: 0.9700\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9861 - val_loss: 0.1071 - val_accuracy: 0.9900\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9889 - val_loss: 0.1148 - val_accuracy: 0.9850\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9853 - val_loss: 0.0917 - val_accuracy: 0.9900\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 0.1243 - val_accuracy: 0.9700\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9861 - val_loss: 0.1096 - val_accuracy: 0.9850\n",
      "Epoch 86/300\n",
      "46/60 [======================>.......] - ETA: 0s - loss: 0.0204 - accuracy: 0.9939Restoring model weights from the end of the best epoch: 56.\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 0.2962 - val_accuracy: 0.9250\n",
      "Epoch 86: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 6\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 5ms/step - loss: 1.2235 - accuracy: 0.4305 - val_loss: 1.1090 - val_accuracy: 0.4950\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1.0831 - accuracy: 0.5147 - val_loss: 1.0447 - val_accuracy: 0.5300\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.9733 - accuracy: 0.5755 - val_loss: 0.9138 - val_accuracy: 0.5850\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.8720 - accuracy: 0.6303 - val_loss: 0.8072 - val_accuracy: 0.6800\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7581 - accuracy: 0.6747 - val_loss: 0.7401 - val_accuracy: 0.7050\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.7189 - val_loss: 0.5961 - val_accuracy: 0.7750\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7611 - val_loss: 0.5615 - val_accuracy: 0.7850\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7808 - val_loss: 0.5012 - val_accuracy: 0.8200\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8053 - val_loss: 0.4906 - val_accuracy: 0.8050\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.8003 - val_loss: 0.4410 - val_accuracy: 0.8500\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8316 - val_loss: 0.3860 - val_accuracy: 0.8400\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8366 - val_loss: 0.3807 - val_accuracy: 0.8500\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8466 - val_loss: 0.3745 - val_accuracy: 0.8650\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8621 - val_loss: 0.3348 - val_accuracy: 0.8650\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8632 - val_loss: 0.3279 - val_accuracy: 0.8550\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8711 - val_loss: 0.3100 - val_accuracy: 0.8700\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.8805 - val_loss: 0.2931 - val_accuracy: 0.8950\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.8966 - val_loss: 0.2480 - val_accuracy: 0.9050\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9084 - val_loss: 0.2257 - val_accuracy: 0.9200\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2000 - accuracy: 0.9147 - val_loss: 0.2122 - val_accuracy: 0.9200\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9250 - val_loss: 0.2236 - val_accuracy: 0.9100\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.8966 - val_loss: 0.1875 - val_accuracy: 0.9500\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9105 - val_loss: 0.1887 - val_accuracy: 0.9350\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9284 - val_loss: 0.1974 - val_accuracy: 0.9000\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9337 - val_loss: 0.1402 - val_accuracy: 0.9450\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.9239 - val_loss: 0.1819 - val_accuracy: 0.9250\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1623 - accuracy: 0.9429 - val_loss: 0.1234 - val_accuracy: 0.9400\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9466 - val_loss: 0.1026 - val_accuracy: 0.9600\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9447 - val_loss: 0.1581 - val_accuracy: 0.9500\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9347 - val_loss: 0.1116 - val_accuracy: 0.9600\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9450 - val_loss: 0.1346 - val_accuracy: 0.9450\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9503 - val_loss: 0.0910 - val_accuracy: 0.9700\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9571 - val_loss: 0.0954 - val_accuracy: 0.9600\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9650 - val_loss: 0.0715 - val_accuracy: 0.9750\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1795 - accuracy: 0.9374 - val_loss: 0.2833 - val_accuracy: 0.8700\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9453 - val_loss: 0.0928 - val_accuracy: 0.9550\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0973 - accuracy: 0.9645 - val_loss: 0.2560 - val_accuracy: 0.9000\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9408 - val_loss: 0.1316 - val_accuracy: 0.9450\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9397 - val_loss: 0.0837 - val_accuracy: 0.9700\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.9668 - val_loss: 0.0446 - val_accuracy: 0.9850\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.9724 - val_loss: 0.0460 - val_accuracy: 0.9800\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9774 - val_loss: 0.0485 - val_accuracy: 0.9750\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.9582 - val_loss: 0.0781 - val_accuracy: 0.9750\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9703 - val_loss: 0.0609 - val_accuracy: 0.9750\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9584 - val_loss: 0.1362 - val_accuracy: 0.9550\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9729 - val_loss: 0.0930 - val_accuracy: 0.9700\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9592 - val_loss: 0.2793 - val_accuracy: 0.9150\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2120 - accuracy: 0.9276 - val_loss: 0.0896 - val_accuracy: 0.9850\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1081 - accuracy: 0.9613 - val_loss: 0.0593 - val_accuracy: 0.9800\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9795 - val_loss: 0.0470 - val_accuracy: 0.9850\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9795 - val_loss: 0.0693 - val_accuracy: 0.9850\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9739 - val_loss: 0.0382 - val_accuracy: 0.9950\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9792 - val_loss: 0.0325 - val_accuracy: 0.9950\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.9579 - val_loss: 0.0573 - val_accuracy: 0.9950\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.9642 - val_loss: 0.0615 - val_accuracy: 0.9850\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9676 - val_loss: 0.0562 - val_accuracy: 0.9850\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9792 - val_loss: 0.0397 - val_accuracy: 0.9800\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9761 - val_loss: 0.0406 - val_accuracy: 0.9900\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9800 - val_loss: 0.0446 - val_accuracy: 0.9900\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9818 - val_loss: 0.0222 - val_accuracy: 0.9950\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9847 - val_loss: 0.0159 - val_accuracy: 0.9950\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9897 - val_loss: 0.0246 - val_accuracy: 0.9850\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9850 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9779 - val_loss: 0.0329 - val_accuracy: 0.9900\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9816 - val_loss: 0.0250 - val_accuracy: 0.9950\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9750 - val_loss: 0.1279 - val_accuracy: 0.9550\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9574 - val_loss: 0.0700 - val_accuracy: 0.9750\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9739 - val_loss: 0.0639 - val_accuracy: 0.9800\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9747 - val_loss: 0.0312 - val_accuracy: 0.9850\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9879 - val_loss: 0.0184 - val_accuracy: 0.9900\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9845 - val_loss: 0.0341 - val_accuracy: 0.9900\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9808 - val_loss: 0.0856 - val_accuracy: 0.9600\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.9805 - val_loss: 0.0366 - val_accuracy: 0.9800\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9839 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9905 - val_loss: 0.0179 - val_accuracy: 0.9900\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 0.0259 - val_accuracy: 0.9900\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9832 - val_loss: 0.0217 - val_accuracy: 0.9950\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9866 - val_loss: 0.0476 - val_accuracy: 0.9850\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9834 - val_loss: 0.0284 - val_accuracy: 0.9900\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 0.0654 - val_accuracy: 0.9800\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0943 - accuracy: 0.9676 - val_loss: 0.0278 - val_accuracy: 0.9900\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9776 - val_loss: 0.0733 - val_accuracy: 0.9650\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9747 - val_loss: 0.0566 - val_accuracy: 0.9850\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9779 - val_loss: 0.0573 - val_accuracy: 0.9800\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1340 - accuracy: 0.9584 - val_loss: 0.0560 - val_accuracy: 0.9900\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9745 - val_loss: 0.0376 - val_accuracy: 0.9950\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9613 - val_loss: 0.0355 - val_accuracy: 0.9850\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.0192 - val_accuracy: 0.9950\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.0283 - val_accuracy: 0.9900\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.0163 - val_accuracy: 0.9900\n",
      "Epoch 91/300\n",
      "47/60 [======================>.......] - ETA: 0s - loss: 0.0549 - accuracy: 0.9820Restoring model weights from the end of the best epoch: 61.\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0751 - accuracy: 0.9784 - val_loss: 0.1315 - val_accuracy: 0.9650\n",
      "Epoch 91: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "\n",
      "Training fold 7\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_96 (Dense)            (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 5ms/step - loss: 1.2106 - accuracy: 0.4426 - val_loss: 1.1142 - val_accuracy: 0.4700\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.0573 - accuracy: 0.5247 - val_loss: 1.0172 - val_accuracy: 0.5050\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.9414 - accuracy: 0.5900 - val_loss: 0.8921 - val_accuracy: 0.6150\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.8251 - accuracy: 0.6489 - val_loss: 0.7491 - val_accuracy: 0.7050\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7278 - accuracy: 0.6900 - val_loss: 0.6959 - val_accuracy: 0.7300\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.7363 - val_loss: 0.6344 - val_accuracy: 0.7500\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7668 - val_loss: 0.5614 - val_accuracy: 0.7700\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7747 - val_loss: 0.5215 - val_accuracy: 0.7800\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8095 - val_loss: 0.4748 - val_accuracy: 0.8200\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8113 - val_loss: 0.4121 - val_accuracy: 0.8500\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8366 - val_loss: 0.3964 - val_accuracy: 0.8400\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8658 - val_loss: 0.3749 - val_accuracy: 0.8450\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8800 - val_loss: 0.3769 - val_accuracy: 0.8400\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8824 - val_loss: 0.2902 - val_accuracy: 0.8950\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2954 - accuracy: 0.8837 - val_loss: 0.3438 - val_accuracy: 0.8650\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.8903 - val_loss: 0.3669 - val_accuracy: 0.8300\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.9068 - val_loss: 0.3214 - val_accuracy: 0.8600\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1965 - accuracy: 0.9263 - val_loss: 0.2797 - val_accuracy: 0.9100\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2096 - accuracy: 0.9213 - val_loss: 0.3228 - val_accuracy: 0.8700\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8758 - val_loss: 0.2688 - val_accuracy: 0.9050\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1853 - accuracy: 0.9274 - val_loss: 0.2271 - val_accuracy: 0.9150\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9413 - val_loss: 0.2598 - val_accuracy: 0.9100\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9437 - val_loss: 0.2645 - val_accuracy: 0.8950\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9503 - val_loss: 0.2864 - val_accuracy: 0.8950\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9337 - val_loss: 0.2312 - val_accuracy: 0.9300\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9295 - val_loss: 0.2668 - val_accuracy: 0.9050\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1671 - accuracy: 0.9387 - val_loss: 0.2388 - val_accuracy: 0.9150\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9600 - val_loss: 0.1695 - val_accuracy: 0.9400\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9639 - val_loss: 0.2297 - val_accuracy: 0.9400\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1711 - accuracy: 0.9374 - val_loss: 0.1824 - val_accuracy: 0.9300\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9605 - val_loss: 0.2517 - val_accuracy: 0.9250\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9616 - val_loss: 0.1280 - val_accuracy: 0.9600\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9761 - val_loss: 0.1624 - val_accuracy: 0.9650\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9679 - val_loss: 0.1398 - val_accuracy: 0.9550\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9739 - val_loss: 0.1831 - val_accuracy: 0.9500\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9555 - val_loss: 0.2806 - val_accuracy: 0.9200\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9508 - val_loss: 0.2385 - val_accuracy: 0.9300\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9634 - val_loss: 0.3861 - val_accuracy: 0.9050\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9587 - val_loss: 0.1780 - val_accuracy: 0.9450\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.9497 - val_loss: 0.1796 - val_accuracy: 0.9350\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9532 - val_loss: 0.1446 - val_accuracy: 0.9450\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 0.9734 - val_loss: 0.1471 - val_accuracy: 0.9550\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1018 - accuracy: 0.9658 - val_loss: 0.1724 - val_accuracy: 0.9200\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9745 - val_loss: 0.1436 - val_accuracy: 0.9500\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9800 - val_loss: 0.1345 - val_accuracy: 0.9600\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9771 - val_loss: 0.1138 - val_accuracy: 0.9750\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9800 - val_loss: 0.1118 - val_accuracy: 0.9500\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 0.9613 - val_loss: 0.2405 - val_accuracy: 0.9200\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9671 - val_loss: 0.1091 - val_accuracy: 0.9750\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9824 - val_loss: 0.1305 - val_accuracy: 0.9600\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.9747 - val_loss: 0.1269 - val_accuracy: 0.9800\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9845 - val_loss: 0.0801 - val_accuracy: 0.9800\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9874 - val_loss: 0.1110 - val_accuracy: 0.9800\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9789 - val_loss: 0.1273 - val_accuracy: 0.9550\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9821 - val_loss: 0.1445 - val_accuracy: 0.9650\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9405 - val_loss: 0.2225 - val_accuracy: 0.9350\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9650 - val_loss: 0.1704 - val_accuracy: 0.9550\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9766 - val_loss: 0.1154 - val_accuracy: 0.9850\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9874 - val_loss: 0.1058 - val_accuracy: 0.9900\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.1072 - val_accuracy: 0.9900\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9892 - val_loss: 0.1022 - val_accuracy: 0.9850\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9805 - val_loss: 0.1388 - val_accuracy: 0.9650\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9789 - val_loss: 0.1256 - val_accuracy: 0.9750\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9834 - val_loss: 0.0920 - val_accuracy: 0.9900\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9874 - val_loss: 0.1063 - val_accuracy: 0.9850\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 0.1145 - val_accuracy: 0.9700\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9768 - val_loss: 0.1979 - val_accuracy: 0.9350\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9816 - val_loss: 0.1304 - val_accuracy: 0.9700\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9784 - val_loss: 0.1636 - val_accuracy: 0.9550\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9839 - val_loss: 0.1216 - val_accuracy: 0.9850\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9782 - val_loss: 0.1367 - val_accuracy: 0.9800\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9853 - val_loss: 0.0834 - val_accuracy: 0.9900\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9905 - val_loss: 0.0810 - val_accuracy: 0.9850\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9821 - val_loss: 0.1189 - val_accuracy: 0.9700\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9821 - val_loss: 0.1751 - val_accuracy: 0.9600\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9784 - val_loss: 0.0791 - val_accuracy: 0.9850\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9750 - val_loss: 0.1771 - val_accuracy: 0.9600\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1887 - accuracy: 0.9453 - val_loss: 0.1475 - val_accuracy: 0.9450\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9811 - val_loss: 0.0751 - val_accuracy: 0.9900\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 0.1083 - val_accuracy: 0.9700\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.0873 - val_accuracy: 0.9850\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9908 - val_loss: 0.0869 - val_accuracy: 0.9900\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.0926 - val_accuracy: 0.9900\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9924 - val_loss: 0.0830 - val_accuracy: 0.9900\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.0955 - val_accuracy: 0.9900\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9913 - val_loss: 0.0983 - val_accuracy: 0.9850\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9913 - val_loss: 0.0922 - val_accuracy: 0.9900\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9937 - val_loss: 0.1003 - val_accuracy: 0.9900\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9884 - val_loss: 0.2757 - val_accuracy: 0.9300\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0901 - accuracy: 0.9705 - val_loss: 0.1207 - val_accuracy: 0.9750\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9895 - val_loss: 0.1138 - val_accuracy: 0.9800\n",
      "Epoch 92/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.1198 - val_accuracy: 0.9850\n",
      "Epoch 93/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9716 - val_loss: 0.1865 - val_accuracy: 0.9400\n",
      "Epoch 94/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9566 - val_loss: 0.0756 - val_accuracy: 0.9850\n",
      "Epoch 95/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.0787 - val_accuracy: 0.9750\n",
      "Epoch 96/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9821 - val_loss: 0.1576 - val_accuracy: 0.9600\n",
      "Epoch 97/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9595 - val_loss: 0.1186 - val_accuracy: 0.9700\n",
      "Epoch 98/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9800 - val_loss: 0.0876 - val_accuracy: 0.9850\n",
      "Epoch 99/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9879 - val_loss: 0.0929 - val_accuracy: 0.9750\n",
      "Epoch 100/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 0.0990 - val_accuracy: 0.9850\n",
      "Epoch 101/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9945 - val_loss: 0.0772 - val_accuracy: 0.9950\n",
      "Epoch 102/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9926 - val_loss: 0.1289 - val_accuracy: 0.9700\n",
      "Epoch 103/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9703 - val_loss: 0.1111 - val_accuracy: 0.9650\n",
      "Epoch 104/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9750 - val_loss: 0.1324 - val_accuracy: 0.9800\n",
      "Epoch 105/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9834 - val_loss: 0.0963 - val_accuracy: 0.9850\n",
      "Epoch 106/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 0.0669 - val_accuracy: 0.9900\n",
      "Epoch 107/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.0698 - val_accuracy: 0.9900\n",
      "Epoch 108/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0835 - val_accuracy: 0.9850\n",
      "Epoch 109/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.0810 - val_accuracy: 0.9900\n",
      "Epoch 110/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 0.0857 - val_accuracy: 0.9900\n",
      "Epoch 111/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 0.1116 - val_accuracy: 0.9800\n",
      "Epoch 112/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.1167 - val_accuracy: 0.9800\n",
      "Epoch 113/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9895 - val_loss: 0.1292 - val_accuracy: 0.9750\n",
      "Epoch 114/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9868 - val_loss: 0.1438 - val_accuracy: 0.9750\n",
      "Epoch 115/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9739 - val_loss: 0.2254 - val_accuracy: 0.9150\n",
      "Epoch 116/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1110 - accuracy: 0.9592 - val_loss: 0.1384 - val_accuracy: 0.9600\n",
      "Epoch 117/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9832 - val_loss: 0.1114 - val_accuracy: 0.9750\n",
      "Epoch 118/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9839 - val_loss: 0.0941 - val_accuracy: 0.9850\n",
      "Epoch 119/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.0930 - val_accuracy: 0.9900\n",
      "Epoch 120/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.0985 - val_accuracy: 0.9900\n",
      "Epoch 121/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.1255 - val_accuracy: 0.9800\n",
      "Epoch 122/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.1044 - val_accuracy: 0.9950\n",
      "Epoch 123/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9955 - val_loss: 0.0977 - val_accuracy: 0.9950\n",
      "Epoch 124/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.1098 - val_accuracy: 0.9850\n",
      "Epoch 125/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 0.1174 - val_accuracy: 0.9850\n",
      "Epoch 126/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 0.1168 - val_accuracy: 0.9800\n",
      "Epoch 127/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9634 - val_loss: 0.0842 - val_accuracy: 0.9750\n",
      "Epoch 128/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9803 - val_loss: 0.0661 - val_accuracy: 0.9850\n",
      "Epoch 129/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9847 - val_loss: 0.0977 - val_accuracy: 0.9850\n",
      "Epoch 130/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.0788 - val_accuracy: 0.9950\n",
      "Epoch 131/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0819 - val_accuracy: 0.9950\n",
      "Epoch 132/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9816 - val_loss: 0.0983 - val_accuracy: 0.9800\n",
      "Epoch 133/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9818 - val_loss: 0.1670 - val_accuracy: 0.9700\n",
      "Epoch 134/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9763 - val_loss: 0.1235 - val_accuracy: 0.9750\n",
      "Epoch 135/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9884 - val_loss: 0.0665 - val_accuracy: 0.9900\n",
      "Epoch 136/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9939 - val_loss: 0.0670 - val_accuracy: 0.9900\n",
      "Epoch 137/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0802 - val_accuracy: 0.9900\n",
      "Epoch 138/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.1448 - val_accuracy: 0.9750\n",
      "Epoch 139/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9837 - val_loss: 0.1731 - val_accuracy: 0.9550\n",
      "Epoch 140/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.9689 - val_loss: 0.0560 - val_accuracy: 0.9850\n",
      "Epoch 141/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9847 - val_loss: 0.1125 - val_accuracy: 0.9700\n",
      "Epoch 142/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9916 - val_loss: 0.0839 - val_accuracy: 0.9800\n",
      "Epoch 143/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0798 - val_accuracy: 0.9950\n",
      "Epoch 144/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0846 - val_accuracy: 0.9950\n",
      "Epoch 145/300\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9966 - val_loss: 0.0835 - val_accuracy: 0.9950\n",
      "Epoch 146/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9816 - val_loss: 0.1256 - val_accuracy: 0.9850\n",
      "Epoch 147/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9858 - val_loss: 0.0978 - val_accuracy: 0.9850\n",
      "Epoch 148/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.0749 - val_accuracy: 0.9900\n",
      "Epoch 149/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0847 - val_accuracy: 0.9900\n",
      "Epoch 150/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.1264 - val_accuracy: 0.9750\n",
      "Epoch 151/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9876 - val_loss: 0.1625 - val_accuracy: 0.9650\n",
      "Epoch 152/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0901 - val_accuracy: 0.9950\n",
      "Epoch 153/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.1087 - val_accuracy: 0.9950\n",
      "Epoch 154/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9953 - val_loss: 0.1795 - val_accuracy: 0.9650\n",
      "Epoch 155/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9863 - val_loss: 0.1641 - val_accuracy: 0.9750\n",
      "Epoch 156/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9895 - val_loss: 0.1036 - val_accuracy: 0.9950\n",
      "Epoch 157/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1065 - val_accuracy: 0.9950\n",
      "Epoch 158/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1116 - val_accuracy: 0.9900\n",
      "Epoch 159/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9926 - val_loss: 0.1231 - val_accuracy: 0.9900\n",
      "Epoch 160/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.1080 - val_accuracy: 0.9950\n",
      "Epoch 161/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.1153 - val_accuracy: 0.9950\n",
      "Epoch 162/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9932 - val_loss: 0.1213 - val_accuracy: 0.9900\n",
      "Epoch 163/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1413 - accuracy: 0.9584 - val_loss: 0.2427 - val_accuracy: 0.9200\n",
      "Epoch 164/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9458 - val_loss: 0.1995 - val_accuracy: 0.9350\n",
      "Epoch 165/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.0782 - val_accuracy: 0.9900\n",
      "Epoch 166/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.1443 - val_accuracy: 0.9700\n",
      "Epoch 167/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.0931 - val_accuracy: 0.9850\n",
      "Epoch 168/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.0809 - val_accuracy: 0.9950\n",
      "Epoch 169/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.0817 - val_accuracy: 0.9950\n",
      "Epoch 170/300\n",
      "44/60 [=====================>........] - ETA: 0s - loss: 0.0701 - accuracy: 0.9790Restoring model weights from the end of the best epoch: 140.\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9753 - val_loss: 0.1853 - val_accuracy: 0.9500\n",
      "Epoch 170: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 8\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_102 (Dense)           (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 5ms/step - loss: 1.2241 - accuracy: 0.4466 - val_loss: 1.0842 - val_accuracy: 0.5200\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1.0908 - accuracy: 0.5200 - val_loss: 1.0220 - val_accuracy: 0.5350\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.9783 - accuracy: 0.5732 - val_loss: 0.9380 - val_accuracy: 0.5900\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.8907 - accuracy: 0.6324 - val_loss: 0.8364 - val_accuracy: 0.6500\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7806 - accuracy: 0.6724 - val_loss: 0.8135 - val_accuracy: 0.6200\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.7233 - accuracy: 0.6958 - val_loss: 0.6780 - val_accuracy: 0.6950\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7416 - val_loss: 0.6834 - val_accuracy: 0.6800\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7632 - val_loss: 0.5518 - val_accuracy: 0.8050\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7797 - val_loss: 0.5204 - val_accuracy: 0.7750\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7921 - val_loss: 0.4300 - val_accuracy: 0.8250\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.8084 - val_loss: 0.3975 - val_accuracy: 0.8250\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8274 - val_loss: 0.4052 - val_accuracy: 0.8300\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8376 - val_loss: 0.5937 - val_accuracy: 0.7050\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8389 - val_loss: 0.3589 - val_accuracy: 0.8550\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8682 - val_loss: 0.3367 - val_accuracy: 0.8600\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8737 - val_loss: 0.2674 - val_accuracy: 0.8950\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8879 - val_loss: 0.2521 - val_accuracy: 0.9300\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8813 - val_loss: 0.3223 - val_accuracy: 0.8600\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8758 - val_loss: 0.2785 - val_accuracy: 0.9000\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.8979 - val_loss: 0.2353 - val_accuracy: 0.8950\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2186 - accuracy: 0.9124 - val_loss: 0.2823 - val_accuracy: 0.8650\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9195 - val_loss: 0.2142 - val_accuracy: 0.9100\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2622 - accuracy: 0.8963 - val_loss: 0.2274 - val_accuracy: 0.9050\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9311 - val_loss: 0.1617 - val_accuracy: 0.9400\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9216 - val_loss: 0.2033 - val_accuracy: 0.9050\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9253 - val_loss: 0.1670 - val_accuracy: 0.9400\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1666 - accuracy: 0.9374 - val_loss: 0.1323 - val_accuracy: 0.9600\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1772 - accuracy: 0.9363 - val_loss: 0.2979 - val_accuracy: 0.8950\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2043 - accuracy: 0.9221 - val_loss: 0.1394 - val_accuracy: 0.9350\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9421 - val_loss: 0.1077 - val_accuracy: 0.9700\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9500 - val_loss: 0.1236 - val_accuracy: 0.9550\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1123 - accuracy: 0.9563 - val_loss: 0.0898 - val_accuracy: 0.9600\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 0.9484 - val_loss: 0.0836 - val_accuracy: 0.9650\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9595 - val_loss: 0.2084 - val_accuracy: 0.9500\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9289 - val_loss: 0.1889 - val_accuracy: 0.9250\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9571 - val_loss: 0.1585 - val_accuracy: 0.9550\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 0.9624 - val_loss: 0.1567 - val_accuracy: 0.9600\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1041 - accuracy: 0.9608 - val_loss: 0.1780 - val_accuracy: 0.9500\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9745 - val_loss: 0.1262 - val_accuracy: 0.9550\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9734 - val_loss: 0.0906 - val_accuracy: 0.9700\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9789 - val_loss: 0.1070 - val_accuracy: 0.9750\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9663 - val_loss: 0.0947 - val_accuracy: 0.9700\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9708 - val_loss: 0.1771 - val_accuracy: 0.9550\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 0.9705 - val_loss: 0.1030 - val_accuracy: 0.9700\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9800 - val_loss: 0.0879 - val_accuracy: 0.9800\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9792 - val_loss: 0.1195 - val_accuracy: 0.9800\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1212 - accuracy: 0.9608 - val_loss: 0.2108 - val_accuracy: 0.9400\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9624 - val_loss: 0.1079 - val_accuracy: 0.9650\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9492 - val_loss: 0.3117 - val_accuracy: 0.8900\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9476 - val_loss: 0.0841 - val_accuracy: 0.9750\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9750 - val_loss: 0.0464 - val_accuracy: 0.9850\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9800 - val_loss: 0.0710 - val_accuracy: 0.9750\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9732 - val_loss: 0.0741 - val_accuracy: 0.9700\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9755 - val_loss: 0.0506 - val_accuracy: 0.9850\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9803 - val_loss: 0.0510 - val_accuracy: 0.9900\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.9763 - val_loss: 0.0884 - val_accuracy: 0.9600\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9797 - val_loss: 0.0327 - val_accuracy: 0.9900\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9868 - val_loss: 0.0360 - val_accuracy: 0.9850\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9816 - val_loss: 0.1626 - val_accuracy: 0.9350\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1310 - accuracy: 0.9582 - val_loss: 0.0905 - val_accuracy: 0.9600\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9858 - val_loss: 0.0337 - val_accuracy: 0.9850\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.0290 - val_accuracy: 0.9900\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9839 - val_loss: 0.0393 - val_accuracy: 0.9850\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9811 - val_loss: 0.1082 - val_accuracy: 0.9600\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9718 - val_loss: 0.0862 - val_accuracy: 0.9750\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9666 - val_loss: 0.1264 - val_accuracy: 0.9700\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0885 - accuracy: 0.9689 - val_loss: 0.0628 - val_accuracy: 0.9850\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9818 - val_loss: 0.0537 - val_accuracy: 0.9650\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9882 - val_loss: 0.0796 - val_accuracy: 0.9650\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9750 - val_loss: 0.0397 - val_accuracy: 0.9850\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0388 - val_accuracy: 0.9850\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.0260 - val_accuracy: 0.9950\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.0192 - val_accuracy: 0.9950\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.0202 - val_accuracy: 0.9900\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0261 - val_accuracy: 0.9950\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.0247 - val_accuracy: 0.9900\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.1178 - val_accuracy: 0.9400\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9321 - val_loss: 0.1265 - val_accuracy: 0.9550\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9697 - val_loss: 0.0416 - val_accuracy: 0.9850\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9913 - val_loss: 0.0659 - val_accuracy: 0.9750\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9876 - val_loss: 0.0477 - val_accuracy: 0.9700\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9908 - val_loss: 0.0222 - val_accuracy: 0.9950\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0120 - val_accuracy: 0.9950\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9916 - val_loss: 0.0374 - val_accuracy: 0.9800\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9905 - val_loss: 0.0568 - val_accuracy: 0.9850\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9774 - val_loss: 0.0748 - val_accuracy: 0.9700\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0249 - val_accuracy: 0.9900\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.0555 - val_accuracy: 0.9800\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9868 - val_loss: 0.0166 - val_accuracy: 0.9950\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9847 - val_loss: 0.0229 - val_accuracy: 0.9900\n",
      "Epoch 92/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9876 - val_loss: 0.0291 - val_accuracy: 0.9850\n",
      "Epoch 94/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9918 - val_loss: 0.0337 - val_accuracy: 0.9800\n",
      "Epoch 95/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9932 - val_loss: 0.1086 - val_accuracy: 0.9650\n",
      "Epoch 97/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9774 - val_loss: 0.0841 - val_accuracy: 0.9650\n",
      "Epoch 98/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9616 - val_loss: 0.1437 - val_accuracy: 0.9400\n",
      "Epoch 99/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1541 - accuracy: 0.9511 - val_loss: 0.1437 - val_accuracy: 0.9400\n",
      "Epoch 100/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9858 - val_loss: 0.0320 - val_accuracy: 0.9900\n",
      "Epoch 101/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0136 - val_accuracy: 0.9950\n",
      "Epoch 103/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0270 - val_accuracy: 0.9900\n",
      "Epoch 104/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9903 - val_loss: 0.0270 - val_accuracy: 0.9900\n",
      "Epoch 106/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.9813 - val_loss: 0.0755 - val_accuracy: 0.9750\n",
      "Epoch 107/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9755 - val_loss: 0.0341 - val_accuracy: 0.9950\n",
      "Epoch 108/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9737 - val_loss: 0.0731 - val_accuracy: 0.9700\n",
      "Epoch 109/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9824 - val_loss: 0.0430 - val_accuracy: 0.9850\n",
      "Epoch 110/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9905 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.9889 - val_loss: 0.0576 - val_accuracy: 0.9850\n",
      "Epoch 112/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9811 - val_loss: 0.1045 - val_accuracy: 0.9800\n",
      "Epoch 113/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0847 - val_accuracy: 0.9800\n",
      "Epoch 114/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.0566 - val_accuracy: 0.9950\n",
      "Epoch 115/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9926 - val_loss: 0.0741 - val_accuracy: 0.9800\n",
      "Epoch 116/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0673 - val_accuracy: 0.9950\n",
      "Epoch 117/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.0870 - val_accuracy: 0.9800\n",
      "Epoch 118/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 0.1155 - val_accuracy: 0.9800\n",
      "Epoch 119/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9768 - val_loss: 0.1031 - val_accuracy: 0.9950\n",
      "Epoch 120/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.0650 - val_accuracy: 0.9900\n",
      "Epoch 121/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.0637 - val_accuracy: 0.9950\n",
      "Epoch 122/300\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9997Restoring model weights from the end of the best epoch: 92.\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0610 - val_accuracy: 0.9950\n",
      "Epoch 122: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 9\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_108 (Dense)           (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 6ms/step - loss: 1.2274 - accuracy: 0.4400 - val_loss: 1.1776 - val_accuracy: 0.3800\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 1.1008 - accuracy: 0.5189 - val_loss: 1.0533 - val_accuracy: 0.4800\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.9950 - accuracy: 0.5666 - val_loss: 0.9520 - val_accuracy: 0.5650\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.8799 - accuracy: 0.6347 - val_loss: 0.8424 - val_accuracy: 0.6750\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.7826 - accuracy: 0.6671 - val_loss: 0.7953 - val_accuracy: 0.6700\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.7245 - val_loss: 0.7144 - val_accuracy: 0.6700\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.7347 - val_loss: 0.6514 - val_accuracy: 0.6900\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5623 - accuracy: 0.7621 - val_loss: 0.5850 - val_accuracy: 0.7350\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7871 - val_loss: 0.4912 - val_accuracy: 0.8100\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8039 - val_loss: 0.5021 - val_accuracy: 0.7800\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8116 - val_loss: 0.5050 - val_accuracy: 0.8000\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.8203 - val_loss: 0.4701 - val_accuracy: 0.7900\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8321 - val_loss: 0.3733 - val_accuracy: 0.8350\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.8650 - val_loss: 0.3634 - val_accuracy: 0.8500\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8671 - val_loss: 0.3599 - val_accuracy: 0.8450\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8737 - val_loss: 0.4375 - val_accuracy: 0.8100\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.8689 - val_loss: 0.4494 - val_accuracy: 0.8200\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8650 - val_loss: 0.3648 - val_accuracy: 0.8250\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8868 - val_loss: 0.2828 - val_accuracy: 0.8900\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2262 - accuracy: 0.9005 - val_loss: 0.2214 - val_accuracy: 0.9300\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2163 - accuracy: 0.9116 - val_loss: 0.2408 - val_accuracy: 0.8750\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1936 - accuracy: 0.9213 - val_loss: 0.2139 - val_accuracy: 0.9200\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1886 - accuracy: 0.9232 - val_loss: 0.2734 - val_accuracy: 0.8800\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1822 - accuracy: 0.9255 - val_loss: 0.2103 - val_accuracy: 0.9200\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2436 - accuracy: 0.9032 - val_loss: 0.3664 - val_accuracy: 0.8300\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2073 - accuracy: 0.9168 - val_loss: 0.2064 - val_accuracy: 0.9200\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.9316 - val_loss: 0.1916 - val_accuracy: 0.9200\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9413 - val_loss: 0.1460 - val_accuracy: 0.9750\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9418 - val_loss: 0.1691 - val_accuracy: 0.9400\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9458 - val_loss: 0.2014 - val_accuracy: 0.9350\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9497 - val_loss: 0.2226 - val_accuracy: 0.9350\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9579 - val_loss: 0.1458 - val_accuracy: 0.9600\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9476 - val_loss: 0.1910 - val_accuracy: 0.9350\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 0.9642 - val_loss: 0.1922 - val_accuracy: 0.9200\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.9553 - val_loss: 0.1851 - val_accuracy: 0.9600\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9513 - val_loss: 0.1995 - val_accuracy: 0.9350\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1136 - accuracy: 0.9558 - val_loss: 0.1345 - val_accuracy: 0.9700\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9653 - val_loss: 0.1713 - val_accuracy: 0.9550\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.9482 - val_loss: 0.2623 - val_accuracy: 0.9200\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9379 - val_loss: 0.1790 - val_accuracy: 0.9550\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.9618 - val_loss: 0.1917 - val_accuracy: 0.9500\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0978 - accuracy: 0.9608 - val_loss: 0.1487 - val_accuracy: 0.9600\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0759 - accuracy: 0.9713 - val_loss: 0.1582 - val_accuracy: 0.9450\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9750 - val_loss: 0.1358 - val_accuracy: 0.9850\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9779 - val_loss: 0.1473 - val_accuracy: 0.9750\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9776 - val_loss: 0.1144 - val_accuracy: 0.9800\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.9797 - val_loss: 0.1821 - val_accuracy: 0.9400\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0892 - accuracy: 0.9639 - val_loss: 0.1974 - val_accuracy: 0.9450\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9734 - val_loss: 0.1409 - val_accuracy: 0.9750\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9768 - val_loss: 0.1432 - val_accuracy: 0.9700\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9818 - val_loss: 0.2238 - val_accuracy: 0.9450\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9579 - val_loss: 0.1803 - val_accuracy: 0.9600\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9245 - val_loss: 0.5142 - val_accuracy: 0.8650\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1355 - accuracy: 0.9474 - val_loss: 0.1619 - val_accuracy: 0.9700\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9811 - val_loss: 0.1397 - val_accuracy: 0.9800\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9845 - val_loss: 0.1255 - val_accuracy: 0.9800\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9705 - val_loss: 0.1079 - val_accuracy: 0.9850\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9853 - val_loss: 0.0994 - val_accuracy: 0.9750\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9889 - val_loss: 0.1149 - val_accuracy: 0.9700\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9897 - val_loss: 0.1378 - val_accuracy: 0.9700\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9782 - val_loss: 0.1157 - val_accuracy: 0.9700\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9834 - val_loss: 0.1106 - val_accuracy: 0.9800\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.1129 - val_accuracy: 0.9800\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9797 - val_loss: 0.1608 - val_accuracy: 0.9600\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9792 - val_loss: 0.1028 - val_accuracy: 0.9900\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9797 - val_loss: 0.1705 - val_accuracy: 0.9650\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9718 - val_loss: 0.1357 - val_accuracy: 0.9700\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9589 - val_loss: 0.3037 - val_accuracy: 0.9050\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1361 - accuracy: 0.9555 - val_loss: 0.1755 - val_accuracy: 0.9650\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9800 - val_loss: 0.1160 - val_accuracy: 0.9650\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9792 - val_loss: 0.1020 - val_accuracy: 0.9800\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9742 - val_loss: 0.1257 - val_accuracy: 0.9700\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 0.0866 - val_accuracy: 0.9850\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 0.1174 - val_accuracy: 0.9700\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9797 - val_loss: 0.1047 - val_accuracy: 0.9800\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9882 - val_loss: 0.1105 - val_accuracy: 0.9850\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9826 - val_loss: 0.0756 - val_accuracy: 0.9900\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0736 - val_accuracy: 0.9900\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.0804 - val_accuracy: 0.9900\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0676 - val_accuracy: 0.9850\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.0895 - val_accuracy: 0.9800\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9761 - val_loss: 0.1668 - val_accuracy: 0.9650\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9613 - val_loss: 0.0954 - val_accuracy: 0.9800\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9911 - val_loss: 0.0677 - val_accuracy: 0.9950\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0702 - val_accuracy: 0.9850\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9597 - val_loss: 0.1208 - val_accuracy: 0.9800\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9818 - val_loss: 0.0805 - val_accuracy: 0.9900\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.0510 - val_accuracy: 0.9950\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9903 - val_loss: 0.0633 - val_accuracy: 0.9900\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9800 - val_loss: 0.2711 - val_accuracy: 0.9200\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9605 - val_loss: 0.0956 - val_accuracy: 0.9950\n",
      "Epoch 92/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9858 - val_loss: 0.1297 - val_accuracy: 0.9950\n",
      "Epoch 93/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.1180 - val_accuracy: 0.9950\n",
      "Epoch 94/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.1013 - val_accuracy: 0.9950\n",
      "Epoch 95/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.1035 - val_accuracy: 0.9950\n",
      "Epoch 96/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.1200 - val_accuracy: 0.9900\n",
      "Epoch 97/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.2823 - val_accuracy: 0.9300\n",
      "Epoch 98/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0999 - accuracy: 0.9692 - val_loss: 0.2108 - val_accuracy: 0.9450\n",
      "Epoch 99/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9782 - val_loss: 0.0879 - val_accuracy: 0.9800\n",
      "Epoch 100/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9782 - val_loss: 0.3171 - val_accuracy: 0.9250\n",
      "Epoch 101/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9611 - val_loss: 0.2238 - val_accuracy: 0.9500\n",
      "Epoch 102/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9716 - val_loss: 0.0964 - val_accuracy: 0.9850\n",
      "Epoch 103/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.0902 - val_accuracy: 0.9850\n",
      "Epoch 104/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0992 - val_accuracy: 0.9800\n",
      "Epoch 105/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9966 - val_loss: 0.0777 - val_accuracy: 0.9950\n",
      "Epoch 106/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.1056 - val_accuracy: 0.9900\n",
      "Epoch 107/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.1098 - val_accuracy: 0.9900\n",
      "Epoch 108/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9816 - val_loss: 0.1423 - val_accuracy: 0.9600\n",
      "Epoch 109/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.0837 - val_accuracy: 0.9900\n",
      "Epoch 110/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0779 - val_accuracy: 0.9900\n",
      "Epoch 111/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0743 - val_accuracy: 0.9950\n",
      "Epoch 112/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9905 - val_loss: 0.1485 - val_accuracy: 0.9800\n",
      "Epoch 113/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9737 - val_loss: 0.2160 - val_accuracy: 0.9450\n",
      "Epoch 114/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9776 - val_loss: 0.1565 - val_accuracy: 0.9500\n",
      "Epoch 115/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9761 - val_loss: 0.0804 - val_accuracy: 0.9800\n",
      "Epoch 116/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9892 - val_loss: 0.0982 - val_accuracy: 0.9800\n",
      "Epoch 117/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9916 - val_loss: 0.0703 - val_accuracy: 0.9950\n",
      "Epoch 118/300\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.0125 - accuracy: 0.9975Restoring model weights from the end of the best epoch: 88.\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9974 - val_loss: 0.0730 - val_accuracy: 0.9950\n",
      "Epoch 118: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Training fold 10\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_114 (Dense)           (None, 100)               3100      \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 300)               60300     \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164304 (641.81 KB)\n",
      "Trainable params: 164304 (641.81 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "60/60 [==============================] - 1s 6ms/step - loss: 1.1939 - accuracy: 0.4539 - val_loss: 1.1036 - val_accuracy: 0.5200\n",
      "Epoch 2/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1.0655 - accuracy: 0.5287 - val_loss: 1.1034 - val_accuracy: 0.5050\n",
      "Epoch 3/300\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.9743 - accuracy: 0.5853 - val_loss: 0.9606 - val_accuracy: 0.5750\n",
      "Epoch 4/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.8437 - accuracy: 0.6479 - val_loss: 0.7949 - val_accuracy: 0.6750\n",
      "Epoch 5/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.6911 - val_loss: 0.8118 - val_accuracy: 0.6850\n",
      "Epoch 6/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.7213 - val_loss: 0.7142 - val_accuracy: 0.6850\n",
      "Epoch 7/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7716 - val_loss: 0.5972 - val_accuracy: 0.7450\n",
      "Epoch 8/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7966 - val_loss: 0.5310 - val_accuracy: 0.7850\n",
      "Epoch 9/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8008 - val_loss: 0.5582 - val_accuracy: 0.7550\n",
      "Epoch 10/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8221 - val_loss: 0.4381 - val_accuracy: 0.8200\n",
      "Epoch 11/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8505 - val_loss: 0.4241 - val_accuracy: 0.8200\n",
      "Epoch 12/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3310 - accuracy: 0.8655 - val_loss: 0.3650 - val_accuracy: 0.8500\n",
      "Epoch 13/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8592 - val_loss: 0.4094 - val_accuracy: 0.8250\n",
      "Epoch 14/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.8711 - val_loss: 0.4562 - val_accuracy: 0.7850\n",
      "Epoch 15/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8621 - val_loss: 0.3613 - val_accuracy: 0.8450\n",
      "Epoch 16/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.8800 - val_loss: 0.3378 - val_accuracy: 0.8550\n",
      "Epoch 17/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.9018 - val_loss: 0.2982 - val_accuracy: 0.8800\n",
      "Epoch 18/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9079 - val_loss: 0.2589 - val_accuracy: 0.8900\n",
      "Epoch 19/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1955 - accuracy: 0.9189 - val_loss: 0.2353 - val_accuracy: 0.8950\n",
      "Epoch 20/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.9011 - val_loss: 0.2859 - val_accuracy: 0.8800\n",
      "Epoch 21/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2117 - accuracy: 0.9134 - val_loss: 0.2070 - val_accuracy: 0.9150\n",
      "Epoch 22/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9316 - val_loss: 0.2256 - val_accuracy: 0.9150\n",
      "Epoch 23/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9384 - val_loss: 0.2570 - val_accuracy: 0.8750\n",
      "Epoch 24/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.9376 - val_loss: 0.1758 - val_accuracy: 0.9250\n",
      "Epoch 25/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9492 - val_loss: 0.1604 - val_accuracy: 0.9300\n",
      "Epoch 26/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9492 - val_loss: 0.1444 - val_accuracy: 0.9600\n",
      "Epoch 27/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9432 - val_loss: 0.1535 - val_accuracy: 0.9400\n",
      "Epoch 28/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.9068 - val_loss: 0.1984 - val_accuracy: 0.9350\n",
      "Epoch 29/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9421 - val_loss: 0.1437 - val_accuracy: 0.9650\n",
      "Epoch 30/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9618 - val_loss: 0.1909 - val_accuracy: 0.9050\n",
      "Epoch 31/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9600 - val_loss: 0.1574 - val_accuracy: 0.9500\n",
      "Epoch 32/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9545 - val_loss: 0.1140 - val_accuracy: 0.9700\n",
      "Epoch 33/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9753 - val_loss: 0.1256 - val_accuracy: 0.9450\n",
      "Epoch 34/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.9061 - val_loss: 0.2773 - val_accuracy: 0.9250\n",
      "Epoch 35/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2008 - accuracy: 0.9329 - val_loss: 0.1355 - val_accuracy: 0.9700\n",
      "Epoch 36/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.9592 - val_loss: 0.0783 - val_accuracy: 0.9800\n",
      "Epoch 37/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9774 - val_loss: 0.0650 - val_accuracy: 0.9750\n",
      "Epoch 38/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9726 - val_loss: 0.0797 - val_accuracy: 0.9650\n",
      "Epoch 39/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9692 - val_loss: 0.0467 - val_accuracy: 0.9950\n",
      "Epoch 40/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9813 - val_loss: 0.0824 - val_accuracy: 0.9800\n",
      "Epoch 41/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9766 - val_loss: 0.0569 - val_accuracy: 0.9850\n",
      "Epoch 42/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9529 - val_loss: 0.1134 - val_accuracy: 0.9600\n",
      "Epoch 43/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9708 - val_loss: 0.0501 - val_accuracy: 0.9850\n",
      "Epoch 44/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9818 - val_loss: 0.0591 - val_accuracy: 0.9800\n",
      "Epoch 45/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9824 - val_loss: 0.0202 - val_accuracy: 0.9950\n",
      "Epoch 46/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 47/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9532 - val_loss: 0.1238 - val_accuracy: 0.9600\n",
      "Epoch 48/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9503 - val_loss: 0.1386 - val_accuracy: 0.9400\n",
      "Epoch 49/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0936 - accuracy: 0.9687 - val_loss: 0.0566 - val_accuracy: 0.9800\n",
      "Epoch 50/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9834 - val_loss: 0.0499 - val_accuracy: 0.9900\n",
      "Epoch 51/300\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 0.9908 - val_loss: 0.0273 - val_accuracy: 0.9950\n",
      "Epoch 52/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9832 - val_loss: 0.0498 - val_accuracy: 0.9800\n",
      "Epoch 53/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.9753 - val_loss: 0.0545 - val_accuracy: 0.9850\n",
      "Epoch 54/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9826 - val_loss: 0.0181 - val_accuracy: 0.9950\n",
      "Epoch 55/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0211 - val_accuracy: 0.9950\n",
      "Epoch 56/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9908 - val_loss: 0.0365 - val_accuracy: 0.9900\n",
      "Epoch 57/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9732 - val_loss: 0.0861 - val_accuracy: 0.9600\n",
      "Epoch 58/300\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.1576 - accuracy: 0.9482 - val_loss: 0.3278 - val_accuracy: 0.9000\n",
      "Epoch 59/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1135 - accuracy: 0.9689 - val_loss: 0.0647 - val_accuracy: 0.9800\n",
      "Epoch 60/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9795 - val_loss: 0.0155 - val_accuracy: 0.9950\n",
      "Epoch 61/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9845 - val_loss: 0.0480 - val_accuracy: 0.9900\n",
      "Epoch 62/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.0296 - val_accuracy: 0.9900\n",
      "Epoch 63/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0228 - val_accuracy: 0.9950\n",
      "Epoch 64/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.0223 - val_accuracy: 0.9950\n",
      "Epoch 65/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.0539 - val_accuracy: 0.9850\n",
      "Epoch 66/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9666 - val_loss: 0.1019 - val_accuracy: 0.9550\n",
      "Epoch 67/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9718 - val_loss: 0.0926 - val_accuracy: 0.9650\n",
      "Epoch 68/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9687 - val_loss: 0.0730 - val_accuracy: 0.9800\n",
      "Epoch 69/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9821 - val_loss: 0.0754 - val_accuracy: 0.9850\n",
      "Epoch 70/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.0647 - val_accuracy: 0.9700\n",
      "Epoch 71/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9745 - val_loss: 0.0501 - val_accuracy: 0.9950\n",
      "Epoch 72/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.0424 - val_accuracy: 0.9850\n",
      "Epoch 73/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9853 - val_loss: 0.0523 - val_accuracy: 0.9850\n",
      "Epoch 74/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0336 - val_accuracy: 0.9800\n",
      "Epoch 75/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 0.9897 - val_loss: 0.0201 - val_accuracy: 0.9950\n",
      "Epoch 76/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0246 - val_accuracy: 0.9900\n",
      "Epoch 77/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9866 - val_loss: 0.0492 - val_accuracy: 0.9850\n",
      "Epoch 78/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0252 - val_accuracy: 0.9950\n",
      "Epoch 79/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.0173 - val_accuracy: 0.9900\n",
      "Epoch 80/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0134 - val_accuracy: 0.9950\n",
      "Epoch 81/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.0376 - val_accuracy: 0.9850\n",
      "Epoch 82/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9850 - val_loss: 0.0787 - val_accuracy: 0.9700\n",
      "Epoch 83/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9429 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
      "Epoch 84/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9605 - val_loss: 0.0757 - val_accuracy: 0.9700\n",
      "Epoch 85/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9924 - val_loss: 0.0217 - val_accuracy: 0.9950\n",
      "Epoch 86/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0143 - val_accuracy: 0.9950\n",
      "Epoch 87/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0242 - val_accuracy: 0.9900\n",
      "Epoch 88/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.0979 - val_accuracy: 0.9700\n",
      "Epoch 89/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0449 - val_accuracy: 0.9950\n",
      "Epoch 90/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.0117 - val_accuracy: 0.9950\n",
      "Epoch 91/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0070 - val_accuracy: 0.9950\n",
      "Epoch 92/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0080 - val_accuracy: 0.9950\n",
      "Epoch 93/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0162 - val_accuracy: 0.9850\n",
      "Epoch 94/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0075 - val_accuracy: 0.9950\n",
      "Epoch 95/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0248 - val_accuracy: 0.9900\n",
      "Epoch 96/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0142 - val_accuracy: 0.9950\n",
      "Epoch 97/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.0093 - val_accuracy: 0.9950\n",
      "Epoch 98/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.1097 - val_accuracy: 0.9600\n",
      "Epoch 99/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1643 - accuracy: 0.9479 - val_loss: 0.2176 - val_accuracy: 0.9200\n",
      "Epoch 100/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9661 - val_loss: 0.0453 - val_accuracy: 0.9850\n",
      "Epoch 101/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9861 - val_loss: 0.0152 - val_accuracy: 0.9950\n",
      "Epoch 102/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 0.0466 - val_accuracy: 0.9800\n",
      "Epoch 103/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9813 - val_loss: 0.1190 - val_accuracy: 0.9650\n",
      "Epoch 104/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9861 - val_loss: 0.0517 - val_accuracy: 0.9900\n",
      "Epoch 105/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9900 - val_loss: 0.0741 - val_accuracy: 0.9850\n",
      "Epoch 106/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.0614 - val_accuracy: 0.9850\n",
      "Epoch 107/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.0342 - val_accuracy: 0.9950\n",
      "Epoch 108/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0319 - val_accuracy: 0.9950\n",
      "Epoch 109/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9950\n",
      "Epoch 110/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 0.0587 - val_accuracy: 0.9850\n",
      "Epoch 111/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9850 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 112/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9787 - val_loss: 0.0569 - val_accuracy: 0.9850\n",
      "Epoch 113/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.0170 - val_accuracy: 0.9950\n",
      "Epoch 114/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0181 - val_accuracy: 0.9950\n",
      "Epoch 115/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0224 - val_accuracy: 0.9950\n",
      "Epoch 116/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.0380 - val_accuracy: 0.9850\n",
      "Epoch 117/300\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.9784 - val_loss: 0.0827 - val_accuracy: 0.9750\n",
      "Epoch 118/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9703 - val_loss: 0.0347 - val_accuracy: 0.9900\n",
      "Epoch 119/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9774 - val_loss: 0.0703 - val_accuracy: 0.9950\n",
      "Epoch 120/300\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9787 - val_loss: 0.1582 - val_accuracy: 0.9550\n",
      "Epoch 121/300\n",
      "53/60 [=========================>....] - ETA: 0s - loss: 0.0818 - accuracy: 0.9708Restoring model weights from the end of the best epoch: 91.\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9721 - val_loss: 0.0855 - val_accuracy: 0.9700\n",
      "Epoch 121: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "\n",
      "Time taken for training:  00:03:47\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9822 - Test Accuracy 0.4500\n",
      "Fold 2 - Train Accuracy 0.9948 - Test Accuracy 0.4125\n",
      "Fold 3 - Train Accuracy 0.9945 - Test Accuracy 0.3875\n",
      "Fold 4 - Train Accuracy 0.9952 - Test Accuracy 0.4250\n",
      "Fold 5 - Train Accuracy 0.9908 - Test Accuracy 0.3125\n",
      "Fold 6 - Train Accuracy 0.9890 - Test Accuracy 0.2875\n",
      "Fold 7 - Train Accuracy 0.9930 - Test Accuracy 0.4750\n",
      "Fold 8 - Train Accuracy 0.9980 - Test Accuracy 0.4375\n",
      "Fold 9 - Train Accuracy 0.9940 - Test Accuracy 0.3750\n",
      "Fold 10 - Train Accuracy 0.9998 - Test Accuracy 0.4500\n",
      "\n",
      "Mean Train Accuracy: 0.9931 \n",
      "Mean Test Accuracy: 0.4012 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.31      0.33       200\n",
      "           1       0.53      0.64      0.58       200\n",
      "           2       0.36      0.34      0.35       200\n",
      "           3       0.33      0.33      0.33       200\n",
      "\n",
      "    accuracy                           0.40       800\n",
      "   macro avg       0.39      0.40      0.40       800\n",
      "weighted avg       0.39      0.40      0.40       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_v1() :\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape = (30,), activation = 'relu', kernel_initializer = \"he_uniform\"))\n",
    "    model.add(Dense(200, activation = 'relu', kernel_initializer = \"he_uniform\"))\n",
    "    model.add(Dense(300, activation = 'relu', kernel_initializer = \"he_uniform\"))\n",
    "    model.add(Dense(200, activation = 'relu', kernel_initializer = \"he_uniform\"))\n",
    "    model.add(Dense(100, activation = 'relu', kernel_initializer = \"he_uniform\"))\n",
    "    model.add(Dense(4, activation = 'softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Defining the number of folds (10 k-Fold).\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Normalize data using PowerTransformer method.\n",
    "pt = PowerTransformer()\n",
    "\n",
    "# Train the MLP model and evaluate it.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training...\\n\")\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 30, restore_best_weights = True)\n",
    "\n",
    "train_accuracy_by_fold = []\n",
    "test_accuracy_by_fold = []\n",
    "y_predclass_for_report = []\n",
    "y_testclass_for_report = []\n",
    "history_by_fold = []\n",
    "fold_number = 1\n",
    "for train_index, test_index in skf.split(X_resampled, y_resampled):\n",
    "    print(\"\\nTraining fold {}\".format(fold_number))\n",
    "    # Data augmentation (5x).\n",
    "    X_oversampled, y_oversampled = resample(X_resampled[train_index],\n",
    "                                            y_resampled[train_index],\n",
    "                                            replace = True,\n",
    "                                            n_samples = 4000,\n",
    "                                            stratify = y_resampled[train_index],\n",
    "                                            random_state = 42)\n",
    "    X_train_scaled = pt.fit_transform(X_oversampled)\n",
    "    X_test_scaled = pt.transform(X_resampled[test_index])\n",
    "    model = create_v1()\n",
    "    history = model.fit(X_train_scaled, y_oversampled, validation_split = 0.05,\n",
    "                            epochs = 300, batch_size = 64, verbose = 1, callbacks = [es])\n",
    "    _, train_accuracy = model.evaluate(X_train_scaled, y_oversampled, verbose = 0)\n",
    "    _, test_accuracy = model.evaluate(X_test_scaled, y_resampled[test_index], verbose = 0)\n",
    "    train_accuracy_by_fold.append(train_accuracy)\n",
    "    test_accuracy_by_fold.append(test_accuracy)\n",
    "    y_predclass_for_report.extend(np.argmax(model.predict(X_test_scaled), axis = 1))\n",
    "    y_testclass_for_report.extend(y_resampled[test_index])\n",
    "    history_by_fold.append(history)\n",
    "    fold_number += 1\n",
    "\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show metrics.\n",
    "for i in range(len(train_accuracy_by_fold)):\n",
    "    print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "                            train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "print(\"\\nMean Train Accuracy: {:.4f} \".format(np.mean(train_accuracy_by_fold)))\n",
    "print(\"Mean Test Accuracy: {:.4f} \".format(np.mean(test_accuracy_by_fold)))\n",
    "\n",
    "print(\"\\nEvaluate other metrics:\")\n",
    "print(classification_report(y_testclass_for_report, y_predclass_for_report, zero_division = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48119eaf",
   "metadata": {},
   "source": [
    "#### Show loss history by epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a10b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot loss history\n",
    "for i in range(len(history_by_fold)):\n",
    "    plt.plot(history_by_fold[i].history[\"val_loss\"], label = \"Fold {}\".format(i + 1))\n",
    "plt.title(\"Validation Loss vs Number of epochs\", fontsize = 12)\n",
    "plt.xlabel(\"Epochs\", fontsize = 12)\n",
    "plt.ylabel(\"Loss\", fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26847b22",
   "metadata": {},
   "source": [
    "#### Show accuracy history by epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7e0aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot accuracy history\n",
    "for i in range(len(history_by_fold)):\n",
    "    plt.plot(history_by_fold[i].history[\"val_accuracy\"], label = \"Fold {}\".format(i + 1))\n",
    "plt.title(\"Validation Accuracy vs Number of epochs\", fontsize = 12)\n",
    "plt.xlabel('Epochs', fontsize = 12)\n",
    "plt.ylabel('Accuracy', fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
