{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbe460f",
   "metadata": {},
   "source": [
    "#### Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077b6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.utils import resample\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b11eaf",
   "metadata": {},
   "source": [
    "#### Show installed GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae23115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  /physical_device:GPU:0  Type:  GPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus :\n",
    "    print(\"Name: \", gpu.name, \" Type: \", gpu.device_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42175028",
   "metadata": {},
   "source": [
    "#### Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43ccbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"../dataset/original-noneeg-dataset.csv\", sep=\"|\", dtype = {\"hr\": \"float64\", \"label\": \"int8\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d03541",
   "metadata": {},
   "source": [
    "#### Display the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d243cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41992, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579e10b",
   "metadata": {},
   "source": [
    "#### Build a helper function to convert the set data to the required format to perform the undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859f6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_steps = 30\n",
    "\n",
    "def build_time_window_structure(df):\n",
    "    # Splits the dataset into \"time windows\" to be used as a time series list.\n",
    "    # The function groups each 30 dataset records (CSV lines) into one record.\n",
    "    # Each record contains 30 steps and each step contains 1 feature value.\n",
    "    # Parameters:\n",
    "    #    df: Dataframe to be splitted.\n",
    "    # Return:\n",
    "    #    First list contains all time windows.\n",
    "    #    Second list contains all target values.\n",
    "    print(\"\\nStarting build_time_window_structure function.\")\n",
    "    initial_line_number = 0\n",
    "    first_feat_index = 0\n",
    "    last_feat_index = 1\n",
    "    X_array = []\n",
    "    y_array = []\n",
    "    while initial_line_number < len(df[\"label\"]):\n",
    "        target_value = df[\"label\"][initial_line_number]\n",
    "        sub_matrix = df.iloc[initial_line_number : (initial_line_number + number_of_steps), first_feat_index : last_feat_index]\n",
    "        sub_matrix_values = sub_matrix.values\n",
    "        new_line = sub_matrix_values.flatten()\n",
    "        size_diff = number_of_steps - len(new_line)\n",
    "        if size_diff > 0:\n",
    "            last_value = new_line[len(new_line) - 1]\n",
    "            new_line = np.append(new_line, [last_value] * size_diff)\n",
    "        X_array.append(new_line)\n",
    "        y_array.append(target_value)\n",
    "        initial_line_number += number_of_steps\n",
    "    print(\"Quantity of samples (features) => \", len(X_array))\n",
    "    print(\"Quantity os samples (labels) => \", len(y_array))\n",
    "    print(\"Finishing build_time_window_structure function.\")\n",
    "    return X_array, y_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a01eb",
   "metadata": {},
   "source": [
    "#### Perform undersampling to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd2e2c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting undersampling process.\n",
      "\n",
      "Starting build_time_window_structure function.\n",
      "Quantity of samples (features) =>  1400\n",
      "Quantity os samples (labels) =>  1400\n",
      "Finishing build_time_window_structure function.\n",
      "\n",
      "Quantity of resampled samples =>  800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Correct dataset imbalance through undersampling.\n",
    "print(\"\\nStarting undersampling process.\")\n",
    "X_list, y_list = build_time_window_structure(df)\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "X_arr = np.array(X_list)\n",
    "y_arr = np.array(y_list)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_arr, y_arr)\n",
    "print(\"\\nQuantity of resampled samples => \", len(y_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258715ac",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Flatten + Dense (32) + Dense (4)\n",
    "- 800 samples (no data augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e887613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training at:  21:39:47\n",
      "\n",
      "Trainning fold 1\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_260 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_261 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_262 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_180 (MaxPooli  (None, 12, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_180 (Flatten)       (None, 192)               0         \n",
      "                                                                 \n",
      " dense_400 (Dense)           (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,292\n",
      "Trainable params: 14,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 536ms/step - loss: 1.3745 - accuracy: 0.2932 - val_loss: 1.4706 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.3428 - accuracy: 0.3812 - val_loss: 1.5278 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.3164 - accuracy: 0.4429 - val_loss: 1.5782 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2875 - accuracy: 0.4444 - val_loss: 1.6234 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2568 - accuracy: 0.4290 - val_loss: 1.6685 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.2295 - accuracy: 0.4228 - val_loss: 1.7160 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2072 - accuracy: 0.4182 - val_loss: 1.7720 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1946 - accuracy: 0.4182 - val_loss: 1.8397 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1879 - accuracy: 0.4182 - val_loss: 1.8625 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1838 - accuracy: 0.4244 - val_loss: 1.8174 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1790 - accuracy: 0.4383 - val_loss: 1.7018 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1748 - accuracy: 0.4506 - val_loss: 1.5575 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1735 - accuracy: 0.4537 - val_loss: 1.4538 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1731 - accuracy: 0.4568 - val_loss: 1.4429 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1701 - accuracy: 0.4568 - val_loss: 1.5095 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1632 - accuracy: 0.4568 - val_loss: 1.5842 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1617 - accuracy: 0.4552 - val_loss: 1.6300 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1609 - accuracy: 0.4676 - val_loss: 1.6020 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1571 - accuracy: 0.4753 - val_loss: 1.5659 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1527 - accuracy: 0.4722 - val_loss: 1.5658 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1504 - accuracy: 0.4614 - val_loss: 1.5762 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1485 - accuracy: 0.4614 - val_loss: 1.5696 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1468 - accuracy: 0.4707 - val_loss: 1.5781 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1444 - accuracy: 0.4815 - val_loss: 1.5922 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1455 - accuracy: 0.4769 - val_loss: 1.5944 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1424 - accuracy: 0.4799 - val_loss: 1.5968 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1379 - accuracy: 0.4861 - val_loss: 1.6204 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1397 - accuracy: 0.4691 - val_loss: 1.6629 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1404 - accuracy: 0.4722 - val_loss: 1.6760 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1373 - accuracy: 0.4861 - val_loss: 1.6388 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1351 - accuracy: 0.4923 - val_loss: 1.6003 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1336 - accuracy: 0.4907 - val_loss: 1.5803 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1327 - accuracy: 0.4907 - val_loss: 1.5803 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1309 - accuracy: 0.5000 - val_loss: 1.6112 - val_accuracy: 0.0000e+00\n",
      "Epoch 00034: early stopping\n",
      "\n",
      "Trainning fold 2\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_263 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_264 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_265 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_181 (MaxPooli  (None, 12, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_181 (Flatten)       (None, 192)               0         \n",
      "                                                                 \n",
      " dense_402 (Dense)           (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,292\n",
      "Trainable params: 14,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 183ms/step - loss: 1.3671 - accuracy: 0.2994 - val_loss: 1.3960 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.3311 - accuracy: 0.4198 - val_loss: 1.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2972 - accuracy: 0.4306 - val_loss: 1.4372 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2655 - accuracy: 0.4244 - val_loss: 1.4717 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2343 - accuracy: 0.4213 - val_loss: 1.5275 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2132 - accuracy: 0.4228 - val_loss: 1.6098 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2079 - accuracy: 0.4244 - val_loss: 1.6995 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2112 - accuracy: 0.4275 - val_loss: 1.7440 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2097 - accuracy: 0.4306 - val_loss: 1.7206 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1992 - accuracy: 0.4336 - val_loss: 1.6588 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1904 - accuracy: 0.4460 - val_loss: 1.6092 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1892 - accuracy: 0.4630 - val_loss: 1.5848 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1896 - accuracy: 0.4583 - val_loss: 1.5751 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1865 - accuracy: 0.4552 - val_loss: 1.5753 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1826 - accuracy: 0.4583 - val_loss: 1.5844 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1809 - accuracy: 0.4583 - val_loss: 1.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1782 - accuracy: 0.4552 - val_loss: 1.5965 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1757 - accuracy: 0.4583 - val_loss: 1.6035 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1725 - accuracy: 0.4583 - val_loss: 1.6172 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1704 - accuracy: 0.4707 - val_loss: 1.6273 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1685 - accuracy: 0.4707 - val_loss: 1.6430 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 3\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_266 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_267 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_268 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_182 (MaxPooli  (None, 12, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_182 (Flatten)       (None, 192)               0         \n",
      "                                                                 \n",
      " dense_404 (Dense)           (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,292\n",
      "Trainable params: 14,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 178ms/step - loss: 1.3741 - accuracy: 0.3164 - val_loss: 1.4051 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.3450 - accuracy: 0.4290 - val_loss: 1.3991 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3203 - accuracy: 0.4321 - val_loss: 1.4165 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2960 - accuracy: 0.4306 - val_loss: 1.4671 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2789 - accuracy: 0.4290 - val_loss: 1.5093 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2605 - accuracy: 0.4321 - val_loss: 1.5128 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2429 - accuracy: 0.4352 - val_loss: 1.4941 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2243 - accuracy: 0.4321 - val_loss: 1.4723 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2092 - accuracy: 0.4367 - val_loss: 1.4628 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1981 - accuracy: 0.4444 - val_loss: 1.4859 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1881 - accuracy: 0.4491 - val_loss: 1.5329 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1785 - accuracy: 0.4614 - val_loss: 1.6128 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1769 - accuracy: 0.4707 - val_loss: 1.6953 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1735 - accuracy: 0.4722 - val_loss: 1.7185 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1751 - accuracy: 0.4645 - val_loss: 1.6984 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1755 - accuracy: 0.4676 - val_loss: 1.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1694 - accuracy: 0.4769 - val_loss: 1.6801 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1691 - accuracy: 0.4784 - val_loss: 1.7004 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1684 - accuracy: 0.4969 - val_loss: 1.7211 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1625 - accuracy: 0.4938 - val_loss: 1.7378 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1564 - accuracy: 0.4938 - val_loss: 1.7358 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1548 - accuracy: 0.4923 - val_loss: 1.7080 - val_accuracy: 0.0000e+00\n",
      "Epoch 00022: early stopping\n",
      "\n",
      "Trainning fold 4\n",
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_269 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_270 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_271 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_183 (MaxPooli  (None, 12, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_183 (Flatten)       (None, 192)               0         \n",
      "                                                                 \n",
      " dense_406 (Dense)           (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,292\n",
      "Trainable params: 14,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 208ms/step - loss: 1.3887 - accuracy: 0.1713 - val_loss: 1.4431 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3622 - accuracy: 0.3071 - val_loss: 1.4273 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3386 - accuracy: 0.4105 - val_loss: 1.4371 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.3110 - accuracy: 0.4105 - val_loss: 1.4665 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2826 - accuracy: 0.4043 - val_loss: 1.5017 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2577 - accuracy: 0.4043 - val_loss: 1.5421 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2381 - accuracy: 0.4120 - val_loss: 1.5823 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2272 - accuracy: 0.4120 - val_loss: 1.6028 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2170 - accuracy: 0.4105 - val_loss: 1.6010 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2088 - accuracy: 0.4105 - val_loss: 1.5899 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2036 - accuracy: 0.4136 - val_loss: 1.5830 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1990 - accuracy: 0.4136 - val_loss: 1.5865 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1962 - accuracy: 0.4198 - val_loss: 1.5779 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1939 - accuracy: 0.4228 - val_loss: 1.5720 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1913 - accuracy: 0.4259 - val_loss: 1.5765 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1888 - accuracy: 0.4352 - val_loss: 1.5766 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1860 - accuracy: 0.4336 - val_loss: 1.5803 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1834 - accuracy: 0.4306 - val_loss: 1.5874 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1818 - accuracy: 0.4306 - val_loss: 1.5891 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1806 - accuracy: 0.4306 - val_loss: 1.5893 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1794 - accuracy: 0.4336 - val_loss: 1.5859 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1780 - accuracy: 0.4352 - val_loss: 1.5842 - val_accuracy: 0.0000e+00\n",
      "Epoch 00022: early stopping\n",
      "\n",
      "Trainning fold 5\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_272 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_273 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_274 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_184 (MaxPooli  (None, 12, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_184 (Flatten)       (None, 192)               0         \n",
      "                                                                 \n",
      " dense_408 (Dense)           (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_409 (Dense)           (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,292\n",
      "Trainable params: 14,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 200ms/step - loss: 1.3835 - accuracy: 0.2917 - val_loss: 1.3901 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3643 - accuracy: 0.4151 - val_loss: 1.4091 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3473 - accuracy: 0.4151 - val_loss: 1.4341 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.3265 - accuracy: 0.4136 - val_loss: 1.4613 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.3041 - accuracy: 0.4136 - val_loss: 1.4976 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2787 - accuracy: 0.4120 - val_loss: 1.5400 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2534 - accuracy: 0.4136 - val_loss: 1.5957 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2308 - accuracy: 0.4151 - val_loss: 1.6672 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2191 - accuracy: 0.4151 - val_loss: 1.7455 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2140 - accuracy: 0.4167 - val_loss: 1.7927 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2114 - accuracy: 0.4198 - val_loss: 1.7837 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2056 - accuracy: 0.4213 - val_loss: 1.7301 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1953 - accuracy: 0.4213 - val_loss: 1.6311 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1884 - accuracy: 0.4414 - val_loss: 1.5230 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1864 - accuracy: 0.4568 - val_loss: 1.4455 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1848 - accuracy: 0.4660 - val_loss: 1.4132 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1804 - accuracy: 0.4660 - val_loss: 1.4322 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1759 - accuracy: 0.4614 - val_loss: 1.4752 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1715 - accuracy: 0.4552 - val_loss: 1.4973 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1701 - accuracy: 0.4599 - val_loss: 1.5003 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1679 - accuracy: 0.4568 - val_loss: 1.4793 - val_accuracy: 0.0139\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 6\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_275 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_276 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_277 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_185 (MaxPooli  (None, 12, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_185 (Flatten)       (None, 192)               0         \n",
      "                                                                 \n",
      " dense_410 (Dense)           (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_411 (Dense)           (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,292\n",
      "Trainable params: 14,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 222ms/step - loss: 1.4046 - accuracy: 0.2778 - val_loss: 1.4583 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3738 - accuracy: 0.2762 - val_loss: 1.4594 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.3522 - accuracy: 0.2870 - val_loss: 1.4760 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3280 - accuracy: 0.4414 - val_loss: 1.5180 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2991 - accuracy: 0.4290 - val_loss: 1.5749 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2685 - accuracy: 0.4228 - val_loss: 1.6531 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2372 - accuracy: 0.4244 - val_loss: 1.7264 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2153 - accuracy: 0.4275 - val_loss: 1.7764 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2012 - accuracy: 0.4275 - val_loss: 1.7662 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1955 - accuracy: 0.4306 - val_loss: 1.7084 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1867 - accuracy: 0.4321 - val_loss: 1.6099 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1755 - accuracy: 0.4506 - val_loss: 1.5365 - val_accuracy: 0.0139\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1834 - accuracy: 0.4753 - val_loss: 1.5339 - val_accuracy: 0.0139\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1803 - accuracy: 0.4691 - val_loss: 1.5916 - val_accuracy: 0.0139\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1676 - accuracy: 0.4583 - val_loss: 1.6598 - val_accuracy: 0.0139\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1656 - accuracy: 0.4614 - val_loss: 1.6824 - val_accuracy: 0.0139\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1635 - accuracy: 0.4660 - val_loss: 1.6357 - val_accuracy: 0.0139\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1595 - accuracy: 0.4691 - val_loss: 1.5833 - val_accuracy: 0.0139\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1563 - accuracy: 0.4738 - val_loss: 1.5503 - val_accuracy: 0.0139\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1562 - accuracy: 0.4784 - val_loss: 1.5498 - val_accuracy: 0.0139\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1531 - accuracy: 0.4799 - val_loss: 1.6066 - val_accuracy: 0.0139\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 7\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_278 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_279 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_280 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_186 (MaxPooli  (None, 12, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_186 (Flatten)       (None, 192)               0         \n",
      "                                                                 \n",
      " dense_412 (Dense)           (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,292\n",
      "Trainable params: 14,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 239ms/step - loss: 1.3922 - accuracy: 0.2670 - val_loss: 1.4491 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3622 - accuracy: 0.4275 - val_loss: 1.4877 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3365 - accuracy: 0.4367 - val_loss: 1.5387 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3096 - accuracy: 0.4259 - val_loss: 1.5958 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2823 - accuracy: 0.4244 - val_loss: 1.6664 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2604 - accuracy: 0.4228 - val_loss: 1.7522 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2481 - accuracy: 0.4198 - val_loss: 1.8419 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2439 - accuracy: 0.4244 - val_loss: 1.9137 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2344 - accuracy: 0.4275 - val_loss: 1.9548 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2229 - accuracy: 0.4336 - val_loss: 1.9778 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2180 - accuracy: 0.4475 - val_loss: 1.9871 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2162 - accuracy: 0.4568 - val_loss: 1.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2062 - accuracy: 0.4614 - val_loss: 1.9222 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1941 - accuracy: 0.4599 - val_loss: 1.8692 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1870 - accuracy: 0.4614 - val_loss: 1.8003 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1832 - accuracy: 0.4614 - val_loss: 1.7198 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1811 - accuracy: 0.4599 - val_loss: 1.6344 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1740 - accuracy: 0.4630 - val_loss: 1.5519 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1713 - accuracy: 0.4722 - val_loss: 1.5092 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1740 - accuracy: 0.4877 - val_loss: 1.5281 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1675 - accuracy: 0.4784 - val_loss: 1.5798 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 8\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_281 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_282 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_283 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_187 (MaxPooli  (None, 12, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_187 (Flatten)       (None, 192)               0         \n",
      "                                                                 \n",
      " dense_414 (Dense)           (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_415 (Dense)           (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,292\n",
      "Trainable params: 14,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 1.4057 - accuracy: 0.1389 - val_loss: 1.4299 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3579 - accuracy: 0.2762 - val_loss: 1.4635 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3225 - accuracy: 0.3997 - val_loss: 1.4977 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2898 - accuracy: 0.4182 - val_loss: 1.5376 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2629 - accuracy: 0.4182 - val_loss: 1.5834 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2427 - accuracy: 0.4198 - val_loss: 1.6465 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2293 - accuracy: 0.4182 - val_loss: 1.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2182 - accuracy: 0.4213 - val_loss: 1.7515 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2049 - accuracy: 0.4244 - val_loss: 1.7739 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1953 - accuracy: 0.4275 - val_loss: 1.7998 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1877 - accuracy: 0.4475 - val_loss: 1.8285 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1805 - accuracy: 0.4537 - val_loss: 1.8434 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1764 - accuracy: 0.4552 - val_loss: 1.8158 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1749 - accuracy: 0.4522 - val_loss: 1.7491 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1699 - accuracy: 0.4537 - val_loss: 1.6765 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1648 - accuracy: 0.4522 - val_loss: 1.6147 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1620 - accuracy: 0.4614 - val_loss: 1.5608 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1605 - accuracy: 0.4691 - val_loss: 1.5290 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1593 - accuracy: 0.4707 - val_loss: 1.5239 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1571 - accuracy: 0.4784 - val_loss: 1.5277 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1541 - accuracy: 0.4830 - val_loss: 1.5262 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 9\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_284 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_285 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_286 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_188 (MaxPooli  (None, 12, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_188 (Flatten)       (None, 192)               0         \n",
      "                                                                 \n",
      " dense_416 (Dense)           (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_417 (Dense)           (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,292\n",
      "Trainable params: 14,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 206ms/step - loss: 1.4092 - accuracy: 0.2809 - val_loss: 1.4037 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3700 - accuracy: 0.3688 - val_loss: 1.4106 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3504 - accuracy: 0.3580 - val_loss: 1.4211 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3285 - accuracy: 0.4074 - val_loss: 1.4424 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3006 - accuracy: 0.4290 - val_loss: 1.4784 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2671 - accuracy: 0.4275 - val_loss: 1.5248 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2359 - accuracy: 0.4290 - val_loss: 1.5890 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.2117 - accuracy: 0.4352 - val_loss: 1.6747 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1951 - accuracy: 0.4367 - val_loss: 1.7764 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1860 - accuracy: 0.4367 - val_loss: 1.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1809 - accuracy: 0.4398 - val_loss: 1.8940 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1764 - accuracy: 0.4506 - val_loss: 1.8699 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1706 - accuracy: 0.4630 - val_loss: 1.8143 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1628 - accuracy: 0.4676 - val_loss: 1.7546 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1608 - accuracy: 0.4738 - val_loss: 1.6939 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1582 - accuracy: 0.4799 - val_loss: 1.6495 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1560 - accuracy: 0.4877 - val_loss: 1.6321 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1512 - accuracy: 0.4846 - val_loss: 1.6446 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1474 - accuracy: 0.4830 - val_loss: 1.6544 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1472 - accuracy: 0.4830 - val_loss: 1.6517 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1448 - accuracy: 0.4846 - val_loss: 1.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 10\n",
      "Model: \"sequential_189\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_287 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_288 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_289 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_189 (MaxPooli  (None, 12, 16)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_189 (Flatten)       (None, 192)               0         \n",
      "                                                                 \n",
      " dense_418 (Dense)           (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,292\n",
      "Trainable params: 14,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 188ms/step - loss: 1.4085 - accuracy: 0.2407 - val_loss: 1.4821 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3583 - accuracy: 0.3287 - val_loss: 1.5321 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3311 - accuracy: 0.4244 - val_loss: 1.5815 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3057 - accuracy: 0.4151 - val_loss: 1.6432 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2744 - accuracy: 0.4167 - val_loss: 1.7156 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2490 - accuracy: 0.4167 - val_loss: 1.7767 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2270 - accuracy: 0.4136 - val_loss: 1.7893 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2082 - accuracy: 0.4136 - val_loss: 1.7762 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1969 - accuracy: 0.4105 - val_loss: 1.7632 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1929 - accuracy: 0.4105 - val_loss: 1.7437 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1928 - accuracy: 0.4120 - val_loss: 1.7122 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1930 - accuracy: 0.4136 - val_loss: 1.6743 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1908 - accuracy: 0.4151 - val_loss: 1.6317 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1881 - accuracy: 0.4182 - val_loss: 1.5996 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1856 - accuracy: 0.4244 - val_loss: 1.5823 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1853 - accuracy: 0.4290 - val_loss: 1.5600 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1847 - accuracy: 0.4336 - val_loss: 1.5390 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1833 - accuracy: 0.4336 - val_loss: 1.5344 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1810 - accuracy: 0.4336 - val_loss: 1.5408 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1790 - accuracy: 0.4321 - val_loss: 1.5501 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1775 - accuracy: 0.4336 - val_loss: 1.5607 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Time taken for training:  00:00:20\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.4375 - Test Accuracy 0.4625\n",
      "Fold 2 - Train Accuracy 0.4278 - Test Accuracy 0.4250\n",
      "Fold 3 - Train Accuracy 0.4458 - Test Accuracy 0.4125\n",
      "Fold 4 - Train Accuracy 0.3958 - Test Accuracy 0.4875\n",
      "Fold 5 - Train Accuracy 0.4181 - Test Accuracy 0.3875\n",
      "Fold 6 - Train Accuracy 0.4264 - Test Accuracy 0.3250\n",
      "Fold 7 - Train Accuracy 0.4264 - Test Accuracy 0.4500\n",
      "Fold 8 - Train Accuracy 0.4333 - Test Accuracy 0.4250\n",
      "Fold 9 - Train Accuracy 0.4403 - Test Accuracy 0.3250\n",
      "Fold 10 - Train Accuracy 0.3903 - Test Accuracy 0.4375\n",
      "\n",
      "Mean Train Accuracy: 0.4242 \n",
      "Mean Test Accuracy: 0.4137 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_features = 1\n",
    "\n",
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = \"relu\", input_shape = (number_of_steps, number_of_features)))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dense(4, activation = 'softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Defining the number of folds (10 k-Fold).\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Normalize data using box-cox method.\n",
    "pt = PowerTransformer()\n",
    "pt.fit(X_resampled)\n",
    "X_resampled = pt.transform(X_resampled)\n",
    "\n",
    "# Reshape the structure data to be compatible with pattern [samples, timesteps, features].\n",
    "X_train_reshaped = X_resampled.reshape((X_resampled.shape[0], number_of_steps, number_of_features))\n",
    "\n",
    "\n",
    "# Train the CNN model and evaluate it.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training at: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 20)\n",
    "\n",
    "train_accuracy_by_fold = []\n",
    "test_accuracy_by_fold = []\n",
    "fold_number = 1\n",
    "for train_index, test_index in skf.split(X_train_reshaped, y_resampled):\n",
    "    print(\"\\nTraining fold {}\".format(fold_number))\n",
    "    model = create_baseline()\n",
    "    history = model.fit(X_train_reshaped[train_index], y_resampled[train_index], validation_split = 0.1,\n",
    "                            epochs = 300, batch_size = 512, verbose = 1, callbacks = [es])\n",
    "    _, train_accuracy = model.evaluate(X_train_reshaped[train_index], y_resampled[train_index], verbose = 0)\n",
    "    _, test_accuracy = model.evaluate(X_train_reshaped[test_index], y_resampled[test_index], verbose = 0)\n",
    "    train_accuracy_by_fold.append(train_accuracy)\n",
    "    test_accuracy_by_fold.append(test_accuracy)\n",
    "    fold_number += 1\n",
    "\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show metrics.\n",
    "for i in range(len(train_accuracy_by_fold)):\n",
    "    print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "                            train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "print(\"\\nMean Train Accuracy: {:.4f} \".format(np.mean(train_accuracy_by_fold)))\n",
    "print(\"Mean Test Accuracy: {:.4f} \".format(np.mean(test_accuracy_by_fold)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ba9740",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + MaxPooling1D + Flatten + Dense (128) + Dense (4)\n",
    "- 800 samples (no data augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fe81eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training at:  21:52:14\n",
      "\n",
      "Trainning fold 1\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_370 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_270 (MaxPooli  (None, 14, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_250 (Flatten)       (None, 896)               0         \n",
      "                                                                 \n",
      " dense_540 (Dense)           (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_541 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,588\n",
      "Trainable params: 115,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 191ms/step - loss: 1.3407 - accuracy: 0.3981 - val_loss: 1.5294 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.2189 - accuracy: 0.4213 - val_loss: 1.6733 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.2025 - accuracy: 0.4213 - val_loss: 1.6928 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1885 - accuracy: 0.4136 - val_loss: 1.6451 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1806 - accuracy: 0.4182 - val_loss: 1.6202 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1859 - accuracy: 0.4475 - val_loss: 1.6006 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1829 - accuracy: 0.4491 - val_loss: 1.6206 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1743 - accuracy: 0.4429 - val_loss: 1.6595 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1708 - accuracy: 0.4367 - val_loss: 1.6839 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1683 - accuracy: 0.4444 - val_loss: 1.6775 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1647 - accuracy: 0.4552 - val_loss: 1.6604 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1614 - accuracy: 0.4753 - val_loss: 1.6098 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1585 - accuracy: 0.4799 - val_loss: 1.5760 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1535 - accuracy: 0.4830 - val_loss: 1.5909 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1484 - accuracy: 0.4815 - val_loss: 1.6501 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1515 - accuracy: 0.4799 - val_loss: 1.6679 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1461 - accuracy: 0.4861 - val_loss: 1.5947 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1400 - accuracy: 0.4923 - val_loss: 1.5552 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1411 - accuracy: 0.4923 - val_loss: 1.5710 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1367 - accuracy: 0.4954 - val_loss: 1.6367 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1300 - accuracy: 0.4969 - val_loss: 1.6790 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 2\n",
      "Model: \"sequential_251\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_371 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_271 (MaxPooli  (None, 14, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_251 (Flatten)       (None, 896)               0         \n",
      "                                                                 \n",
      " dense_542 (Dense)           (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_543 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,588\n",
      "Trainable params: 115,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 175ms/step - loss: 1.3161 - accuracy: 0.4198 - val_loss: 1.7231 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2226 - accuracy: 0.4213 - val_loss: 1.8040 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2042 - accuracy: 0.4198 - val_loss: 1.6469 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1885 - accuracy: 0.4228 - val_loss: 1.5253 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1954 - accuracy: 0.4321 - val_loss: 1.5272 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1921 - accuracy: 0.4398 - val_loss: 1.6127 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1816 - accuracy: 0.4444 - val_loss: 1.7511 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1784 - accuracy: 0.4414 - val_loss: 1.7891 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1803 - accuracy: 0.4383 - val_loss: 1.7133 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1729 - accuracy: 0.4537 - val_loss: 1.5987 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1657 - accuracy: 0.4707 - val_loss: 1.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1663 - accuracy: 0.4830 - val_loss: 1.5783 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1637 - accuracy: 0.4892 - val_loss: 1.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1586 - accuracy: 0.4938 - val_loss: 1.6840 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1540 - accuracy: 0.4954 - val_loss: 1.6681 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1515 - accuracy: 0.4923 - val_loss: 1.5871 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1482 - accuracy: 0.4938 - val_loss: 1.5654 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1459 - accuracy: 0.4954 - val_loss: 1.6199 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.1426 - accuracy: 0.4954 - val_loss: 1.6780 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1389 - accuracy: 0.5000 - val_loss: 1.7034 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1378 - accuracy: 0.5015 - val_loss: 1.7255 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1366 - accuracy: 0.5031 - val_loss: 1.7859 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1367 - accuracy: 0.5000 - val_loss: 1.7745 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1315 - accuracy: 0.5062 - val_loss: 1.6766 - val_accuracy: 0.0000e+00\n",
      "Epoch 00024: early stopping\n",
      "\n",
      "Trainning fold 3\n",
      "Model: \"sequential_252\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_372 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_272 (MaxPooli  (None, 14, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_252 (Flatten)       (None, 896)               0         \n",
      "                                                                 \n",
      " dense_544 (Dense)           (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_545 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,588\n",
      "Trainable params: 115,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 697ms/step - loss: 1.4146 - accuracy: 0.2253 - val_loss: 1.5046 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2275 - accuracy: 0.4198 - val_loss: 1.6350 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2016 - accuracy: 0.4228 - val_loss: 1.7079 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1957 - accuracy: 0.4275 - val_loss: 1.7164 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1976 - accuracy: 0.4398 - val_loss: 1.6884 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1971 - accuracy: 0.4522 - val_loss: 1.6640 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1880 - accuracy: 0.4506 - val_loss: 1.6449 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1797 - accuracy: 0.4522 - val_loss: 1.6455 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1787 - accuracy: 0.4491 - val_loss: 1.6666 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1777 - accuracy: 0.4568 - val_loss: 1.6505 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1720 - accuracy: 0.4614 - val_loss: 1.6154 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1676 - accuracy: 0.4691 - val_loss: 1.5871 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1670 - accuracy: 0.4830 - val_loss: 1.5812 - val_accuracy: 0.0139\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1632 - accuracy: 0.4846 - val_loss: 1.6131 - val_accuracy: 0.0139\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1599 - accuracy: 0.4846 - val_loss: 1.6484 - val_accuracy: 0.0139\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1576 - accuracy: 0.4892 - val_loss: 1.6885 - val_accuracy: 0.0139\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1548 - accuracy: 0.4954 - val_loss: 1.7285 - val_accuracy: 0.0139\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1527 - accuracy: 0.4907 - val_loss: 1.7476 - val_accuracy: 0.0139\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1504 - accuracy: 0.4954 - val_loss: 1.7326 - val_accuracy: 0.0139\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1491 - accuracy: 0.5077 - val_loss: 1.6598 - val_accuracy: 0.0139\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1436 - accuracy: 0.5031 - val_loss: 1.5778 - val_accuracy: 0.0139\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 4\n",
      "Model: \"sequential_253\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_373 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_273 (MaxPooli  (None, 14, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_253 (Flatten)       (None, 896)               0         \n",
      "                                                                 \n",
      " dense_546 (Dense)           (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_547 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,588\n",
      "Trainable params: 115,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 200ms/step - loss: 1.3358 - accuracy: 0.3194 - val_loss: 1.5665 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2299 - accuracy: 0.4182 - val_loss: 1.6520 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2083 - accuracy: 0.4136 - val_loss: 1.5612 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1944 - accuracy: 0.4182 - val_loss: 1.5268 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1876 - accuracy: 0.4182 - val_loss: 1.5508 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1912 - accuracy: 0.4244 - val_loss: 1.6071 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1907 - accuracy: 0.4290 - val_loss: 1.6385 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1847 - accuracy: 0.4367 - val_loss: 1.6160 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1833 - accuracy: 0.4383 - val_loss: 1.5847 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1824 - accuracy: 0.4414 - val_loss: 1.5715 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1795 - accuracy: 0.4444 - val_loss: 1.6121 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1767 - accuracy: 0.4506 - val_loss: 1.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1744 - accuracy: 0.4506 - val_loss: 1.6212 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1715 - accuracy: 0.4537 - val_loss: 1.5633 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1689 - accuracy: 0.4599 - val_loss: 1.5448 - val_accuracy: 0.0139\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1681 - accuracy: 0.4614 - val_loss: 1.5484 - val_accuracy: 0.0139\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1654 - accuracy: 0.4660 - val_loss: 1.5650 - val_accuracy: 0.0139\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1621 - accuracy: 0.4660 - val_loss: 1.5719 - val_accuracy: 0.0139\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1594 - accuracy: 0.4722 - val_loss: 1.5790 - val_accuracy: 0.0139\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1580 - accuracy: 0.4707 - val_loss: 1.5716 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1554 - accuracy: 0.4784 - val_loss: 1.5537 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1526 - accuracy: 0.4923 - val_loss: 1.5411 - val_accuracy: 0.0139\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1491 - accuracy: 0.4923 - val_loss: 1.5305 - val_accuracy: 0.0139\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1470 - accuracy: 0.4907 - val_loss: 1.5590 - val_accuracy: 0.0139\n",
      "Epoch 00024: early stopping\n",
      "\n",
      "Trainning fold 5\n",
      "Model: \"sequential_254\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_374 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_274 (MaxPooli  (None, 14, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_254 (Flatten)       (None, 896)               0         \n",
      "                                                                 \n",
      " dense_548 (Dense)           (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_549 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,588\n",
      "Trainable params: 115,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 1.3746 - accuracy: 0.2330 - val_loss: 1.5342 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2279 - accuracy: 0.4228 - val_loss: 1.7012 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1943 - accuracy: 0.4228 - val_loss: 1.6776 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1895 - accuracy: 0.4182 - val_loss: 1.6014 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1848 - accuracy: 0.4167 - val_loss: 1.6020 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1798 - accuracy: 0.4244 - val_loss: 1.6275 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1804 - accuracy: 0.4336 - val_loss: 1.5967 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1773 - accuracy: 0.4444 - val_loss: 1.5842 - val_accuracy: 0.0139\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1713 - accuracy: 0.4506 - val_loss: 1.6054 - val_accuracy: 0.0139\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1665 - accuracy: 0.4676 - val_loss: 1.6209 - val_accuracy: 0.0139\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1638 - accuracy: 0.4753 - val_loss: 1.6302 - val_accuracy: 0.0139\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1607 - accuracy: 0.4769 - val_loss: 1.6121 - val_accuracy: 0.0139\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1554 - accuracy: 0.4799 - val_loss: 1.5788 - val_accuracy: 0.0139\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1509 - accuracy: 0.4830 - val_loss: 1.5595 - val_accuracy: 0.0139\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1478 - accuracy: 0.4861 - val_loss: 1.5311 - val_accuracy: 0.0139\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1462 - accuracy: 0.4830 - val_loss: 1.5121 - val_accuracy: 0.0139\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1429 - accuracy: 0.4846 - val_loss: 1.5624 - val_accuracy: 0.0139\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1398 - accuracy: 0.4877 - val_loss: 1.6275 - val_accuracy: 0.0139\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1370 - accuracy: 0.4923 - val_loss: 1.6449 - val_accuracy: 0.0139\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1321 - accuracy: 0.4938 - val_loss: 1.6109 - val_accuracy: 0.0139\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1307 - accuracy: 0.4985 - val_loss: 1.5884 - val_accuracy: 0.0139\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1293 - accuracy: 0.5015 - val_loss: 1.5999 - val_accuracy: 0.0139\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1234 - accuracy: 0.5015 - val_loss: 1.6554 - val_accuracy: 0.0139\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1243 - accuracy: 0.4954 - val_loss: 1.6547 - val_accuracy: 0.0139\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1240 - accuracy: 0.4954 - val_loss: 1.5866 - val_accuracy: 0.0139\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1181 - accuracy: 0.4969 - val_loss: 1.5355 - val_accuracy: 0.0139\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1203 - accuracy: 0.5077 - val_loss: 1.5466 - val_accuracy: 0.0139\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1174 - accuracy: 0.5046 - val_loss: 1.6231 - val_accuracy: 0.0139\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1127 - accuracy: 0.5046 - val_loss: 1.6397 - val_accuracy: 0.0139\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1139 - accuracy: 0.5015 - val_loss: 1.5736 - val_accuracy: 0.0139\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1121 - accuracy: 0.5000 - val_loss: 1.5484 - val_accuracy: 0.0139\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1065 - accuracy: 0.5201 - val_loss: 1.6220 - val_accuracy: 0.0139\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1074 - accuracy: 0.5093 - val_loss: 1.7249 - val_accuracy: 0.0139\n",
      "Epoch 34/300\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1059 - accuracy: 0.5077 - val_loss: 1.7762 - val_accuracy: 0.0139\n",
      "Epoch 35/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1065 - accuracy: 0.5062 - val_loss: 1.7108 - val_accuracy: 0.0139\n",
      "Epoch 36/300\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1031 - accuracy: 0.5077 - val_loss: 1.6228 - val_accuracy: 0.0139\n",
      "Epoch 00036: early stopping\n",
      "\n",
      "Trainning fold 6\n",
      "Model: \"sequential_255\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_375 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_275 (MaxPooli  (None, 14, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_255 (Flatten)       (None, 896)               0         \n",
      "                                                                 \n",
      " dense_550 (Dense)           (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_551 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,588\n",
      "Trainable params: 115,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 215ms/step - loss: 1.3728 - accuracy: 0.3025 - val_loss: 1.4884 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1978 - accuracy: 0.4244 - val_loss: 1.6410 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1858 - accuracy: 0.4228 - val_loss: 1.7431 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1851 - accuracy: 0.4213 - val_loss: 1.7156 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1807 - accuracy: 0.4321 - val_loss: 1.6602 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1799 - accuracy: 0.4383 - val_loss: 1.6487 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1743 - accuracy: 0.4460 - val_loss: 1.6871 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1661 - accuracy: 0.4552 - val_loss: 1.7142 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1599 - accuracy: 0.4614 - val_loss: 1.6894 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1547 - accuracy: 0.4691 - val_loss: 1.5976 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1531 - accuracy: 0.4769 - val_loss: 1.5711 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1504 - accuracy: 0.4892 - val_loss: 1.6020 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1448 - accuracy: 0.4938 - val_loss: 1.6376 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1400 - accuracy: 0.4969 - val_loss: 1.6841 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1386 - accuracy: 0.5046 - val_loss: 1.6986 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1338 - accuracy: 0.5062 - val_loss: 1.6652 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1310 - accuracy: 0.5077 - val_loss: 1.6557 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.1286 - accuracy: 0.5077 - val_loss: 1.6904 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1252 - accuracy: 0.5139 - val_loss: 1.7436 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1223 - accuracy: 0.5154 - val_loss: 1.7479 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1182 - accuracy: 0.5123 - val_loss: 1.7385 - val_accuracy: 0.0139\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 7\n",
      "Model: \"sequential_256\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_376 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_276 (MaxPooli  (None, 14, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_256 (Flatten)       (None, 896)               0         \n",
      "                                                                 \n",
      " dense_552 (Dense)           (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_553 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,588\n",
      "Trainable params: 115,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 325ms/step - loss: 1.3471 - accuracy: 0.3071 - val_loss: 1.5655 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.2188 - accuracy: 0.4136 - val_loss: 1.6186 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.2014 - accuracy: 0.4167 - val_loss: 1.6490 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1919 - accuracy: 0.4151 - val_loss: 1.6487 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1879 - accuracy: 0.4367 - val_loss: 1.6163 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1846 - accuracy: 0.4352 - val_loss: 1.5946 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1807 - accuracy: 0.4398 - val_loss: 1.6107 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1777 - accuracy: 0.4444 - val_loss: 1.6018 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1763 - accuracy: 0.4491 - val_loss: 1.5685 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.1747 - accuracy: 0.4506 - val_loss: 1.5099 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1715 - accuracy: 0.4599 - val_loss: 1.5228 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1681 - accuracy: 0.4599 - val_loss: 1.5662 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.1622 - accuracy: 0.4630 - val_loss: 1.5851 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.1590 - accuracy: 0.4676 - val_loss: 1.6285 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.1565 - accuracy: 0.4707 - val_loss: 1.6616 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.1532 - accuracy: 0.4784 - val_loss: 1.6592 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.1495 - accuracy: 0.4861 - val_loss: 1.6694 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.1465 - accuracy: 0.4907 - val_loss: 1.6777 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.1443 - accuracy: 0.4923 - val_loss: 1.6842 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.1435 - accuracy: 0.4985 - val_loss: 1.6886 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.1400 - accuracy: 0.5046 - val_loss: 1.6871 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.1379 - accuracy: 0.5077 - val_loss: 1.6692 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.1367 - accuracy: 0.5000 - val_loss: 1.6355 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1338 - accuracy: 0.5077 - val_loss: 1.6189 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.1334 - accuracy: 0.5139 - val_loss: 1.6323 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.1331 - accuracy: 0.5077 - val_loss: 1.6806 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1302 - accuracy: 0.5108 - val_loss: 1.7122 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1263 - accuracy: 0.5093 - val_loss: 1.6745 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.1269 - accuracy: 0.5077 - val_loss: 1.6451 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.1265 - accuracy: 0.5093 - val_loss: 1.6537 - val_accuracy: 0.0000e+00\n",
      "Epoch 00030: early stopping\n",
      "\n",
      "Trainning fold 8\n",
      "Model: \"sequential_257\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_377 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_277 (MaxPooli  (None, 14, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_257 (Flatten)       (None, 896)               0         \n",
      "                                                                 \n",
      " dense_554 (Dense)           (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_555 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,588\n",
      "Trainable params: 115,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 2s 685ms/step - loss: 1.3379 - accuracy: 0.3611 - val_loss: 1.5704 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1968 - accuracy: 0.4259 - val_loss: 1.6061 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1801 - accuracy: 0.4213 - val_loss: 1.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1761 - accuracy: 0.4306 - val_loss: 1.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1728 - accuracy: 0.4398 - val_loss: 1.6811 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1714 - accuracy: 0.4398 - val_loss: 1.6315 - val_accuracy: 0.0139\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1696 - accuracy: 0.4444 - val_loss: 1.5510 - val_accuracy: 0.0139\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1687 - accuracy: 0.4475 - val_loss: 1.5199 - val_accuracy: 0.0139\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1682 - accuracy: 0.4522 - val_loss: 1.5070 - val_accuracy: 0.0139\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1640 - accuracy: 0.4599 - val_loss: 1.5195 - val_accuracy: 0.0139\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1605 - accuracy: 0.4506 - val_loss: 1.5702 - val_accuracy: 0.0139\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1580 - accuracy: 0.4537 - val_loss: 1.6169 - val_accuracy: 0.0139\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1544 - accuracy: 0.4599 - val_loss: 1.6175 - val_accuracy: 0.0139\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1517 - accuracy: 0.4691 - val_loss: 1.6291 - val_accuracy: 0.0139\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1499 - accuracy: 0.4707 - val_loss: 1.6390 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1477 - accuracy: 0.4753 - val_loss: 1.6391 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1445 - accuracy: 0.4799 - val_loss: 1.6181 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1436 - accuracy: 0.4954 - val_loss: 1.6144 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.1418 - accuracy: 0.4938 - val_loss: 1.6204 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1377 - accuracy: 0.4923 - val_loss: 1.6151 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1349 - accuracy: 0.4938 - val_loss: 1.6549 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1316 - accuracy: 0.4954 - val_loss: 1.6715 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1303 - accuracy: 0.4969 - val_loss: 1.6615 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1316 - accuracy: 0.4985 - val_loss: 1.6596 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.1293 - accuracy: 0.4985 - val_loss: 1.7248 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1258 - accuracy: 0.5000 - val_loss: 1.7290 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1237 - accuracy: 0.4969 - val_loss: 1.6590 - val_accuracy: 0.0139\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1206 - accuracy: 0.5000 - val_loss: 1.5908 - val_accuracy: 0.0278\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1203 - accuracy: 0.5015 - val_loss: 1.6549 - val_accuracy: 0.0139\n",
      "Epoch 00029: early stopping\n",
      "\n",
      "Trainning fold 9\n",
      "Model: \"sequential_258\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_378 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_278 (MaxPooli  (None, 14, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_258 (Flatten)       (None, 896)               0         \n",
      "                                                                 \n",
      " dense_556 (Dense)           (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_557 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,588\n",
      "Trainable params: 115,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 1.3284 - accuracy: 0.3472 - val_loss: 1.4938 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.2090 - accuracy: 0.4213 - val_loss: 1.5921 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1815 - accuracy: 0.4306 - val_loss: 1.6419 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1760 - accuracy: 0.4429 - val_loss: 1.6402 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1780 - accuracy: 0.4614 - val_loss: 1.6231 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1687 - accuracy: 0.4537 - val_loss: 1.6305 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1660 - accuracy: 0.4475 - val_loss: 1.6732 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1653 - accuracy: 0.4460 - val_loss: 1.7183 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1619 - accuracy: 0.4491 - val_loss: 1.7318 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1575 - accuracy: 0.4583 - val_loss: 1.7435 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1527 - accuracy: 0.4738 - val_loss: 1.7432 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1480 - accuracy: 0.4815 - val_loss: 1.7202 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1445 - accuracy: 0.4815 - val_loss: 1.6966 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1420 - accuracy: 0.4815 - val_loss: 1.6825 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1381 - accuracy: 0.4907 - val_loss: 1.6917 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1344 - accuracy: 0.4938 - val_loss: 1.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1332 - accuracy: 0.4954 - val_loss: 1.6749 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1286 - accuracy: 0.5046 - val_loss: 1.5974 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1313 - accuracy: 0.5077 - val_loss: 1.5485 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1280 - accuracy: 0.5108 - val_loss: 1.5697 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1220 - accuracy: 0.5031 - val_loss: 1.6830 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Trainning fold 10\n",
      "Model: \"sequential_259\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_379 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_279 (MaxPooli  (None, 14, 64)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_259 (Flatten)       (None, 896)               0         \n",
      "                                                                 \n",
      " dense_558 (Dense)           (None, 128)               114816    \n",
      "                                                                 \n",
      " dense_559 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,588\n",
      "Trainable params: 115,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 1.3918 - accuracy: 0.2392 - val_loss: 1.5098 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.2243 - accuracy: 0.4136 - val_loss: 1.6103 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.2257 - accuracy: 0.4151 - val_loss: 1.6443 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.2065 - accuracy: 0.4182 - val_loss: 1.6368 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1852 - accuracy: 0.4259 - val_loss: 1.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1909 - accuracy: 0.4460 - val_loss: 1.7127 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.2014 - accuracy: 0.4599 - val_loss: 1.6959 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1891 - accuracy: 0.4552 - val_loss: 1.6954 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1774 - accuracy: 0.4491 - val_loss: 1.6952 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1749 - accuracy: 0.4414 - val_loss: 1.6789 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1746 - accuracy: 0.4444 - val_loss: 1.6415 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1696 - accuracy: 0.4475 - val_loss: 1.6169 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1630 - accuracy: 0.4537 - val_loss: 1.5738 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1599 - accuracy: 0.4769 - val_loss: 1.5391 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1586 - accuracy: 0.4784 - val_loss: 1.5470 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1557 - accuracy: 0.4877 - val_loss: 1.5870 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1513 - accuracy: 0.4907 - val_loss: 1.6043 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1483 - accuracy: 0.4799 - val_loss: 1.6195 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1478 - accuracy: 0.4830 - val_loss: 1.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1450 - accuracy: 0.4815 - val_loss: 1.5952 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1423 - accuracy: 0.4892 - val_loss: 1.5941 - val_accuracy: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "Time taken for training:  00:00:29\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.4514 - Test Accuracy 0.4750\n",
      "Fold 2 - Train Accuracy 0.4569 - Test Accuracy 0.4500\n",
      "Fold 3 - Train Accuracy 0.4514 - Test Accuracy 0.4125\n",
      "Fold 4 - Train Accuracy 0.4444 - Test Accuracy 0.5375\n",
      "Fold 5 - Train Accuracy 0.4667 - Test Accuracy 0.4250\n",
      "Fold 6 - Train Accuracy 0.4639 - Test Accuracy 0.3625\n",
      "Fold 7 - Train Accuracy 0.4583 - Test Accuracy 0.4500\n",
      "Fold 8 - Train Accuracy 0.4500 - Test Accuracy 0.4875\n",
      "Fold 9 - Train Accuracy 0.4514 - Test Accuracy 0.3875\n",
      "Fold 10 - Train Accuracy 0.4486 - Test Accuracy 0.4750\n",
      "\n",
      "Mean Train Accuracy: 0.4543 - Std: 0.0066 \n",
      "Mean Test Accuracy: 0.4463 - Std: 0.0488 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.58      0.46       200\n",
      "           1       0.58      0.73      0.65       200\n",
      "           2       0.39      0.47      0.42       200\n",
      "           3       0.33      0.01      0.01       200\n",
      "\n",
      "    accuracy                           0.45       800\n",
      "   macro avg       0.42      0.45      0.39       800\n",
      "weighted avg       0.42      0.45      0.39       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_features = 1\n",
    "\n",
    "def create_v1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = \"relu\", input_shape = (number_of_steps, number_of_features)))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dense(4, activation = 'softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Defining the number of folds (10 k-Fold).\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Normalize data using box-cox method.\n",
    "pt = PowerTransformer()\n",
    "pt.fit(X_resampled)\n",
    "X_resampled = pt.transform(X_resampled)\n",
    "\n",
    "# Reshape the structure data to be compatible with pattern [samples, timesteps, features].\n",
    "X_train_reshaped = X_resampled.reshape((X_resampled.shape[0], number_of_steps, number_of_features))\n",
    "\n",
    "\n",
    "# Train the CNN model and evaluate it.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training at: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 20)\n",
    "\n",
    "train_accuracy_by_fold = []\n",
    "test_accuracy_by_fold = []\n",
    "history_by_fold = []\n",
    "y_predclass_for_report = []\n",
    "y_testclass_for_report = []\n",
    "fold_number = 1\n",
    "for train_index, test_index in skf.split(X_train_reshaped, y_resampled):\n",
    "    print(\"\\nTraining fold {}\".format(fold_number))\n",
    "    model = create_v1()\n",
    "    history = model.fit(X_train_reshaped[train_index], y_resampled[train_index], validation_split = 0.1,\n",
    "                            epochs = 300, batch_size = 512, verbose = 1, callbacks = [es])\n",
    "    _, train_accuracy = model.evaluate(X_train_reshaped[train_index], y_resampled[train_index], verbose = 0)\n",
    "    _, test_accuracy = model.evaluate(X_train_reshaped[test_index], y_resampled[test_index], verbose = 0)\n",
    "    train_accuracy_by_fold.append(train_accuracy)\n",
    "    test_accuracy_by_fold.append(test_accuracy)\n",
    "    history_by_fold.append(history)\n",
    "    y_predclass_for_report.extend(np.argmax(model.predict(X_train_reshaped[test_index]), axis = 1))\n",
    "    y_testclass_for_report.extend(y_resampled[test_index])\n",
    "    fold_number += 1\n",
    "\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show metrics.\n",
    "for i in range(len(train_accuracy_by_fold)):\n",
    "    print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "                            train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "print(\"\\nMean Train Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(train_accuracy_by_fold), np.std(train_accuracy_by_fold)))\n",
    "print(\"Mean Test Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(test_accuracy_by_fold), np.std(test_accuracy_by_fold)))\n",
    "\n",
    "print(\"\\nEvaluate other metrics:\")\n",
    "print(classification_report(y_testclass_for_report, y_predclass_for_report, zero_division = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b486db9",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Flatten + Dense (128) + Dense (128) + Dense (128) + Dense (4)\n",
    "- 800 samples (no data augmentation) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39348e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training at:  23:44:56\n",
      "\n",
      "Training fold 1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 12, 16)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "21/21 [==============================] - 7s 24ms/step - loss: 1.2854 - accuracy: 0.3873 - val_loss: 1.7762 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2085 - accuracy: 0.4259 - val_loss: 1.5014 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1843 - accuracy: 0.4599 - val_loss: 1.6218 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1716 - accuracy: 0.4660 - val_loss: 1.4899 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1700 - accuracy: 0.4738 - val_loss: 1.5970 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1594 - accuracy: 0.4691 - val_loss: 1.7931 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1526 - accuracy: 0.5031 - val_loss: 1.6542 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1392 - accuracy: 0.4938 - val_loss: 1.7421 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1334 - accuracy: 0.4892 - val_loss: 1.5883 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1366 - accuracy: 0.5000 - val_loss: 1.5769 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1253 - accuracy: 0.4877 - val_loss: 1.7365 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1190 - accuracy: 0.4969 - val_loss: 1.7903 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1095 - accuracy: 0.5031 - val_loss: 1.6799 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1112 - accuracy: 0.5139 - val_loss: 1.5722 - val_accuracy: 0.0139\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0845 - accuracy: 0.5231 - val_loss: 1.7647 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0778 - accuracy: 0.5309 - val_loss: 1.6743 - val_accuracy: 0.0417\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0798 - accuracy: 0.5077 - val_loss: 1.6106 - val_accuracy: 0.0694\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0582 - accuracy: 0.5340 - val_loss: 1.7643 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0485 - accuracy: 0.5417 - val_loss: 1.5617 - val_accuracy: 0.0972\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0260 - accuracy: 0.5432 - val_loss: 1.9537 - val_accuracy: 0.0417\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0379 - accuracy: 0.5509 - val_loss: 1.8431 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.0187 - accuracy: 0.5509 - val_loss: 1.8277 - val_accuracy: 0.0694\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.9995 - accuracy: 0.5586 - val_loss: 1.7321 - val_accuracy: 0.1111\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.9934 - accuracy: 0.5772 - val_loss: 1.7418 - val_accuracy: 0.0694\n",
      "Epoch 00024: early stopping\n",
      "\n",
      "Training fold 2\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 12, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "21/21 [==============================] - 1s 17ms/step - loss: 1.3122 - accuracy: 0.3627 - val_loss: 1.5424 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2186 - accuracy: 0.4321 - val_loss: 1.5374 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1906 - accuracy: 0.4660 - val_loss: 1.4998 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1813 - accuracy: 0.4815 - val_loss: 1.6663 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1645 - accuracy: 0.4784 - val_loss: 1.6769 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1536 - accuracy: 0.4892 - val_loss: 1.6162 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1516 - accuracy: 0.4954 - val_loss: 1.6191 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1444 - accuracy: 0.5031 - val_loss: 1.7473 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1520 - accuracy: 0.5015 - val_loss: 1.6535 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1229 - accuracy: 0.5062 - val_loss: 1.7314 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1267 - accuracy: 0.5015 - val_loss: 1.7053 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1279 - accuracy: 0.5108 - val_loss: 1.7502 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1056 - accuracy: 0.5170 - val_loss: 1.8412 - val_accuracy: 0.0139\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1008 - accuracy: 0.5093 - val_loss: 1.5300 - val_accuracy: 0.0556\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0825 - accuracy: 0.5309 - val_loss: 1.8874 - val_accuracy: 0.0139\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0785 - accuracy: 0.5201 - val_loss: 1.6738 - val_accuracy: 0.0139\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0651 - accuracy: 0.5417 - val_loss: 1.6841 - val_accuracy: 0.0278\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0620 - accuracy: 0.5417 - val_loss: 1.6613 - val_accuracy: 0.0417\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0652 - accuracy: 0.5432 - val_loss: 1.7523 - val_accuracy: 0.0139\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0499 - accuracy: 0.5525 - val_loss: 1.6498 - val_accuracy: 0.0694\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0183 - accuracy: 0.5586 - val_loss: 1.8282 - val_accuracy: 0.0278\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.0079 - accuracy: 0.5617 - val_loss: 1.6319 - val_accuracy: 0.0556\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0109 - accuracy: 0.5525 - val_loss: 1.9553 - val_accuracy: 0.0278\n",
      "Epoch 00023: early stopping\n",
      "\n",
      "Training fold 3\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 12, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "21/21 [==============================] - 1s 16ms/step - loss: 1.2706 - accuracy: 0.4074 - val_loss: 1.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1904 - accuracy: 0.4568 - val_loss: 1.7415 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1914 - accuracy: 0.4630 - val_loss: 1.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1825 - accuracy: 0.4691 - val_loss: 1.5726 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1748 - accuracy: 0.4815 - val_loss: 1.6655 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1851 - accuracy: 0.4799 - val_loss: 1.4394 - val_accuracy: 0.3889\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1603 - accuracy: 0.4815 - val_loss: 1.6940 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1506 - accuracy: 0.5062 - val_loss: 1.6783 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1334 - accuracy: 0.5015 - val_loss: 1.6825 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1252 - accuracy: 0.5046 - val_loss: 1.7524 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1570 - accuracy: 0.5154 - val_loss: 1.4913 - val_accuracy: 0.0278\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1204 - accuracy: 0.5077 - val_loss: 1.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1052 - accuracy: 0.5170 - val_loss: 1.8877 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0912 - accuracy: 0.5432 - val_loss: 1.7483 - val_accuracy: 0.0139\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.0889 - accuracy: 0.5231 - val_loss: 1.7680 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0798 - accuracy: 0.5324 - val_loss: 1.5218 - val_accuracy: 0.1806\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0530 - accuracy: 0.5340 - val_loss: 1.9407 - val_accuracy: 0.0556\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0529 - accuracy: 0.5586 - val_loss: 2.2160 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.0562 - accuracy: 0.5463 - val_loss: 1.8596 - val_accuracy: 0.0556\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0192 - accuracy: 0.5432 - val_loss: 1.6378 - val_accuracy: 0.1250\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.9980 - accuracy: 0.5741 - val_loss: 2.1114 - val_accuracy: 0.0139\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9711 - accuracy: 0.6019 - val_loss: 1.8547 - val_accuracy: 0.1389\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9741 - accuracy: 0.5972 - val_loss: 1.7937 - val_accuracy: 0.1528\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9360 - accuracy: 0.6204 - val_loss: 2.1516 - val_accuracy: 0.0833\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9494 - accuracy: 0.5895 - val_loss: 2.2153 - val_accuracy: 0.0417\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9162 - accuracy: 0.6296 - val_loss: 1.9304 - val_accuracy: 0.1250\n",
      "Epoch 00026: early stopping\n",
      "\n",
      "Training fold 4\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_9 (Conv1D)           (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 12, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 17ms/step - loss: 1.2790 - accuracy: 0.4012 - val_loss: 1.6315 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.2138 - accuracy: 0.4290 - val_loss: 1.5766 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1932 - accuracy: 0.4321 - val_loss: 1.6040 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1842 - accuracy: 0.4537 - val_loss: 1.5471 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1726 - accuracy: 0.4537 - val_loss: 1.5746 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1850 - accuracy: 0.4537 - val_loss: 1.5110 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1698 - accuracy: 0.4722 - val_loss: 1.5707 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1730 - accuracy: 0.4954 - val_loss: 1.5975 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1579 - accuracy: 0.4830 - val_loss: 1.7053 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1414 - accuracy: 0.4954 - val_loss: 1.7095 - val_accuracy: 0.0139\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1382 - accuracy: 0.5031 - val_loss: 1.7823 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1294 - accuracy: 0.4892 - val_loss: 1.5526 - val_accuracy: 0.0139\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1158 - accuracy: 0.5093 - val_loss: 1.7174 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1100 - accuracy: 0.5185 - val_loss: 1.6166 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0861 - accuracy: 0.5309 - val_loss: 1.8373 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0795 - accuracy: 0.5278 - val_loss: 1.5395 - val_accuracy: 0.0417\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0609 - accuracy: 0.5262 - val_loss: 1.7861 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0398 - accuracy: 0.5386 - val_loss: 1.6040 - val_accuracy: 0.0556\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0326 - accuracy: 0.5509 - val_loss: 1.8558 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0573 - accuracy: 0.5355 - val_loss: 1.8812 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0279 - accuracy: 0.5386 - val_loss: 1.6973 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0080 - accuracy: 0.5648 - val_loss: 1.8844 - val_accuracy: 0.0139\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9712 - accuracy: 0.5802 - val_loss: 1.5828 - val_accuracy: 0.1667\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9616 - accuracy: 0.5725 - val_loss: 1.8733 - val_accuracy: 0.0278\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9273 - accuracy: 0.6204 - val_loss: 1.8953 - val_accuracy: 0.0417\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.9062 - accuracy: 0.6065 - val_loss: 1.9091 - val_accuracy: 0.0278\n",
      "Epoch 00026: early stopping\n",
      "\n",
      "Training fold 5\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 12, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "21/21 [==============================] - 1s 17ms/step - loss: 1.2607 - accuracy: 0.4059 - val_loss: 1.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1888 - accuracy: 0.4398 - val_loss: 1.6498 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1802 - accuracy: 0.4691 - val_loss: 1.5314 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1611 - accuracy: 0.4954 - val_loss: 1.6125 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1585 - accuracy: 0.4830 - val_loss: 1.6740 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1344 - accuracy: 0.4923 - val_loss: 1.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1391 - accuracy: 0.4799 - val_loss: 1.6592 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1456 - accuracy: 0.4907 - val_loss: 1.5478 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1226 - accuracy: 0.5108 - val_loss: 1.8180 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1065 - accuracy: 0.5031 - val_loss: 1.5984 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1084 - accuracy: 0.4969 - val_loss: 1.5385 - val_accuracy: 0.0139\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0783 - accuracy: 0.5170 - val_loss: 1.6559 - val_accuracy: 0.0278\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.0701 - accuracy: 0.5185 - val_loss: 1.7707 - val_accuracy: 0.0278\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0587 - accuracy: 0.5278 - val_loss: 1.6452 - val_accuracy: 0.0278\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0443 - accuracy: 0.5448 - val_loss: 1.4264 - val_accuracy: 0.1667\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0357 - accuracy: 0.5556 - val_loss: 1.4388 - val_accuracy: 0.4861\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0196 - accuracy: 0.5448 - val_loss: 1.9103 - val_accuracy: 0.0139\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0256 - accuracy: 0.5494 - val_loss: 1.5051 - val_accuracy: 0.1250\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0098 - accuracy: 0.5509 - val_loss: 1.9486 - val_accuracy: 0.0417\n",
      "Epoch 20/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9876 - accuracy: 0.5694 - val_loss: 1.7559 - val_accuracy: 0.0278\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9862 - accuracy: 0.5710 - val_loss: 1.6418 - val_accuracy: 0.1389\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9767 - accuracy: 0.5802 - val_loss: 1.7107 - val_accuracy: 0.1111\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9335 - accuracy: 0.5941 - val_loss: 1.4584 - val_accuracy: 0.2361\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9070 - accuracy: 0.6003 - val_loss: 1.8820 - val_accuracy: 0.0833\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8562 - accuracy: 0.6296 - val_loss: 1.6420 - val_accuracy: 0.1944\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8504 - accuracy: 0.6420 - val_loss: 1.7570 - val_accuracy: 0.1389\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8017 - accuracy: 0.6590 - val_loss: 2.0761 - val_accuracy: 0.1111\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7918 - accuracy: 0.6590 - val_loss: 2.2088 - val_accuracy: 0.0556\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7532 - accuracy: 0.6944 - val_loss: 1.8765 - val_accuracy: 0.1667\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7172 - accuracy: 0.6914 - val_loss: 2.6094 - val_accuracy: 0.0417\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.7029 - accuracy: 0.7099 - val_loss: 2.7594 - val_accuracy: 0.1250\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6992 - accuracy: 0.7191 - val_loss: 2.8881 - val_accuracy: 0.0417\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6405 - accuracy: 0.7330 - val_loss: 2.5532 - val_accuracy: 0.1944\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6454 - accuracy: 0.7253 - val_loss: 2.3074 - val_accuracy: 0.1667\n",
      "Epoch 35/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.6023 - accuracy: 0.7531 - val_loss: 2.7442 - val_accuracy: 0.1528\n",
      "Epoch 00035: early stopping\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000251EBFD83A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Training fold 6\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_15 (Conv1D)          (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 12, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "21/21 [==============================] - 1s 17ms/step - loss: 1.2812 - accuracy: 0.4043 - val_loss: 1.7364 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1953 - accuracy: 0.4660 - val_loss: 1.6436 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1682 - accuracy: 0.4707 - val_loss: 1.6504 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1630 - accuracy: 0.4753 - val_loss: 1.6072 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1648 - accuracy: 0.4815 - val_loss: 1.6658 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1401 - accuracy: 0.5093 - val_loss: 1.6739 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1447 - accuracy: 0.5031 - val_loss: 1.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1192 - accuracy: 0.5031 - val_loss: 1.7193 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1151 - accuracy: 0.5154 - val_loss: 1.6678 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1077 - accuracy: 0.5185 - val_loss: 1.5449 - val_accuracy: 0.0278\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1019 - accuracy: 0.5015 - val_loss: 1.8107 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0901 - accuracy: 0.5231 - val_loss: 1.6495 - val_accuracy: 0.0139\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0708 - accuracy: 0.5309 - val_loss: 1.7574 - val_accuracy: 0.0139\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0589 - accuracy: 0.5262 - val_loss: 1.7470 - val_accuracy: 0.0417\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0465 - accuracy: 0.5417 - val_loss: 1.7019 - val_accuracy: 0.0139\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0346 - accuracy: 0.5432 - val_loss: 1.5868 - val_accuracy: 0.0417\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0333 - accuracy: 0.5556 - val_loss: 1.8987 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0004 - accuracy: 0.5772 - val_loss: 1.4529 - val_accuracy: 0.0972\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0008 - accuracy: 0.5540 - val_loss: 1.8557 - val_accuracy: 0.0278\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9533 - accuracy: 0.6034 - val_loss: 1.4395 - val_accuracy: 0.3333\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9408 - accuracy: 0.5849 - val_loss: 2.0071 - val_accuracy: 0.0139\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9381 - accuracy: 0.5772 - val_loss: 3.0324 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9332 - accuracy: 0.5957 - val_loss: 2.0365 - val_accuracy: 0.0139\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9064 - accuracy: 0.6034 - val_loss: 1.9778 - val_accuracy: 0.0417\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8764 - accuracy: 0.6281 - val_loss: 2.4036 - val_accuracy: 0.0139\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8858 - accuracy: 0.6343 - val_loss: 1.8840 - val_accuracy: 0.0417\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8840 - accuracy: 0.6127 - val_loss: 1.8795 - val_accuracy: 0.1111\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8083 - accuracy: 0.6605 - val_loss: 2.2028 - val_accuracy: 0.0972\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7819 - accuracy: 0.6574 - val_loss: 2.0189 - val_accuracy: 0.1250\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7966 - accuracy: 0.6528 - val_loss: 1.9609 - val_accuracy: 0.1667\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8067 - accuracy: 0.6574 - val_loss: 2.0183 - val_accuracy: 0.1528\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.7732 - accuracy: 0.6682 - val_loss: 1.8963 - val_accuracy: 0.2361\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7377 - accuracy: 0.6651 - val_loss: 2.2303 - val_accuracy: 0.1667\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.6995 - accuracy: 0.7037 - val_loss: 3.0926 - val_accuracy: 0.0417\n",
      "Epoch 35/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6867 - accuracy: 0.7222 - val_loss: 2.7946 - val_accuracy: 0.0556\n",
      "Epoch 36/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.7083 - accuracy: 0.7130 - val_loss: 2.3760 - val_accuracy: 0.1250\n",
      "Epoch 37/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.6496 - accuracy: 0.7438 - val_loss: 2.8900 - val_accuracy: 0.0972\n",
      "Epoch 38/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6131 - accuracy: 0.7469 - val_loss: 3.1632 - val_accuracy: 0.0833\n",
      "Epoch 39/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.6148 - accuracy: 0.7469 - val_loss: 3.2507 - val_accuracy: 0.0694\n",
      "Epoch 40/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.5858 - accuracy: 0.7593 - val_loss: 2.9992 - val_accuracy: 0.1528\n",
      "Epoch 00040: early stopping\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025289813A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Training fold 7\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_18 (Conv1D)          (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 12, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "21/21 [==============================] - 1s 17ms/step - loss: 1.2465 - accuracy: 0.4182 - val_loss: 1.7814 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.2109 - accuracy: 0.4352 - val_loss: 1.5756 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1912 - accuracy: 0.4506 - val_loss: 1.6094 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1854 - accuracy: 0.4552 - val_loss: 1.7598 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1763 - accuracy: 0.4769 - val_loss: 1.6557 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1512 - accuracy: 0.4907 - val_loss: 1.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1387 - accuracy: 0.5062 - val_loss: 1.7027 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1366 - accuracy: 0.4969 - val_loss: 1.6300 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1399 - accuracy: 0.4861 - val_loss: 1.6876 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1210 - accuracy: 0.5077 - val_loss: 1.8262 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1070 - accuracy: 0.4969 - val_loss: 1.6282 - val_accuracy: 0.0278\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1079 - accuracy: 0.5170 - val_loss: 1.7417 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1113 - accuracy: 0.5062 - val_loss: 1.6864 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1109 - accuracy: 0.5077 - val_loss: 1.5199 - val_accuracy: 0.0278\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.0960 - accuracy: 0.5154 - val_loss: 1.6672 - val_accuracy: 0.0417\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0843 - accuracy: 0.5247 - val_loss: 1.6081 - val_accuracy: 0.0417\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0787 - accuracy: 0.5386 - val_loss: 1.9004 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0662 - accuracy: 0.5309 - val_loss: 1.7470 - val_accuracy: 0.0139\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0329 - accuracy: 0.5556 - val_loss: 1.6478 - val_accuracy: 0.0417\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0161 - accuracy: 0.5602 - val_loss: 1.8592 - val_accuracy: 0.0139\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9971 - accuracy: 0.5648 - val_loss: 1.6423 - val_accuracy: 0.1250\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9875 - accuracy: 0.5833 - val_loss: 1.7536 - val_accuracy: 0.0556\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9828 - accuracy: 0.5941 - val_loss: 1.6131 - val_accuracy: 0.0694\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9604 - accuracy: 0.5957 - val_loss: 2.0302 - val_accuracy: 0.0417\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9109 - accuracy: 0.6096 - val_loss: 1.8282 - val_accuracy: 0.0833\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8962 - accuracy: 0.6250 - val_loss: 1.9664 - val_accuracy: 0.0694\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8592 - accuracy: 0.6451 - val_loss: 2.3879 - val_accuracy: 0.0417\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8705 - accuracy: 0.6343 - val_loss: 2.0831 - val_accuracy: 0.0972\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8527 - accuracy: 0.6466 - val_loss: 2.2181 - val_accuracy: 0.0556\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8053 - accuracy: 0.6651 - val_loss: 2.2973 - val_accuracy: 0.0417\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7917 - accuracy: 0.6806 - val_loss: 2.0464 - val_accuracy: 0.1250\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7357 - accuracy: 0.6944 - val_loss: 2.5244 - val_accuracy: 0.0694\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7392 - accuracy: 0.6852 - val_loss: 2.6345 - val_accuracy: 0.0972\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6855 - accuracy: 0.7207 - val_loss: 2.1649 - val_accuracy: 0.1250\n",
      "Epoch 00034: early stopping\n",
      "\n",
      "Training fold 8\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_21 (Conv1D)          (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 12, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "21/21 [==============================] - 1s 16ms/step - loss: 1.2801 - accuracy: 0.3951 - val_loss: 1.7778 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1851 - accuracy: 0.4568 - val_loss: 1.5179 - val_accuracy: 0.0139\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1717 - accuracy: 0.4522 - val_loss: 1.6892 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1679 - accuracy: 0.4491 - val_loss: 1.5965 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1566 - accuracy: 0.4877 - val_loss: 1.5872 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1447 - accuracy: 0.4923 - val_loss: 1.8253 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.1378 - accuracy: 0.5062 - val_loss: 1.6214 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1308 - accuracy: 0.5000 - val_loss: 1.6101 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1232 - accuracy: 0.4676 - val_loss: 1.9609 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1245 - accuracy: 0.5077 - val_loss: 1.6682 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1076 - accuracy: 0.5154 - val_loss: 1.5518 - val_accuracy: 0.0278\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1147 - accuracy: 0.4954 - val_loss: 1.6535 - val_accuracy: 0.0694\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1015 - accuracy: 0.5231 - val_loss: 1.5800 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1137 - accuracy: 0.5231 - val_loss: 1.4478 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.0890 - accuracy: 0.5355 - val_loss: 1.7926 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0635 - accuracy: 0.5340 - val_loss: 1.6154 - val_accuracy: 0.0139\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0386 - accuracy: 0.5509 - val_loss: 1.7458 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0518 - accuracy: 0.5185 - val_loss: 1.6894 - val_accuracy: 0.0139\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0160 - accuracy: 0.5478 - val_loss: 1.9214 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0114 - accuracy: 0.5710 - val_loss: 1.4526 - val_accuracy: 0.0694\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9961 - accuracy: 0.5710 - val_loss: 2.0078 - val_accuracy: 0.0139\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9963 - accuracy: 0.5802 - val_loss: 1.7424 - val_accuracy: 0.0556\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9880 - accuracy: 0.5725 - val_loss: 1.6007 - val_accuracy: 0.3750\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9427 - accuracy: 0.5802 - val_loss: 1.7877 - val_accuracy: 0.0417\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9275 - accuracy: 0.5941 - val_loss: 1.8594 - val_accuracy: 0.0694\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9116 - accuracy: 0.6142 - val_loss: 1.8804 - val_accuracy: 0.0417\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8927 - accuracy: 0.6142 - val_loss: 2.1149 - val_accuracy: 0.0417\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8595 - accuracy: 0.6512 - val_loss: 1.6372 - val_accuracy: 0.1806\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8346 - accuracy: 0.6481 - val_loss: 2.2524 - val_accuracy: 0.0833\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8041 - accuracy: 0.6667 - val_loss: 2.1902 - val_accuracy: 0.0278\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7824 - accuracy: 0.6836 - val_loss: 2.1434 - val_accuracy: 0.0417\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7541 - accuracy: 0.6883 - val_loss: 2.6804 - val_accuracy: 0.0417\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7250 - accuracy: 0.7068 - val_loss: 2.8810 - val_accuracy: 0.0139\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.6935 - accuracy: 0.7330 - val_loss: 2.2704 - val_accuracy: 0.1528\n",
      "Epoch 00034: early stopping\n",
      "\n",
      "Training fold 9\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_24 (Conv1D)          (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_26 (Conv1D)          (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 12, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 16ms/step - loss: 1.2840 - accuracy: 0.3704 - val_loss: 1.6343 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1863 - accuracy: 0.4583 - val_loss: 1.5124 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1710 - accuracy: 0.4630 - val_loss: 1.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1678 - accuracy: 0.4722 - val_loss: 1.6890 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1571 - accuracy: 0.4861 - val_loss: 1.6464 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1401 - accuracy: 0.4892 - val_loss: 1.7306 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1389 - accuracy: 0.4938 - val_loss: 1.6489 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1410 - accuracy: 0.5093 - val_loss: 1.7942 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1162 - accuracy: 0.5170 - val_loss: 1.6275 - val_accuracy: 0.0139\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.1260 - accuracy: 0.5046 - val_loss: 1.5322 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1165 - accuracy: 0.5077 - val_loss: 1.8124 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.0911 - accuracy: 0.5139 - val_loss: 1.7676 - val_accuracy: 0.0139\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1024 - accuracy: 0.5031 - val_loss: 1.7543 - val_accuracy: 0.0139\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0891 - accuracy: 0.5247 - val_loss: 1.7328 - val_accuracy: 0.0278\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0787 - accuracy: 0.5309 - val_loss: 1.8065 - val_accuracy: 0.0278\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0597 - accuracy: 0.5309 - val_loss: 1.7056 - val_accuracy: 0.0972\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0435 - accuracy: 0.5278 - val_loss: 1.6506 - val_accuracy: 0.0278\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0138 - accuracy: 0.5664 - val_loss: 1.8365 - val_accuracy: 0.0694\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0316 - accuracy: 0.5571 - val_loss: 1.9286 - val_accuracy: 0.0278\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0046 - accuracy: 0.5741 - val_loss: 1.9719 - val_accuracy: 0.0556\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9923 - accuracy: 0.5802 - val_loss: 2.0790 - val_accuracy: 0.0417\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9618 - accuracy: 0.5849 - val_loss: 1.9413 - val_accuracy: 0.0556\n",
      "Epoch 00022: early stopping\n",
      "\n",
      "Training fold 10\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_27 (Conv1D)          (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_28 (Conv1D)          (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 12, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "21/21 [==============================] - 1s 18ms/step - loss: 1.2797 - accuracy: 0.4043 - val_loss: 1.5379 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1963 - accuracy: 0.4460 - val_loss: 1.5578 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1937 - accuracy: 0.4630 - val_loss: 1.5490 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1757 - accuracy: 0.4676 - val_loss: 1.5174 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1561 - accuracy: 0.4830 - val_loss: 1.7427 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1570 - accuracy: 0.4784 - val_loss: 1.5301 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 1.1545 - accuracy: 0.4923 - val_loss: 1.5520 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.1287 - accuracy: 0.5123 - val_loss: 1.7070 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1395 - accuracy: 0.5031 - val_loss: 1.5883 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1099 - accuracy: 0.5108 - val_loss: 1.9394 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.1132 - accuracy: 0.5123 - val_loss: 1.6152 - val_accuracy: 0.0278\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.0932 - accuracy: 0.5216 - val_loss: 1.6748 - val_accuracy: 0.0139\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0889 - accuracy: 0.5170 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.0731 - accuracy: 0.5201 - val_loss: 1.7492 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.0932 - accuracy: 0.5293 - val_loss: 1.7947 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0793 - accuracy: 0.5293 - val_loss: 1.6012 - val_accuracy: 0.0556\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0360 - accuracy: 0.5432 - val_loss: 1.7604 - val_accuracy: 0.0417\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0430 - accuracy: 0.5525 - val_loss: 1.9700 - val_accuracy: 0.0139\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.0260 - accuracy: 0.5540 - val_loss: 1.5950 - val_accuracy: 0.1111\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9794 - accuracy: 0.5818 - val_loss: 1.7640 - val_accuracy: 0.0972\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9826 - accuracy: 0.5648 - val_loss: 2.1010 - val_accuracy: 0.0417\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.9806 - accuracy: 0.5694 - val_loss: 1.6268 - val_accuracy: 0.1111\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9410 - accuracy: 0.5833 - val_loss: 1.9602 - val_accuracy: 0.1111\n",
      "Epoch 24/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9380 - accuracy: 0.6034 - val_loss: 1.6815 - val_accuracy: 0.1389\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9332 - accuracy: 0.6096 - val_loss: 1.7535 - val_accuracy: 0.1111\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.9147 - accuracy: 0.6420 - val_loss: 1.7191 - val_accuracy: 0.0833\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.8652 - accuracy: 0.6343 - val_loss: 2.0919 - val_accuracy: 0.0278\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8336 - accuracy: 0.6667 - val_loss: 2.1197 - val_accuracy: 0.0694\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.8393 - accuracy: 0.6435 - val_loss: 1.5557 - val_accuracy: 0.1667\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7915 - accuracy: 0.6682 - val_loss: 2.5065 - val_accuracy: 0.0556\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7737 - accuracy: 0.6790 - val_loss: 2.2451 - val_accuracy: 0.0694\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7609 - accuracy: 0.6960 - val_loss: 2.3415 - val_accuracy: 0.0556\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.7396 - accuracy: 0.6836 - val_loss: 2.3901 - val_accuracy: 0.0694\n",
      "Epoch 00033: early stopping\n",
      "\n",
      "Time taken for training:  00:01:11\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.5375 - Test Accuracy 0.4750\n",
      "Fold 2 - Train Accuracy 0.5167 - Test Accuracy 0.4625\n",
      "Fold 3 - Train Accuracy 0.5931 - Test Accuracy 0.3875\n",
      "Fold 4 - Train Accuracy 0.5861 - Test Accuracy 0.4875\n",
      "Fold 5 - Train Accuracy 0.7361 - Test Accuracy 0.3875\n",
      "Fold 6 - Train Accuracy 0.7028 - Test Accuracy 0.3500\n",
      "Fold 7 - Train Accuracy 0.6806 - Test Accuracy 0.4750\n",
      "Fold 8 - Train Accuracy 0.6625 - Test Accuracy 0.4375\n",
      "Fold 9 - Train Accuracy 0.5486 - Test Accuracy 0.4000\n",
      "Fold 10 - Train Accuracy 0.6528 - Test Accuracy 0.3625\n",
      "\n",
      "Mean Train Accuracy: 0.6217 - Std: 0.0716 \n",
      "Mean Test Accuracy: 0.4225 - Std: 0.0483 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.51      0.43       200\n",
      "           1       0.52      0.71      0.60       200\n",
      "           2       0.37      0.34      0.35       200\n",
      "           3       0.37      0.13      0.19       200\n",
      "\n",
      "    accuracy                           0.42       800\n",
      "   macro avg       0.41      0.42      0.39       800\n",
      "weighted avg       0.41      0.42      0.39       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_features = 1\n",
    "\n",
    "def create_v2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = \"relu\", input_shape = (number_of_steps, number_of_features)))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dense(4, activation = 'softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Defining the number of folds (10 k-Fold).\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Normalize data using box-cox method.\n",
    "pt = PowerTransformer()\n",
    "pt.fit(X_resampled)\n",
    "X_resampled = pt.transform(X_resampled)\n",
    "\n",
    "# Reshape the structure data to be compatible with pattern [samples, timesteps, features].\n",
    "X_train_reshaped = X_resampled.reshape((X_resampled.shape[0], number_of_steps, number_of_features))\n",
    "\n",
    "\n",
    "# Train the CNN model and evaluate it.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training at: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 20)\n",
    "\n",
    "train_accuracy_by_fold = []\n",
    "test_accuracy_by_fold = []\n",
    "history_by_fold = []\n",
    "y_predclass_for_report = []\n",
    "y_testclass_for_report = []\n",
    "fold_number = 1\n",
    "for train_index, test_index in skf.split(X_train_reshaped, y_resampled):\n",
    "    print(\"\\nTraining fold {}\".format(fold_number))\n",
    "    model = create_v2()\n",
    "    history = model.fit(X_train_reshaped[train_index], y_resampled[train_index], validation_split = 0.1,\n",
    "                            epochs = 300, batch_size = 32, verbose = 1, callbacks = [es])\n",
    "    _, train_accuracy = model.evaluate(X_train_reshaped[train_index], y_resampled[train_index], verbose = 0)\n",
    "    _, test_accuracy = model.evaluate(X_train_reshaped[test_index], y_resampled[test_index], verbose = 0)\n",
    "    train_accuracy_by_fold.append(train_accuracy)\n",
    "    test_accuracy_by_fold.append(test_accuracy)\n",
    "    history_by_fold.append(history)\n",
    "    y_predclass_for_report.extend(np.argmax(model.predict(X_train_reshaped[test_index]), axis = 1))\n",
    "    y_testclass_for_report.extend(y_resampled[test_index])\n",
    "    fold_number += 1\n",
    "\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show metrics.\n",
    "for i in range(len(train_accuracy_by_fold)):\n",
    "    print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "                            train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "print(\"\\nMean Train Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(train_accuracy_by_fold), np.std(train_accuracy_by_fold)))\n",
    "print(\"Mean Test Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(test_accuracy_by_fold), np.std(test_accuracy_by_fold)))\n",
    "\n",
    "print(\"\\nEvaluate other metrics:\")\n",
    "print(classification_report(y_testclass_for_report, y_predclass_for_report, zero_division = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3839e2c",
   "metadata": {},
   "source": [
    "#### Train a Convolutional Neural Network model and evaluate the metrics.\n",
    "- Layer architecture => Conv1D (64) + Conv1D (32) + Conv1D (16) + MaxPooling1D + Flatten + Dense (128) + Dense (128) + Dense (128) + Dense (4)\n",
    "- 4000 samples - Data augmentation (5x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef432ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting data augmentation.\n",
      "\n",
      "Quantity of samples generated by oversampling =>  4000\n",
      "\n",
      "Starting training at:  17:19:22\n",
      "\n",
      "Trainning fold 1\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_240 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_241 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_242 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_80 (MaxPoolin  (None, 12, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_80 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.2002 - accuracy: 0.4423 - val_loss: 1.5335 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1478 - accuracy: 0.4929 - val_loss: 1.7329 - val_accuracy: 0.0083\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1136 - accuracy: 0.5046 - val_loss: 1.5551 - val_accuracy: 0.0444\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0609 - accuracy: 0.5207 - val_loss: 1.7594 - val_accuracy: 0.0222\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9983 - accuracy: 0.5694 - val_loss: 1.4559 - val_accuracy: 0.1028\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8992 - accuracy: 0.6299 - val_loss: 1.3883 - val_accuracy: 0.1361\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8001 - accuracy: 0.6691 - val_loss: 1.5014 - val_accuracy: 0.1694\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.7238 - val_loss: 1.2180 - val_accuracy: 0.3944\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.7586 - val_loss: 1.1297 - val_accuracy: 0.3528\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7957 - val_loss: 0.9541 - val_accuracy: 0.5389\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8355 - val_loss: 1.0422 - val_accuracy: 0.4639\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8515 - val_loss: 0.9712 - val_accuracy: 0.5389\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.2988 - accuracy: 0.8849 - val_loss: 0.8179 - val_accuracy: 0.6806\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.9006 - val_loss: 0.6562 - val_accuracy: 0.8333\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.9213 - val_loss: 0.8741 - val_accuracy: 0.7611\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1995 - accuracy: 0.9222 - val_loss: 0.5489 - val_accuracy: 0.8944\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9290 - val_loss: 0.7328 - val_accuracy: 0.8111\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9552 - val_loss: 0.8623 - val_accuracy: 0.7889\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9664 - val_loss: 0.7682 - val_accuracy: 0.8667\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.2306 - accuracy: 0.9228 - val_loss: 1.0289 - val_accuracy: 0.7611\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 0.9562 - val_loss: 0.8229 - val_accuracy: 0.8583\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0818 - accuracy: 0.9735 - val_loss: 0.9693 - val_accuracy: 0.8333\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9744 - val_loss: 0.9674 - val_accuracy: 0.8167\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9802 - val_loss: 0.6833 - val_accuracy: 0.8889\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9744 - val_loss: 0.7699 - val_accuracy: 0.9000\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9870 - val_loss: 0.8362 - val_accuracy: 0.8583\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 0.8101 - val_accuracy: 0.9056\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9846 - val_loss: 0.8292 - val_accuracy: 0.8833\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9593 - val_loss: 1.0904 - val_accuracy: 0.7639\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.9747 - val_loss: 0.8091 - val_accuracy: 0.8889\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9790 - val_loss: 0.8444 - val_accuracy: 0.8889\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9855 - val_loss: 0.6931 - val_accuracy: 0.8944\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9836 - val_loss: 0.7741 - val_accuracy: 0.9139\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9843 - val_loss: 0.8783 - val_accuracy: 0.9056\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9883 - val_loss: 0.7744 - val_accuracy: 0.9278\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.7889 - val_accuracy: 0.9278\n",
      "Epoch 00036: early stopping\n",
      "\n",
      "Trainning fold 2\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_243 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_244 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_245 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_81 (MaxPoolin  (None, 12, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_81 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 2s 12ms/step - loss: 1.2054 - accuracy: 0.4546 - val_loss: 1.7185 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1402 - accuracy: 0.4886 - val_loss: 1.9915 - val_accuracy: 0.0111\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1090 - accuracy: 0.5142 - val_loss: 1.6778 - val_accuracy: 0.0278\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0580 - accuracy: 0.5315 - val_loss: 1.6454 - val_accuracy: 0.0694\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0114 - accuracy: 0.5707 - val_loss: 1.5787 - val_accuracy: 0.1028\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9151 - accuracy: 0.6133 - val_loss: 1.3873 - val_accuracy: 0.2444\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.8383 - accuracy: 0.6503 - val_loss: 1.6994 - val_accuracy: 0.2000\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.7165 - accuracy: 0.7049 - val_loss: 1.2578 - val_accuracy: 0.4139\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.6265 - accuracy: 0.7525 - val_loss: 1.1535 - val_accuracy: 0.4722\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.5196 - accuracy: 0.7935 - val_loss: 1.2446 - val_accuracy: 0.4056\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4326 - accuracy: 0.8377 - val_loss: 0.9116 - val_accuracy: 0.6000\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3535 - accuracy: 0.8679 - val_loss: 0.7592 - val_accuracy: 0.7667\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.3216 - accuracy: 0.8812 - val_loss: 1.0038 - val_accuracy: 0.5917\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2941 - accuracy: 0.8870 - val_loss: 0.7472 - val_accuracy: 0.7722\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2199 - accuracy: 0.9182 - val_loss: 0.7097 - val_accuracy: 0.8194\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2050 - accuracy: 0.9259 - val_loss: 0.8516 - val_accuracy: 0.7889\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1552 - accuracy: 0.9466 - val_loss: 0.7793 - val_accuracy: 0.7306\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1236 - accuracy: 0.9562 - val_loss: 0.7779 - val_accuracy: 0.7806\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1093 - accuracy: 0.9645 - val_loss: 0.8055 - val_accuracy: 0.8028\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0983 - accuracy: 0.9685 - val_loss: 0.9668 - val_accuracy: 0.7889\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0886 - accuracy: 0.9719 - val_loss: 1.2259 - val_accuracy: 0.7389\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0738 - accuracy: 0.9762 - val_loss: 0.8417 - val_accuracy: 0.8528\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1334 - accuracy: 0.9586 - val_loss: 2.1359 - val_accuracy: 0.4694\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2516 - accuracy: 0.9213 - val_loss: 0.6939 - val_accuracy: 0.8528\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0625 - accuracy: 0.9843 - val_loss: 0.7505 - val_accuracy: 0.8556\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0452 - accuracy: 0.9880 - val_loss: 1.0207 - val_accuracy: 0.7861\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0434 - accuracy: 0.9867 - val_loss: 0.7045 - val_accuracy: 0.8944\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0381 - accuracy: 0.9867 - val_loss: 0.8713 - val_accuracy: 0.8694\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0381 - accuracy: 0.9873 - val_loss: 0.9150 - val_accuracy: 0.8694\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 0.9648 - val_accuracy: 0.8806\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0305 - accuracy: 0.9901 - val_loss: 1.0925 - val_accuracy: 0.8778\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0911 - accuracy: 0.9735 - val_loss: 0.7514 - val_accuracy: 0.8944\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0871 - accuracy: 0.9673 - val_loss: 1.1275 - val_accuracy: 0.7722\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1474 - accuracy: 0.9556 - val_loss: 0.7517 - val_accuracy: 0.8750\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9898 - val_loss: 0.7419 - val_accuracy: 0.8750\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0214 - accuracy: 0.9920 - val_loss: 0.9227 - val_accuracy: 0.8806\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0225 - accuracy: 0.9917 - val_loss: 0.8887 - val_accuracy: 0.8861\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.8788 - val_accuracy: 0.8944\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.8960 - val_accuracy: 0.9083\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0693 - accuracy: 0.9806 - val_loss: 0.8810 - val_accuracy: 0.8889\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.9080 - val_accuracy: 0.9056\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0144 - accuracy: 0.9944 - val_loss: 0.9713 - val_accuracy: 0.9000\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 1.0136 - val_accuracy: 0.9000\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.9856 - val_accuracy: 0.9000\n",
      "Epoch 00044: early stopping\n",
      "\n",
      "Trainning fold 3\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_246 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_247 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_248 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_82 (MaxPoolin  (None, 12, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_82 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_340 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.2009 - accuracy: 0.4574 - val_loss: 1.6329 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 5ms/step - loss: 1.1438 - accuracy: 0.5062 - val_loss: 1.6426 - val_accuracy: 0.0028\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.1157 - accuracy: 0.5123 - val_loss: 1.8605 - val_accuracy: 0.0083\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0754 - accuracy: 0.5250 - val_loss: 1.6741 - val_accuracy: 0.0361\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 1.0083 - accuracy: 0.5546 - val_loss: 1.5286 - val_accuracy: 0.0944\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.9149 - accuracy: 0.6117 - val_loss: 1.2980 - val_accuracy: 0.2361\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.8091 - accuracy: 0.6552 - val_loss: 1.0138 - val_accuracy: 0.7472\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.7088 - accuracy: 0.6963 - val_loss: 1.2669 - val_accuracy: 0.3667\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.6174 - accuracy: 0.7463 - val_loss: 0.9793 - val_accuracy: 0.4917\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.5135 - accuracy: 0.7991 - val_loss: 0.9967 - val_accuracy: 0.5472\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4515 - accuracy: 0.8231 - val_loss: 1.0741 - val_accuracy: 0.5944\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4060 - accuracy: 0.8432 - val_loss: 0.8253 - val_accuracy: 0.6833\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.3162 - accuracy: 0.8880 - val_loss: 1.3965 - val_accuracy: 0.5361\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2962 - accuracy: 0.8901 - val_loss: 0.9629 - val_accuracy: 0.6111\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2529 - accuracy: 0.9077 - val_loss: 0.9412 - val_accuracy: 0.6639\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2919 - accuracy: 0.8910 - val_loss: 0.6728 - val_accuracy: 0.6861\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2471 - accuracy: 0.9188 - val_loss: 0.7429 - val_accuracy: 0.7389\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1747 - accuracy: 0.9386 - val_loss: 0.7338 - val_accuracy: 0.7889\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1396 - accuracy: 0.9552 - val_loss: 0.5887 - val_accuracy: 0.8778\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1223 - accuracy: 0.9574 - val_loss: 0.4457 - val_accuracy: 0.8833\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1047 - accuracy: 0.9636 - val_loss: 0.5081 - val_accuracy: 0.9028\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0938 - accuracy: 0.9698 - val_loss: 0.7439 - val_accuracy: 0.8389\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1080 - accuracy: 0.9633 - val_loss: 0.5434 - val_accuracy: 0.9111\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1327 - accuracy: 0.9611 - val_loss: 0.7034 - val_accuracy: 0.7861\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.2013 - accuracy: 0.9377 - val_loss: 0.5905 - val_accuracy: 0.8778\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0826 - accuracy: 0.9759 - val_loss: 0.7277 - val_accuracy: 0.8639\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0655 - accuracy: 0.9790 - val_loss: 0.5971 - val_accuracy: 0.8806\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0550 - accuracy: 0.9852 - val_loss: 0.6094 - val_accuracy: 0.9139\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0441 - accuracy: 0.9864 - val_loss: 0.6334 - val_accuracy: 0.9194\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 0.6001 - val_accuracy: 0.9278\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9892 - val_loss: 0.5754 - val_accuracy: 0.9361\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 0.6747 - val_accuracy: 0.9083\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0868 - accuracy: 0.9698 - val_loss: 1.2874 - val_accuracy: 0.7639\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1769 - accuracy: 0.9398 - val_loss: 0.3820 - val_accuracy: 0.9333\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0748 - accuracy: 0.9781 - val_loss: 0.3716 - val_accuracy: 0.9111\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0305 - accuracy: 0.9920 - val_loss: 0.4834 - val_accuracy: 0.9361\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0201 - accuracy: 0.9944 - val_loss: 0.6281 - val_accuracy: 0.9000\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9892 - val_loss: 0.5034 - val_accuracy: 0.9361\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.4821 - val_accuracy: 0.9361\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.6362 - val_accuracy: 0.9278\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0810 - accuracy: 0.9759 - val_loss: 0.6856 - val_accuracy: 0.9028\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0933 - accuracy: 0.9722 - val_loss: 0.4767 - val_accuracy: 0.9056\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0403 - accuracy: 0.9892 - val_loss: 0.5946 - val_accuracy: 0.9306\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.5873 - val_accuracy: 0.9361\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.6346 - val_accuracy: 0.9361\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.6452 - val_accuracy: 0.9361\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.7188 - val_accuracy: 0.9361\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0561 - accuracy: 0.9818 - val_loss: 0.5694 - val_accuracy: 0.9250\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0629 - accuracy: 0.9827 - val_loss: 0.5951 - val_accuracy: 0.9417\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0348 - accuracy: 0.9901 - val_loss: 0.5606 - val_accuracy: 0.9417\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0696 - accuracy: 0.9821 - val_loss: 0.5852 - val_accuracy: 0.9667\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0345 - accuracy: 0.9904 - val_loss: 0.7144 - val_accuracy: 0.9417\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.7410 - val_accuracy: 0.9556\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.7895 - val_accuracy: 0.9417\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.7704 - val_accuracy: 0.9417\n",
      "Epoch 00055: early stopping\n",
      "\n",
      "Trainning fold 4\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_249 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_250 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_251 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_83 (MaxPoolin  (None, 12, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_83 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "102/102 [==============================] - 2s 8ms/step - loss: 1.2022 - accuracy: 0.4451 - val_loss: 2.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.1512 - accuracy: 0.4818 - val_loss: 1.4678 - val_accuracy: 0.0056\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.1103 - accuracy: 0.5065 - val_loss: 1.5944 - val_accuracy: 0.0139\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0838 - accuracy: 0.5188 - val_loss: 1.6479 - val_accuracy: 0.0139\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0259 - accuracy: 0.5509 - val_loss: 1.6076 - val_accuracy: 0.0472\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.9738 - accuracy: 0.5660 - val_loss: 1.6822 - val_accuracy: 0.0556\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.9049 - accuracy: 0.6012 - val_loss: 1.6364 - val_accuracy: 0.0944\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.8221 - accuracy: 0.6586 - val_loss: 1.4862 - val_accuracy: 0.2028\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.7121 - accuracy: 0.7099 - val_loss: 1.5585 - val_accuracy: 0.2528\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6111 - accuracy: 0.7485 - val_loss: 1.0808 - val_accuracy: 0.4472\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4925 - accuracy: 0.8028 - val_loss: 1.0200 - val_accuracy: 0.4472\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.8253 - val_loss: 1.3358 - val_accuracy: 0.4139\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3390 - accuracy: 0.8664 - val_loss: 0.7593 - val_accuracy: 0.7306\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3314 - accuracy: 0.8614 - val_loss: 1.0645 - val_accuracy: 0.5278\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2961 - accuracy: 0.8827 - val_loss: 0.8785 - val_accuracy: 0.6639\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2138 - accuracy: 0.9160 - val_loss: 0.9233 - val_accuracy: 0.6750\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2052 - accuracy: 0.9194 - val_loss: 0.6789 - val_accuracy: 0.7694\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1558 - accuracy: 0.9407 - val_loss: 0.6484 - val_accuracy: 0.8306\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1254 - accuracy: 0.9549 - val_loss: 0.7677 - val_accuracy: 0.7639\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1898 - accuracy: 0.9364 - val_loss: 0.7088 - val_accuracy: 0.8111\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1213 - accuracy: 0.9574 - val_loss: 0.7496 - val_accuracy: 0.7611\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0948 - accuracy: 0.9651 - val_loss: 0.7610 - val_accuracy: 0.8667\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0814 - accuracy: 0.9710 - val_loss: 0.6596 - val_accuracy: 0.8722\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0774 - accuracy: 0.9713 - val_loss: 0.6649 - val_accuracy: 0.8861\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0540 - accuracy: 0.9806 - val_loss: 0.6289 - val_accuracy: 0.8972\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0518 - accuracy: 0.9815 - val_loss: 0.6774 - val_accuracy: 0.9028\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1391 - accuracy: 0.9590 - val_loss: 0.8969 - val_accuracy: 0.7972\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2205 - accuracy: 0.9238 - val_loss: 1.0487 - val_accuracy: 0.8000\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0725 - accuracy: 0.9796 - val_loss: 0.6336 - val_accuracy: 0.9028\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0411 - accuracy: 0.9901 - val_loss: 0.6062 - val_accuracy: 0.8556\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9889 - val_loss: 0.6891 - val_accuracy: 0.8972\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.6846 - val_accuracy: 0.9278\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.7026 - val_accuracy: 0.9056\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.7650 - val_accuracy: 0.9056\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0513 - accuracy: 0.9830 - val_loss: 0.8301 - val_accuracy: 0.8944\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0729 - accuracy: 0.9802 - val_loss: 0.8860 - val_accuracy: 0.8806\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0820 - accuracy: 0.9716 - val_loss: 0.8084 - val_accuracy: 0.8556\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0521 - accuracy: 0.9846 - val_loss: 0.6392 - val_accuracy: 0.9222\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.7225 - val_accuracy: 0.9083\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.6844 - val_accuracy: 0.9250\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.8097 - val_accuracy: 0.9194\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0154 - accuracy: 0.9938 - val_loss: 0.7689 - val_accuracy: 0.9194\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.7357 - val_accuracy: 0.9278\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.8277 - val_accuracy: 0.9194\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 0.8248 - val_accuracy: 0.9278\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 0.8498 - val_accuracy: 0.9194\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.8478 - val_accuracy: 0.9194\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1102 - accuracy: 0.9676 - val_loss: 1.5246 - val_accuracy: 0.7556\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2077 - accuracy: 0.9346 - val_loss: 0.7563 - val_accuracy: 0.8806\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0566 - accuracy: 0.9846 - val_loss: 0.5879 - val_accuracy: 0.9194\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 0.6978 - val_accuracy: 0.9194\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.6790 - val_accuracy: 0.9194\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.6887 - val_accuracy: 0.9278\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.6760 - val_accuracy: 0.9278\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.7460 - val_accuracy: 0.9278\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.7262 - val_accuracy: 0.9278\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.6898 - val_accuracy: 0.9278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.7385 - val_accuracy: 0.9278\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7551 - val_accuracy: 0.9278\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 0.7378 - val_accuracy: 0.9278\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.7747 - val_accuracy: 0.9278\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.7590 - val_accuracy: 0.9278\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.9278\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7906 - val_accuracy: 0.9278\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.9278\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.7976 - val_accuracy: 0.9278\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1078 - accuracy: 0.9679 - val_loss: 1.4325 - val_accuracy: 0.7861\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1712 - accuracy: 0.9426 - val_loss: 0.8103 - val_accuracy: 0.8556\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0391 - accuracy: 0.9898 - val_loss: 0.5113 - val_accuracy: 0.9278\n",
      "Epoch 70/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.6283 - val_accuracy: 0.9278\n",
      "Epoch 71/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.6054 - val_accuracy: 0.9278\n",
      "Epoch 72/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6449 - val_accuracy: 0.9278\n",
      "Epoch 73/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.6118 - val_accuracy: 0.9278\n",
      "Epoch 74/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.6305 - val_accuracy: 0.9278\n",
      "Epoch 75/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.7953 - val_accuracy: 0.9250\n",
      "Epoch 76/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0251 - accuracy: 0.9889 - val_loss: 0.3179 - val_accuracy: 0.9417\n",
      "Epoch 77/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0469 - accuracy: 0.9846 - val_loss: 0.5861 - val_accuracy: 0.9000\n",
      "Epoch 78/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0398 - accuracy: 0.9867 - val_loss: 0.8080 - val_accuracy: 0.9111\n",
      "Epoch 79/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.6636 - val_accuracy: 0.9222\n",
      "Epoch 80/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.9222\n",
      "Epoch 81/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 8.5650e-04 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.9222\n",
      "Epoch 82/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.7135 - val_accuracy: 0.9222\n",
      "Epoch 83/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 7.5955e-04 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.9139\n",
      "Epoch 84/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.7751 - val_accuracy: 0.9222\n",
      "Epoch 85/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 0.7075 - val_accuracy: 0.9222\n",
      "Epoch 86/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8098 - val_accuracy: 0.9222\n",
      "Epoch 87/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.8141 - val_accuracy: 0.9222\n",
      "Epoch 88/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 6.5573e-04 - accuracy: 1.0000 - val_loss: 0.8351 - val_accuracy: 0.9139\n",
      "Epoch 89/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.8510 - val_accuracy: 0.9222\n",
      "Epoch 90/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 6.7564e-04 - accuracy: 0.9997 - val_loss: 0.8343 - val_accuracy: 0.9222\n",
      "Epoch 91/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 0.7732 - val_accuracy: 0.9222\n",
      "Epoch 92/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1416 - accuracy: 0.9670 - val_loss: 0.9251 - val_accuracy: 0.7944\n",
      "Epoch 93/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0649 - accuracy: 0.9784 - val_loss: 0.4816 - val_accuracy: 0.9194\n",
      "Epoch 94/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.5649 - val_accuracy: 0.9278\n",
      "Epoch 95/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6309 - val_accuracy: 0.9194\n",
      "Epoch 96/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.6122 - val_accuracy: 0.9278\n",
      "Epoch 00096: early stopping\n",
      "\n",
      "Trainning fold 5\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_252 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_253 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_254 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_84 (MaxPoolin  (None, 12, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_84 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_346 (Dense)           (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.2134 - accuracy: 0.4494 - val_loss: 1.5586 - val_accuracy: 0.0056\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.1513 - accuracy: 0.4904 - val_loss: 1.3519 - val_accuracy: 0.0611\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0920 - accuracy: 0.5207 - val_loss: 1.5637 - val_accuracy: 0.0472\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0171 - accuracy: 0.5562 - val_loss: 1.6287 - val_accuracy: 0.0722\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.9329 - accuracy: 0.6012 - val_loss: 1.5667 - val_accuracy: 0.1389\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.8222 - accuracy: 0.6590 - val_loss: 1.4806 - val_accuracy: 0.2417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.7195 - accuracy: 0.7000 - val_loss: 1.0346 - val_accuracy: 0.4194\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6133 - accuracy: 0.7481 - val_loss: 1.1474 - val_accuracy: 0.4444\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.5284 - accuracy: 0.7951 - val_loss: 0.8472 - val_accuracy: 0.6722\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4764 - accuracy: 0.8062 - val_loss: 1.0891 - val_accuracy: 0.5917\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.4119 - accuracy: 0.8466 - val_loss: 0.7880 - val_accuracy: 0.7222\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3716 - accuracy: 0.8515 - val_loss: 1.0426 - val_accuracy: 0.5139\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3035 - accuracy: 0.8799 - val_loss: 0.7082 - val_accuracy: 0.7083\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2424 - accuracy: 0.9090 - val_loss: 0.6447 - val_accuracy: 0.7556\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2798 - accuracy: 0.8981 - val_loss: 0.6536 - val_accuracy: 0.7750\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2154 - accuracy: 0.9201 - val_loss: 0.5644 - val_accuracy: 0.7972\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1814 - accuracy: 0.9321 - val_loss: 0.4921 - val_accuracy: 0.8056\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1385 - accuracy: 0.9478 - val_loss: 0.5953 - val_accuracy: 0.8167\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2122 - accuracy: 0.9250 - val_loss: 0.5272 - val_accuracy: 0.8083\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1159 - accuracy: 0.9608 - val_loss: 0.5724 - val_accuracy: 0.8833\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0896 - accuracy: 0.9719 - val_loss: 0.7412 - val_accuracy: 0.7917\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0766 - accuracy: 0.9747 - val_loss: 0.5013 - val_accuracy: 0.8250\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1065 - accuracy: 0.9639 - val_loss: 0.3328 - val_accuracy: 0.9389\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2460 - accuracy: 0.9210 - val_loss: 0.5523 - val_accuracy: 0.8361\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1024 - accuracy: 0.9657 - val_loss: 0.5484 - val_accuracy: 0.8389\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0615 - accuracy: 0.9802 - val_loss: 0.6181 - val_accuracy: 0.8472\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0492 - accuracy: 0.9864 - val_loss: 0.5631 - val_accuracy: 0.8611\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0374 - accuracy: 0.9886 - val_loss: 0.5719 - val_accuracy: 0.8778\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0588 - accuracy: 0.9824 - val_loss: 0.6685 - val_accuracy: 0.8389\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0679 - accuracy: 0.9781 - val_loss: 0.5371 - val_accuracy: 0.8833\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9898 - val_loss: 0.4233 - val_accuracy: 0.9472\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0388 - accuracy: 0.9873 - val_loss: 0.5391 - val_accuracy: 0.9083\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0394 - accuracy: 0.9858 - val_loss: 0.6270 - val_accuracy: 0.8694\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2521 - accuracy: 0.9293 - val_loss: 0.8966 - val_accuracy: 0.7861\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1015 - accuracy: 0.9710 - val_loss: 0.5093 - val_accuracy: 0.8972\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0367 - accuracy: 0.9904 - val_loss: 0.5138 - val_accuracy: 0.9056\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0289 - accuracy: 0.9904 - val_loss: 0.5356 - val_accuracy: 0.9083\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0281 - accuracy: 0.9907 - val_loss: 0.5327 - val_accuracy: 0.9139\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0298 - accuracy: 0.9886 - val_loss: 0.5924 - val_accuracy: 0.8917\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0204 - accuracy: 0.9923 - val_loss: 0.4501 - val_accuracy: 0.9333\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1208 - accuracy: 0.9617 - val_loss: 0.5187 - val_accuracy: 0.9167\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0542 - accuracy: 0.9821 - val_loss: 0.6581 - val_accuracy: 0.8889\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0253 - accuracy: 0.9901 - val_loss: 0.5248 - val_accuracy: 0.9222\n",
      "Epoch 00043: early stopping\n",
      "\n",
      "Trainning fold 6\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_255 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_256 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_257 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_85 (MaxPoolin  (None, 12, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_85 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_350 (Dense)           (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_352 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 2s 6ms/step - loss: 1.2031 - accuracy: 0.4593 - val_loss: 1.4795 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1508 - accuracy: 0.4917 - val_loss: 1.5886 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.1020 - accuracy: 0.5120 - val_loss: 1.4519 - val_accuracy: 0.0250\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0512 - accuracy: 0.5478 - val_loss: 1.5658 - val_accuracy: 0.0639\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.9950 - accuracy: 0.5648 - val_loss: 1.8565 - val_accuracy: 0.1000\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.9063 - accuracy: 0.6170 - val_loss: 1.1465 - val_accuracy: 0.4583\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.8144 - accuracy: 0.6546 - val_loss: 1.6638 - val_accuracy: 0.1694\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.7163 - accuracy: 0.6966 - val_loss: 1.0648 - val_accuracy: 0.5472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6235 - accuracy: 0.7451 - val_loss: 1.1538 - val_accuracy: 0.4139\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.5407 - accuracy: 0.7824 - val_loss: 1.2060 - val_accuracy: 0.3722\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.4650 - accuracy: 0.8105 - val_loss: 0.8236 - val_accuracy: 0.5889\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.8269 - val_loss: 0.6808 - val_accuracy: 0.6750\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3665 - accuracy: 0.8537 - val_loss: 0.6475 - val_accuracy: 0.6889\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2865 - accuracy: 0.8895 - val_loss: 0.7206 - val_accuracy: 0.7000\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2481 - accuracy: 0.9040 - val_loss: 0.6441 - val_accuracy: 0.8222\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3092 - accuracy: 0.8892 - val_loss: 0.7584 - val_accuracy: 0.7278\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1886 - accuracy: 0.9281 - val_loss: 0.7987 - val_accuracy: 0.7278\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1532 - accuracy: 0.9466 - val_loss: 0.5106 - val_accuracy: 0.8694\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1333 - accuracy: 0.9540 - val_loss: 0.6034 - val_accuracy: 0.7722\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1407 - accuracy: 0.9531 - val_loss: 0.8354 - val_accuracy: 0.7722\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1080 - accuracy: 0.9627 - val_loss: 0.5075 - val_accuracy: 0.8556\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1021 - accuracy: 0.9667 - val_loss: 0.5151 - val_accuracy: 0.8889\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0619 - accuracy: 0.9818 - val_loss: 0.5810 - val_accuracy: 0.8444\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1394 - accuracy: 0.9562 - val_loss: 1.3401 - val_accuracy: 0.7111\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2527 - accuracy: 0.9167 - val_loss: 0.6064 - val_accuracy: 0.7861\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0695 - accuracy: 0.9790 - val_loss: 0.4039 - val_accuracy: 0.9194\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0450 - accuracy: 0.9877 - val_loss: 0.3861 - val_accuracy: 0.9250\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0385 - accuracy: 0.9892 - val_loss: 0.4398 - val_accuracy: 0.9333\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0306 - accuracy: 0.9914 - val_loss: 0.4272 - val_accuracy: 0.9278\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.5060 - val_accuracy: 0.9278\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 0.4498 - val_accuracy: 0.9444\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0226 - accuracy: 0.9951 - val_loss: 0.4481 - val_accuracy: 0.9417\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.5555 - val_accuracy: 0.9194\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2019 - accuracy: 0.9395 - val_loss: 0.8224 - val_accuracy: 0.8306\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1267 - accuracy: 0.9639 - val_loss: 0.5029 - val_accuracy: 0.8917\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0487 - accuracy: 0.9867 - val_loss: 0.4088 - val_accuracy: 0.9361\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0204 - accuracy: 0.9951 - val_loss: 0.4628 - val_accuracy: 0.9361\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.5091 - val_accuracy: 0.9194\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.5290 - val_accuracy: 0.9333\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.4970 - val_accuracy: 0.9333\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.5302 - val_accuracy: 0.9333\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.5623 - val_accuracy: 0.9222\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.5512 - val_accuracy: 0.9333\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.5513 - val_accuracy: 0.9417\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.5801 - val_accuracy: 0.9333\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.5708 - val_accuracy: 0.9333\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0096 - accuracy: 0.9960 - val_loss: 0.5950 - val_accuracy: 0.9278\n",
      "Epoch 00047: early stopping\n",
      "\n",
      "Trainning fold 7\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_258 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_259 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_260 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_86 (MaxPoolin  (None, 12, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_86 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_354 (Dense)           (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.2115 - accuracy: 0.4485 - val_loss: 1.6023 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.1371 - accuracy: 0.5037 - val_loss: 1.7620 - val_accuracy: 0.0194\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0970 - accuracy: 0.5127 - val_loss: 1.4498 - val_accuracy: 0.0556\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 1.0569 - accuracy: 0.5373 - val_loss: 1.6128 - val_accuracy: 0.0250\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 1.0001 - accuracy: 0.5648 - val_loss: 1.6883 - val_accuracy: 0.0500\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.9276 - accuracy: 0.6102 - val_loss: 1.4486 - val_accuracy: 0.1861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.8583 - accuracy: 0.6377 - val_loss: 1.5218 - val_accuracy: 0.2833\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.7583 - accuracy: 0.6883 - val_loss: 1.2130 - val_accuracy: 0.3361\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6548 - accuracy: 0.7333 - val_loss: 1.1265 - val_accuracy: 0.4694\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6005 - accuracy: 0.7571 - val_loss: 0.8683 - val_accuracy: 0.5250\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.5093 - accuracy: 0.7972 - val_loss: 1.1830 - val_accuracy: 0.4667\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4558 - accuracy: 0.8130 - val_loss: 0.8788 - val_accuracy: 0.5889\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3967 - accuracy: 0.8478 - val_loss: 0.7166 - val_accuracy: 0.7417\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3242 - accuracy: 0.8790 - val_loss: 0.7906 - val_accuracy: 0.6639\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3057 - accuracy: 0.8873 - val_loss: 0.6496 - val_accuracy: 0.7250\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3001 - accuracy: 0.8920 - val_loss: 0.7093 - val_accuracy: 0.7028\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2103 - accuracy: 0.9235 - val_loss: 0.5099 - val_accuracy: 0.8528\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1816 - accuracy: 0.9361 - val_loss: 0.5894 - val_accuracy: 0.8389\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1691 - accuracy: 0.9358 - val_loss: 0.6571 - val_accuracy: 0.7167\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1806 - accuracy: 0.9404 - val_loss: 1.0040 - val_accuracy: 0.6944\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1389 - accuracy: 0.9565 - val_loss: 1.0949 - val_accuracy: 0.7111\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1689 - accuracy: 0.9435 - val_loss: 0.4531 - val_accuracy: 0.8750\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1389 - accuracy: 0.9590 - val_loss: 0.3701 - val_accuracy: 0.8750\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0877 - accuracy: 0.9741 - val_loss: 0.3716 - val_accuracy: 0.9056\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0697 - accuracy: 0.9802 - val_loss: 0.3901 - val_accuracy: 0.9167\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0547 - accuracy: 0.9858 - val_loss: 0.3714 - val_accuracy: 0.9139\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0828 - accuracy: 0.9735 - val_loss: 0.5037 - val_accuracy: 0.8889\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0591 - accuracy: 0.9830 - val_loss: 0.4067 - val_accuracy: 0.9083\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0442 - accuracy: 0.9880 - val_loss: 0.3776 - val_accuracy: 0.9194\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0402 - accuracy: 0.9883 - val_loss: 0.3831 - val_accuracy: 0.9333\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0484 - accuracy: 0.9870 - val_loss: 0.4778 - val_accuracy: 0.8972\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0349 - accuracy: 0.9901 - val_loss: 0.4722 - val_accuracy: 0.9167\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9904 - val_loss: 0.4428 - val_accuracy: 0.9167\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 0.3955 - val_accuracy: 0.9333\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.4124 - val_accuracy: 0.9167\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0271 - accuracy: 0.9895 - val_loss: 0.5482 - val_accuracy: 0.9139\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1899 - accuracy: 0.9438 - val_loss: 0.6860 - val_accuracy: 0.8361\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0949 - accuracy: 0.9679 - val_loss: 0.4042 - val_accuracy: 0.8861\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0433 - accuracy: 0.9855 - val_loss: 0.2513 - val_accuracy: 0.9500\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9901 - val_loss: 0.4848 - val_accuracy: 0.8556\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0288 - accuracy: 0.9895 - val_loss: 0.3216 - val_accuracy: 0.9361\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0230 - accuracy: 0.9917 - val_loss: 0.3016 - val_accuracy: 0.9333\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.3696 - val_accuracy: 0.9250\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0163 - accuracy: 0.9938 - val_loss: 0.3452 - val_accuracy: 0.9333\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0161 - accuracy: 0.9935 - val_loss: 0.3324 - val_accuracy: 0.9333\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0158 - accuracy: 0.9932 - val_loss: 0.3922 - val_accuracy: 0.9472\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 0.5409 - val_accuracy: 0.9250\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.0244 - accuracy: 0.9907 - val_loss: 0.3246 - val_accuracy: 0.9583\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0147 - accuracy: 0.9935 - val_loss: 0.3947 - val_accuracy: 0.9333\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.3788 - val_accuracy: 0.9472\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.3960 - val_accuracy: 0.9417\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0429 - accuracy: 0.9892 - val_loss: 0.3105 - val_accuracy: 0.9556\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2340 - accuracy: 0.9358 - val_loss: 0.4370 - val_accuracy: 0.9056\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0459 - accuracy: 0.9867 - val_loss: 0.4843 - val_accuracy: 0.9361\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0181 - accuracy: 0.9935 - val_loss: 0.6316 - val_accuracy: 0.9361\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.5938 - val_accuracy: 0.9472\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0116 - accuracy: 0.9948 - val_loss: 0.6274 - val_accuracy: 0.9472\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.6148 - val_accuracy: 0.9389\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.6900 - val_accuracy: 0.9306\n",
      "Epoch 00059: early stopping\n",
      "\n",
      "Trainning fold 8\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_261 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_262 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_263 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_87 (MaxPoolin  (None, 12, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_87 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_360 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 6ms/step - loss: 1.1919 - accuracy: 0.4528 - val_loss: 1.5926 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 1.1346 - accuracy: 0.4969 - val_loss: 1.4595 - val_accuracy: 0.0278\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 1.1057 - accuracy: 0.5096 - val_loss: 1.6960 - val_accuracy: 0.0250\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0784 - accuracy: 0.5228 - val_loss: 1.6160 - val_accuracy: 0.0194\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0365 - accuracy: 0.5497 - val_loss: 1.5680 - val_accuracy: 0.0111\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.9939 - accuracy: 0.5762 - val_loss: 1.4422 - val_accuracy: 0.0833\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.9219 - accuracy: 0.6093 - val_loss: 1.6047 - val_accuracy: 0.0722\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.8455 - accuracy: 0.6460 - val_loss: 1.4276 - val_accuracy: 0.2361\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.7426 - accuracy: 0.6883 - val_loss: 1.4903 - val_accuracy: 0.2083\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6590 - accuracy: 0.7299 - val_loss: 1.1203 - val_accuracy: 0.3306\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.5560 - accuracy: 0.7731 - val_loss: 0.9999 - val_accuracy: 0.4361\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4777 - accuracy: 0.8093 - val_loss: 1.0746 - val_accuracy: 0.4611\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4013 - accuracy: 0.8420 - val_loss: 0.8338 - val_accuracy: 0.5806\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3348 - accuracy: 0.8716 - val_loss: 1.6112 - val_accuracy: 0.3750\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3541 - accuracy: 0.8691 - val_loss: 0.7517 - val_accuracy: 0.7500\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3163 - accuracy: 0.8809 - val_loss: 0.6346 - val_accuracy: 0.7444\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2364 - accuracy: 0.9114 - val_loss: 0.8074 - val_accuracy: 0.6556\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1983 - accuracy: 0.9293 - val_loss: 0.6636 - val_accuracy: 0.7778\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1689 - accuracy: 0.9398 - val_loss: 0.5332 - val_accuracy: 0.8194\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1514 - accuracy: 0.9512 - val_loss: 0.5228 - val_accuracy: 0.8778\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1816 - accuracy: 0.9361 - val_loss: 0.9211 - val_accuracy: 0.7139\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2324 - accuracy: 0.9241 - val_loss: 0.7400 - val_accuracy: 0.7694\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1204 - accuracy: 0.9565 - val_loss: 0.8364 - val_accuracy: 0.7528\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0948 - accuracy: 0.9698 - val_loss: 0.5507 - val_accuracy: 0.8444\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0962 - accuracy: 0.9651 - val_loss: 0.7372 - val_accuracy: 0.7694\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0867 - accuracy: 0.9713 - val_loss: 0.6379 - val_accuracy: 0.8806\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0936 - accuracy: 0.9660 - val_loss: 0.4878 - val_accuracy: 0.8861\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.0636 - accuracy: 0.9793 - val_loss: 0.4919 - val_accuracy: 0.8694\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0784 - accuracy: 0.9731 - val_loss: 0.8647 - val_accuracy: 0.7778\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1982 - accuracy: 0.9336 - val_loss: 0.8266 - val_accuracy: 0.8000\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0971 - accuracy: 0.9701 - val_loss: 0.4313 - val_accuracy: 0.8861\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0436 - accuracy: 0.9870 - val_loss: 0.4393 - val_accuracy: 0.9028\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0337 - accuracy: 0.9889 - val_loss: 0.5758 - val_accuracy: 0.8861\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0301 - accuracy: 0.9907 - val_loss: 0.6081 - val_accuracy: 0.8833\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9898 - val_loss: 0.5564 - val_accuracy: 0.9028\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0291 - accuracy: 0.9914 - val_loss: 0.6473 - val_accuracy: 0.9111\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0266 - accuracy: 0.9907 - val_loss: 0.6031 - val_accuracy: 0.9083\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1671 - accuracy: 0.9469 - val_loss: 0.5558 - val_accuracy: 0.8667\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0453 - accuracy: 0.9864 - val_loss: 0.6845 - val_accuracy: 0.8528\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0566 - accuracy: 0.9793 - val_loss: 0.4716 - val_accuracy: 0.9306\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.4847 - val_accuracy: 0.9361\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.4953 - val_accuracy: 0.9222\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0197 - accuracy: 0.9948 - val_loss: 0.6487 - val_accuracy: 0.8861\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0657 - accuracy: 0.9762 - val_loss: 0.4933 - val_accuracy: 0.9333\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0687 - accuracy: 0.9799 - val_loss: 0.4796 - val_accuracy: 0.9083\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0494 - accuracy: 0.9840 - val_loss: 0.4527 - val_accuracy: 0.9278\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.5086 - val_accuracy: 0.9361\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0773 - accuracy: 0.9728 - val_loss: 0.4462 - val_accuracy: 0.9306\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.3736 - val_accuracy: 0.9556\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.3942 - val_accuracy: 0.9556\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0075 - accuracy: 0.9966 - val_loss: 0.4140 - val_accuracy: 0.9556\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.4602 - val_accuracy: 0.9361\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.4843 - val_accuracy: 0.9361\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.4635 - val_accuracy: 0.9417\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.4690 - val_accuracy: 0.9417\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.4771 - val_accuracy: 0.9361\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.5154 - val_accuracy: 0.9417\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.4608 - val_accuracy: 0.9417\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.4489 - val_accuracy: 0.9556\n",
      "Epoch 60/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.5519 - val_accuracy: 0.9417\n",
      "Epoch 61/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1029 - accuracy: 0.9731 - val_loss: 0.7263 - val_accuracy: 0.8528\n",
      "Epoch 62/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.1179 - accuracy: 0.9608 - val_loss: 1.1211 - val_accuracy: 0.7917\n",
      "Epoch 63/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0621 - accuracy: 0.9799 - val_loss: 0.4814 - val_accuracy: 0.9250\n",
      "Epoch 64/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.4419 - val_accuracy: 0.9472\n",
      "Epoch 65/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.5282 - val_accuracy: 0.9333\n",
      "Epoch 66/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9975 - val_loss: 0.5653 - val_accuracy: 0.9278\n",
      "Epoch 67/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0094 - accuracy: 0.9954 - val_loss: 0.5300 - val_accuracy: 0.9333\n",
      "Epoch 68/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.5432 - val_accuracy: 0.9333\n",
      "Epoch 69/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5564 - val_accuracy: 0.9333\n",
      "Epoch 00069: early stopping\n",
      "\n",
      "Trainning fold 9\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_264 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_265 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_266 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_88 (MaxPoolin  (None, 12, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_88 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_365 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.1927 - accuracy: 0.4531 - val_loss: 1.8083 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 1.1428 - accuracy: 0.4978 - val_loss: 1.8030 - val_accuracy: 0.0083\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0912 - accuracy: 0.5231 - val_loss: 1.7854 - val_accuracy: 0.0361\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0629 - accuracy: 0.5259 - val_loss: 1.5465 - val_accuracy: 0.0472\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0112 - accuracy: 0.5633 - val_loss: 1.7345 - val_accuracy: 0.0389\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.9434 - accuracy: 0.5840 - val_loss: 1.3328 - val_accuracy: 0.3611\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.8614 - accuracy: 0.6373 - val_loss: 1.3208 - val_accuracy: 0.2500\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.7966 - accuracy: 0.6633 - val_loss: 1.2858 - val_accuracy: 0.3861\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6971 - accuracy: 0.7108 - val_loss: 1.0435 - val_accuracy: 0.4972\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6009 - accuracy: 0.7608 - val_loss: 1.1690 - val_accuracy: 0.3889\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.5151 - accuracy: 0.7948 - val_loss: 1.4898 - val_accuracy: 0.3222\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4399 - accuracy: 0.8306 - val_loss: 1.2106 - val_accuracy: 0.5000\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3491 - accuracy: 0.8664 - val_loss: 0.7402 - val_accuracy: 0.7194\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3060 - accuracy: 0.8802 - val_loss: 1.2041 - val_accuracy: 0.5528\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2895 - accuracy: 0.8923 - val_loss: 0.8812 - val_accuracy: 0.6194\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2528 - accuracy: 0.9049 - val_loss: 0.8302 - val_accuracy: 0.7111\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1841 - accuracy: 0.9327 - val_loss: 0.8700 - val_accuracy: 0.7694\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1597 - accuracy: 0.9451 - val_loss: 0.8336 - val_accuracy: 0.8194\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1301 - accuracy: 0.9540 - val_loss: 0.8262 - val_accuracy: 0.8111\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1108 - accuracy: 0.9593 - val_loss: 0.8539 - val_accuracy: 0.8111\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.1750 - accuracy: 0.9407 - val_loss: 2.2528 - val_accuracy: 0.4944\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2068 - accuracy: 0.9299 - val_loss: 0.7802 - val_accuracy: 0.8278\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0891 - accuracy: 0.9701 - val_loss: 0.6059 - val_accuracy: 0.9000\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0746 - accuracy: 0.9753 - val_loss: 0.7299 - val_accuracy: 0.8694\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0676 - accuracy: 0.9778 - val_loss: 0.8322 - val_accuracy: 0.8722\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0876 - accuracy: 0.9710 - val_loss: 0.8685 - val_accuracy: 0.8889\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0874 - accuracy: 0.9698 - val_loss: 0.9379 - val_accuracy: 0.8306\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0492 - accuracy: 0.9833 - val_loss: 0.9184 - val_accuracy: 0.8778\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0994 - accuracy: 0.9657 - val_loss: 1.1800 - val_accuracy: 0.7222\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1511 - accuracy: 0.9590 - val_loss: 0.7517 - val_accuracy: 0.8778\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0807 - accuracy: 0.9719 - val_loss: 0.7424 - val_accuracy: 0.9083\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 0.7487 - val_accuracy: 0.9250\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9898 - val_loss: 0.8098 - val_accuracy: 0.9028\n",
      "Epoch 34/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0737 - accuracy: 0.9769 - val_loss: 1.0200 - val_accuracy: 0.8306\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9886 - val_loss: 0.7035 - val_accuracy: 0.9222\n",
      "Epoch 36/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.7892 - val_accuracy: 0.9222\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.8685 - val_accuracy: 0.9167\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0161 - accuracy: 0.9960 - val_loss: 0.8393 - val_accuracy: 0.9306\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 0.9400 - val_accuracy: 0.9167\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.9905 - val_accuracy: 0.9083\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0525 - accuracy: 0.9796 - val_loss: 1.0383 - val_accuracy: 0.8944\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0424 - accuracy: 0.9886 - val_loss: 0.7274 - val_accuracy: 0.9222\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.1304 - accuracy: 0.9599 - val_loss: 0.7417 - val_accuracy: 0.8944\n",
      "Epoch 00043: early stopping\n",
      "\n",
      "Trainning fold 10\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_267 (Conv1D)         (None, 28, 64)            256       \n",
      "                                                                 \n",
      " conv1d_268 (Conv1D)         (None, 26, 32)            6176      \n",
      "                                                                 \n",
      " conv1d_269 (Conv1D)         (None, 24, 16)            1552      \n",
      "                                                                 \n",
      " max_pooling1d_89 (MaxPoolin  (None, 12, 16)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_89 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 128)               24704     \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,228\n",
      "Trainable params: 66,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "102/102 [==============================] - 2s 7ms/step - loss: 1.2030 - accuracy: 0.4435 - val_loss: 1.5417 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1508 - accuracy: 0.4957 - val_loss: 1.5811 - val_accuracy: 0.0028\n",
      "Epoch 3/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.1201 - accuracy: 0.4991 - val_loss: 1.7075 - val_accuracy: 0.0278\n",
      "Epoch 4/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0626 - accuracy: 0.5269 - val_loss: 1.3775 - val_accuracy: 0.3139\n",
      "Epoch 5/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 1.0028 - accuracy: 0.5679 - val_loss: 1.7238 - val_accuracy: 0.0472\n",
      "Epoch 6/300\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.9222 - accuracy: 0.6102 - val_loss: 1.3914 - val_accuracy: 0.1167\n",
      "Epoch 7/300\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.8269 - accuracy: 0.6605 - val_loss: 1.3388 - val_accuracy: 0.2639\n",
      "Epoch 8/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.7384 - accuracy: 0.6978 - val_loss: 1.3881 - val_accuracy: 0.2667\n",
      "Epoch 9/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.6388 - accuracy: 0.7469 - val_loss: 1.3028 - val_accuracy: 0.3722\n",
      "Epoch 10/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.5579 - accuracy: 0.7728 - val_loss: 1.0715 - val_accuracy: 0.4833\n",
      "Epoch 11/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4968 - accuracy: 0.8077 - val_loss: 1.0117 - val_accuracy: 0.5361\n",
      "Epoch 12/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8302 - val_loss: 0.7709 - val_accuracy: 0.6139\n",
      "Epoch 13/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3602 - accuracy: 0.8602 - val_loss: 0.8246 - val_accuracy: 0.6194\n",
      "Epoch 14/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.3089 - accuracy: 0.8929 - val_loss: 0.7638 - val_accuracy: 0.6722\n",
      "Epoch 15/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2704 - accuracy: 0.9034 - val_loss: 0.8113 - val_accuracy: 0.6972\n",
      "Epoch 16/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1973 - accuracy: 0.9318 - val_loss: 0.4075 - val_accuracy: 0.8500\n",
      "Epoch 17/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.2508 - accuracy: 0.9127 - val_loss: 0.5786 - val_accuracy: 0.7889\n",
      "Epoch 18/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2090 - accuracy: 0.9293 - val_loss: 0.5784 - val_accuracy: 0.7750\n",
      "Epoch 19/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1505 - accuracy: 0.9515 - val_loss: 0.4519 - val_accuracy: 0.8500\n",
      "Epoch 20/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.1098 - accuracy: 0.9642 - val_loss: 0.3457 - val_accuracy: 0.9194\n",
      "Epoch 21/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1010 - accuracy: 0.9648 - val_loss: 0.4955 - val_accuracy: 0.8417\n",
      "Epoch 22/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0927 - accuracy: 0.9719 - val_loss: 0.4512 - val_accuracy: 0.8694\n",
      "Epoch 23/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0834 - accuracy: 0.9750 - val_loss: 0.4693 - val_accuracy: 0.9000\n",
      "Epoch 24/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0979 - accuracy: 0.9698 - val_loss: 0.4711 - val_accuracy: 0.8639\n",
      "Epoch 25/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1254 - accuracy: 0.9602 - val_loss: 0.4378 - val_accuracy: 0.8639\n",
      "Epoch 26/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.1116 - accuracy: 0.9642 - val_loss: 0.6522 - val_accuracy: 0.7861\n",
      "Epoch 27/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0573 - accuracy: 0.9836 - val_loss: 0.3591 - val_accuracy: 0.9250\n",
      "Epoch 28/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0467 - accuracy: 0.9846 - val_loss: 0.3313 - val_accuracy: 0.9389\n",
      "Epoch 29/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 0.3624 - val_accuracy: 0.9500\n",
      "Epoch 30/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.4381 - val_accuracy: 0.9000\n",
      "Epoch 31/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.4043 - val_accuracy: 0.9250\n",
      "Epoch 32/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0190 - accuracy: 0.9932 - val_loss: 0.3152 - val_accuracy: 0.9500\n",
      "Epoch 33/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.3182 - val_accuracy: 0.9500\n",
      "Epoch 34/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0268 - accuracy: 0.9914 - val_loss: 0.4503 - val_accuracy: 0.9278\n",
      "Epoch 35/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.2597 - accuracy: 0.9173 - val_loss: 0.7931 - val_accuracy: 0.7583\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9769 - val_loss: 0.3126 - val_accuracy: 0.9361\n",
      "Epoch 37/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.3086 - val_accuracy: 0.9417\n",
      "Epoch 38/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.2968 - val_accuracy: 0.9417\n",
      "Epoch 39/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.2866 - val_accuracy: 0.9500\n",
      "Epoch 40/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.3178 - val_accuracy: 0.9556\n",
      "Epoch 41/300\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.3153 - val_accuracy: 0.9500\n",
      "Epoch 42/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.3157 - val_accuracy: 0.9500\n",
      "Epoch 43/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.3347 - val_accuracy: 0.9500\n",
      "Epoch 44/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.3216 - val_accuracy: 0.9500\n",
      "Epoch 45/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.3173 - val_accuracy: 0.9639\n",
      "Epoch 46/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.3512 - val_accuracy: 0.9444\n",
      "Epoch 47/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.3745 - val_accuracy: 0.9361\n",
      "Epoch 48/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0675 - accuracy: 0.9815 - val_loss: 0.6196 - val_accuracy: 0.8778\n",
      "Epoch 49/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.1753 - accuracy: 0.9497 - val_loss: 0.7149 - val_accuracy: 0.8167\n",
      "Epoch 50/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0700 - accuracy: 0.9796 - val_loss: 0.4379 - val_accuracy: 0.9472\n",
      "Epoch 51/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.3055 - val_accuracy: 0.9500\n",
      "Epoch 52/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.3854 - val_accuracy: 0.9444\n",
      "Epoch 53/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0055 - accuracy: 0.9978 - val_loss: 0.3897 - val_accuracy: 0.9444\n",
      "Epoch 54/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.3961 - val_accuracy: 0.9444\n",
      "Epoch 55/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4242 - val_accuracy: 0.9444\n",
      "Epoch 56/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.4305 - val_accuracy: 0.9444\n",
      "Epoch 57/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.4428 - val_accuracy: 0.9444\n",
      "Epoch 58/300\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.4616 - val_accuracy: 0.9444\n",
      "Epoch 59/300\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.4600 - val_accuracy: 0.9444\n",
      "Epoch 00059: early stopping\n",
      "\n",
      "Time taken for training:  00:06:46\n",
      "\n",
      "\n",
      "Fold 1 - Train Accuracy 0.9889 - Test Accuracy 0.9825\n",
      "Fold 2 - Train Accuracy 0.9839 - Test Accuracy 0.9675\n",
      "Fold 3 - Train Accuracy 0.9928 - Test Accuracy 0.9800\n",
      "Fold 4 - Train Accuracy 0.9922 - Test Accuracy 0.9800\n",
      "Fold 5 - Train Accuracy 0.9878 - Test Accuracy 0.9800\n",
      "Fold 6 - Train Accuracy 0.9917 - Test Accuracy 0.9800\n",
      "Fold 7 - Train Accuracy 0.9906 - Test Accuracy 0.9825\n",
      "Fold 8 - Train Accuracy 0.9919 - Test Accuracy 0.9800\n",
      "Fold 9 - Train Accuracy 0.9725 - Test Accuracy 0.9425\n",
      "Fold 10 - Train Accuracy 0.9944 - Test Accuracy 0.9750\n",
      "\n",
      "Mean Train Accuracy: 0.9887 - Std: 0.0061 \n",
      "Mean Test Accuracy: 0.9750 - Std: 0.0116 \n",
      "\n",
      "Evaluate other metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      1000\n",
      "           1       0.97      0.99      0.98      1000\n",
      "           2       0.97      0.98      0.98      1000\n",
      "           3       0.99      0.94      0.96      1000\n",
      "\n",
      "    accuracy                           0.97      4000\n",
      "   macro avg       0.98      0.97      0.97      4000\n",
      "weighted avg       0.98      0.97      0.97      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_features = 1\n",
    "\n",
    "def create_v3():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = 64, kernel_size = 3, activation = \"relu\", input_shape = (number_of_steps, number_of_features)))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(Conv1D(filters = 16, kernel_size = 3, activation = \"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size = 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dense(4, activation = 'softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Data augmentation (5x).\n",
    "print(\"\\nStarting data augmentation.\")\n",
    "X_all_oversampled = []\n",
    "y_all_oversampled = []\n",
    "for count in range(0, 4):\n",
    "    X_oversampled, y_oversampled = resample(X_resampled[y_resampled == count],\n",
    "                                            y_resampled[y_resampled == count],\n",
    "                                            replace = True,\n",
    "                                            n_samples = 1000,\n",
    "                                            random_state = 42)\n",
    "    X_all_oversampled.extend(X_oversampled)\n",
    "    y_all_oversampled.extend(y_oversampled)\n",
    "X_resampled_arr = np.array(X_all_oversampled)\n",
    "y_resampled_arr = np.array(y_all_oversampled)\n",
    "print(\"\\nQuantity of samples generated by oversampling => \", len(y_resampled_arr))\n",
    "\n",
    "# Defining the number of folds (10 k-Fold).\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "# Normalize data using box-cox method.\n",
    "pt = PowerTransformer()\n",
    "pt.fit(X_resampled_arr)\n",
    "X_resampled_arr = pt.transform(X_resampled_arr)\n",
    "\n",
    "# Reshape the structure data to be compatible with pattern [samples, timesteps, features].\n",
    "X_train_reshaped = X_resampled_arr.reshape((X_resampled_arr.shape[0], number_of_steps, number_of_features))\n",
    "\n",
    "\n",
    "# Train the CNN model and evaluate it.\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting training at: \", time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 20)\n",
    "\n",
    "train_accuracy_by_fold = []\n",
    "test_accuracy_by_fold = []\n",
    "history_by_fold = []\n",
    "y_predclass_for_report = []\n",
    "y_testclass_for_report = []\n",
    "fold_number = 1\n",
    "for train_index, test_index in skf.split(X_train_reshaped, y_resampled_arr):\n",
    "    print(\"\\nTraining fold {}\".format(fold_number))\n",
    "    model = create_v3()\n",
    "    history = model.fit(X_train_reshaped[train_index], y_resampled_arr[train_index], validation_split = 0.1,\n",
    "                            epochs = 300, batch_size = 32, verbose = 1, callbacks = [es])\n",
    "    _, train_accuracy = model.evaluate(X_train_reshaped[train_index], y_resampled_arr[train_index], verbose = 0)\n",
    "    _, test_accuracy = model.evaluate(X_train_reshaped[test_index], y_resampled_arr[test_index], verbose = 0)\n",
    "    train_accuracy_by_fold.append(train_accuracy)\n",
    "    test_accuracy_by_fold.append(test_accuracy)\n",
    "    history_by_fold.append(history)\n",
    "    y_predclass_for_report.extend(np.argmax(model.predict(X_train_reshaped[test_index]), axis = 1))\n",
    "    y_testclass_for_report.extend(y_resampled_arr[test_index])\n",
    "    fold_number += 1\n",
    "\n",
    "elapsed_seconds = time.time() - start_time\n",
    "print(\"\\nTime taken for training: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_seconds)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show metrics.\n",
    "for i in range(len(train_accuracy_by_fold)):\n",
    "    print(\"Fold {} - Train Accuracy {:.4f} - Test Accuracy {:.4f}\".format((i + 1),\n",
    "                            train_accuracy_by_fold[i], test_accuracy_by_fold[i]))\n",
    "print(\"\\nMean Train Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(train_accuracy_by_fold), np.std(train_accuracy_by_fold)))\n",
    "print(\"Mean Test Accuracy: {:.4f} - Std: {:.4f} \".format(np.mean(test_accuracy_by_fold), np.std(test_accuracy_by_fold)))\n",
    "\n",
    "print(\"\\nEvaluate other metrics:\")\n",
    "print(classification_report(y_testclass_for_report, y_predclass_for_report, zero_division = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48119eaf",
   "metadata": {},
   "source": [
    "#### Show loss history by epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a10b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot loss history\n",
    "for i in range(len(history_by_fold)):\n",
    "    plt.plot(history_by_fold[i].history[\"val_loss\"], label = \"Fold {}\".format(i + 1))\n",
    "plt.title(\"Validation Loss vs Number of epochs\", fontsize = 12)\n",
    "plt.xlabel(\"Epochs\", fontsize = 12)\n",
    "plt.ylabel(\"Loss\", fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26847b22",
   "metadata": {},
   "source": [
    "#### Show accuracy history by epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a7e0aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot accuracy history\n",
    "for i in range(len(history_by_fold)):\n",
    "    plt.plot(history_by_fold[i].history[\"val_accuracy\"], label = \"Fold {}\".format(i + 1))\n",
    "plt.title(\"Validation Accuracy vs Number of epochs\", fontsize = 12)\n",
    "plt.xlabel('Epochs', fontsize = 12)\n",
    "plt.ylabel('Accuracy', fontsize = 12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1cb61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
